% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[style=apa,]{biblatex}
\addbibresource{book.bib}
\addbibresource{packages.bib}
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Data Management in Large-Scale Education Research},
  pdfauthor={Crystal Lewis},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Data Management in Large-Scale Education Research}
\author{Crystal Lewis}
\date{2022-10-12}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{preamble}{%
\chapter{Preamble}\label{preamble}}

This is the in-progress version of \emph{Data Management in Large-Scale Education Research}. To see a previous version of this material, please visit this \href{https://cghlewis.github.io/mpsi-data-training/}{website}.

\emph{The results of educational research studies are only as accurate as the data used to produce them.}
\emph{- Aleata Hubbard} \autocite{hubbard_data_2017}

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

In 2013, without knowing that the term research data management existed, I accepted a job as a Research Associate with a prevention science research center. My job was to coordinate the collection and management of data for federally funded randomized controlled trial efficacy studies taking place in K-12 schools, along with a team of PIs, other full-time staff, part-time data collectors, and graduate students. While I had some experience analyzing and working with education data, i.e.~ECKLS-K, I had no experience running research grants, collecting original data, or managing research data, but I was excited to learn.

In my time in that position I learned to plan, schedule, and track data collection activities, create data collection tools, organize and document data inputs, and produce usable data outputs; but I didn't learn to do these things through any formal training. There were no books, courses, or workshops that I learned from. I learned from colleagues and a large amount of trial and error. Since then, as I have met more PIs, data managers, and project coordinators in education research, I realize that this is a common method for learning data management (mentoring and ``winging it''). And while learning data management through these informal methods helps us get by, what these type of training methods really lack are standards, leading to inconsistencies across the field \autocite{borghi_promoting_2022}.

\hypertarget{why-this-book}{%
\section{Why this book}\label{why-this-book}}

Research data management is becoming more complicated. We are collecting more data, in sometimes very novel ways, and using more complex technologies, all while increasing the visibility of our work with the push for data sharing and open science practices \autocite{briney_data_2015}. Ad hoc data management practices may have worked for us in the past, but now others need to understand our processes as well, requiring researchers to be more thoughtful in planning their data management routines.

\hypertarget{lack-of-training-resources-and-standards}{%
\subsection{Lack of training, resources, and standards}\label{lack-of-training-resources-and-standards}}

In order to implement thoughtful and standardized data management practices, researchers need training. Yet there is a clear lack of data management training in higher education. In a survey of 274 psychology researchers, Borghi and Van Gulick \autocite{borghi_data_2021} found that only 33\% of respondents learned data management from college level coursework, while 64\% learned from collaborators, and 52\% learned from self-education. In their survey of 202 education researchers (PIs and Co-PIs), Ceviren and Logan \autocite{ceviren_ceviren_logan_ehe_forum_2022pdf_2022} found that over 60\% of respondents reported having no formal training in data management, yet across eight different data management practices, respondents were responsible for data management activities anywhere from 25-50\% of the time.

Without training, resources and formal support systems are the next best option for learning best practices. During my data management journey I have discovered an excellent support system of professionals in university systems, i.e.~research data librarians, who can consult with research teams in their data management journey, and I have also come across some solid existing research data management books and manuals which I will link to in this book. However, while education researchers are starting to put out some excellent resources \autocite{neild_sharing_2022,reynolds_basics_2022}, I still find there is a dearth of tangible guides for researchers to refer to when building a data management workflow in the field of education, especially those working on large-scale longitudinal research grants where there are many moving pieces. Researchers are often collecting data in real-world environments, such as school systems, and keeping that data secure and reliable in a deliberate and orderly way can be overwhelming.

Last, unfortunately, while other fields of research, such as psychology, appear to be banding together to develop standards around data management \autocite{noauthor_psych-ds_nodate}, the field of education has yet to develop agreed upon rules for things such as data documentation or data formats. With this lack of standards, researchers are left to create practices that work for their team, leading to inconsistent data management practices across the field.

\hypertarget{consequences}{%
\subsection{Consequences}\label{consequences}}

A lack of training in data management practices and an absence of agreed upon standards in the field of education leads to consequences. Implementing inconsistent data management practices, while typically only resulting in frustration and time lost, also has the potential to be devastating, resulting in analyzing erroneous data or even unusable or lost data. In a review of 1,082 retracted publications from the journal PubMed from 2013-2016, authors found that 32\% of retractions were due to data management errors \autocite{campos-varela_misconduct_2019}. In a 2013 study surveying 360 graduate students about their data management practices, 14\% of students indicated they had to recollect data that had been previously collected because they could not find a file or the file had been corrupted, while 17\% of students said they had lost a file and been unable to recollect it \autocite{doucette_drowning_2013}. In their 2021 study of 488 researchers who had published in a psychology journal between 2010 and 2018, Kovacs et al. \autocite{kovacs_role_2021} asked respondents about their data management mistakes and found that the most serious data management mistakes reported led to a range of consequences including time loss, frustration, and even erroneous conclusions.

Poor data management can even prevent researchers from implementing other good open science practices. In waves 1 and 2 of the Open Scholarship Survey being collected by the Center for Open Science, the team has found that of the education researchers surveyed who are currently not publicly sharing their research data, about 10\% mentioned ``being nervous about mistakes'' as a reason for not sharing \autocite{osf_cos_2022}. The well known replication crisis is another reason to be concerned with data management. Failure to implement practices such as quality documentation or standardization of practices (among many other reasons), resulted in one study finding that across 1,500 researchers surveyed, more than 70\% had tried and failed to reproduce another researcher's study \autocite{eisenstein_pursuit_2022}.

\hypertarget{about-this-book}{%
\section{About this book}\label{about-this-book}}

My hope is that this book can be a foundation to help researchers think through how to build a consistent and standardized data management workflow that works for their team and their projects. While the field as a whole may not have agreed upon rules for data management, there are still best practices that are proven to result in more reproducible, reliable, and secure data. While this book cannot remove barriers to implementing good data management practices, such as the complexity of your project or the novelty of the technology you are using \autocite{alston_beginners_2021} it hopefully provides you the knowledge and skills necessary to work in these complex environments.

This book should be viewed as a handbook to be referred to regularly and is not necessarily meant to be read in its entirety in one sitting. While perusing through the entire book to better understand the entire research data life cycle is very helpful, this book is also intended to have chapters referenced as needed when you are ready to start planning a specific phase of your project.

\hypertarget{what-this-book-will-cover}{%
\subsection{What this book will cover}\label{what-this-book-will-cover}}

This book begins, like many other books in this subject area, by describing the research life cycle and how data management fits within the larger picture. The remaining chapters are then organized by each phase of the life cycle, with examples of best practices provided for each phase. Considerations on whether you should implement and how to integrate those practices into your workflow will be discussed.

\hypertarget{what-this-book-will-not-cover}{%
\subsection{What this book will not cover}\label{what-this-book-will-not-cover}}

It is important to also point out what this book will not cover. This book is intended to be tool agnostic and provide suggestions that anyone can use, no matter what tools you work with, especially when it comes to data cleaning. Therefore while I might mention options of tools you can use for different tasks, I will not advocate for any specific tools.

There are also no specific coding practices or actual syntax included in this book. To be honest, in many ways I feel that the actual ``data cleaning'' phase of data management is the ``easiest'' phase to implement, as long as you implement good practices up until that point. Because of that, this book introduces practices in all phases leading up to data cleaning that will prepare your data for minimal cleaning. With that said, I do provide examples of what I would expect to see in a data cleaning process, I just do not provide steps for any specific software system. That is beyond the scope of this book.

This book will also not talk about analysis or preparing data for analysis through means such as data imputation or calculating analysis specific variables. This book is written from the perspective of a data manager, and that perspective is to implement practices that keep data in its most true, but usable form, for any future researcher to analyze in a way that works best for them.

\hypertarget{who-this-book-is-for}{%
\section{Who this book is for}\label{who-this-book-is-for}}

This book is for anyone involved in a research study involving original data collection. This book in particular focuses on quantitative data collection, while I do think that many of the practices covered can also apply to qualitative data as well. This book also applies to any team member, ranging from PIs, to data managers, to project staff, to students, to contractual data collectors. The contents of this book are useful for anyone who may have a part in planning, collecting, or organizing research study data.

\hypertarget{final-note}{%
\section{Final note}\label{final-note}}

Planning and implementing new data management practices on top of planning the implementation of your entire research grant can feel overwhelming. However, the idea of this book is to find and implement the practices that work for you and your team, and that may be just a few of the suggestions mentioned or all of the suggestions. Improving your data management workflow is a process and it becomes easier over time as those practices become part of your normal routine. At some point you may even find that you enjoy working on data management processes as you start to see the benefits of their implementation!

\hypertarget{acknowledgements}{%
\section{Acknowledgements}\label{acknowledgements}}

This book is a compilation of lessons I have learned in my personal experiences as a data manager, knowledge collected from existing books and papers (many written by librarians or those involved in the open science movement), as well as advice and stories collected through interviews with other researchers who work with data. I want to be clear that I did not study research data management, unlike research data librarians who are experts in this content. Much of this book will be based off of lessons learned from firsthand experience and this book is my attempt to hopefully save others from making the same mistakes I have personally made or seen others make. I can not emphasize enough that if you work for a university and you have the opportunity to consult with a librarian for your project, you absolutely should!

With that said, there is a long list of people I would like to acknowledge for their contributions to this book and for supporting me in this process.

Interviewees:

Others:

\hypertarget{research-data-management}{%
\chapter{Research Data Management}\label{research-data-management}}

\hypertarget{what-is-research-data-management}{%
\section{What is research data management?}\label{what-is-research-data-management}}

Research data management (RDM) involves the broad process of planning and implementing standardized practices across the research life cycle \autocite{borghi_promoting_2022}. The practices of managing data begin long before data is ever collected, during the planning phase, and continue well after a research project ends during the archiving phase.

While organizations like Data Documentation Initiative and Dublin Core have developed metadata standards for fields to adopt, it is common knowledge that there are no agreed-upon norms for managing data within and across disciplines within the field of education. The rules for how data should be collected, organized, stored, described, and shared is often left up to each individual team, as long as external requirements of the IRB and funders are met \autocite{tenopir_data_2016-1}. With a growing interest in open science practices and expanding requirements for federally funded research to make data publicly available \autocite{office_of_science_and_technology_policy_ostp_2022}, data repositories will most likely begin to play a stronger role in promoting standards for many data management practices around data formats and documentation \autocite{borghi_promoting_2022}.

\hypertarget{why-care-about-research-data-management}{%
\section{Why care about research data management?}\label{why-care-about-research-data-management}}

Without agreed-upon standards in the field, it is important for research teams to develop their own data management standards that apply within and across all of their projects. There are both external pressures and personal reasons to care about developing research data management standards.

\hypertarget{external-reasons}{%
\subsection{External Reasons}\label{external-reasons}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Funder compliance}: Since 2013, even earlier for the National Science Foundation, most federal agencies that education researchers work with have required a data management plan as part of their funding application. While the focus of these plans is mostly on the future outcome of data sharing, the data management plan is a means of ensuring that researchers will thoughtfully plan for a research study that will result in data that can be shared with confidence, free from errors, uncertainty, or violations of confidentiality. President Obama's May 2013 Executive Order declared that ``the default state of new and modernized government information resources shall be open and machine readable'' \autocite{the_white_house_executive_2013}. In August of 2022, the Office of Science and Technology Policy (OSTP) doubled down on their data sharing policy and issued a memorandum stating that all federal agencies must update their public access policies no later than December 31, 2025, to make federally funded publications and their supporting data accessible to the public with no embargo on their release \autocite{office_of_science_and_technology_policy_ostp_2022}. Along with this mandatory data sharing policy, comes the incentive to manage your data for the purposes of data sharing \autocite{borghi_promoting_2022}.
\item
  \textbf{Journal compliance}: Depending on what journal you publish with, providing open access to the data associated with your publication may be a requirement. Again, along with data sharing, comes the incentive to manage your data in a thoughtful, responsible, and organized way.
\item
  \textbf{Compliance with legal and ethical mandates}: If you are required to submit your research project to the Institutional Review Board, they will monitor how you manage your data. They care about the welfare, rights, and privacy of research participants and will have rules for how data is managed and stored securely.
\item
  \textbf{Open science practices}: With a growing interest in open science practices, sharing well managed data, curated in a reproducible way is ``a strong indicator to fellow researchers of rigor, trustworthiness, and transparency in scientific research'' (Alston \& Rick, 2021, p.2 \autocite{alston_beginners_2021}). Sharing data that has been managed in a reproducible way allows others to learn from your work, validate your results to strengthen evidence, as well as potentially catch errors in your work, preventing decisions being made based on incorrect data \autocite{alston_beginners_2021}. Well-managed data with sufficient documentation can also lead to more collaboration and greater impact as collaborators are able to access and understand your data with ease \autocites[ \textcite{eaker_what_2016}]{borghi_promoting_2022,cowles_research_nodate}.
\end{enumerate}

\hypertarget{personal-reasons}{%
\subsection{Personal reasons}\label{personal-reasons}}

Even if you never plan to share your data outside of your research group, there are still many compelling reasons to manage your data.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Contributes to reproducibility}: Reproducible research ``is a by-product of careful attention to detail throughout the research process'' (Alston \& Rick, 2021, p.2 \autocite{alston_beginners_2021}). Even if you are not concerned with others being able to reproduce your work (which is unlikely), you most likely want you and your team members to be able to reproduce each others work, ensuring you can trust your results.
\item
  \textbf{Improve continuity}: Implementing reproducible practices ensures project continuity through staff turnover. Having developed thorough protocols allows new staff to pick up right where the project left off, and implement the project with fidelity \autocite{borghi_data_2021,cowles_research_nodate,markowetz_five_2015}. Furthermore, having documented your data cleaning steps and transformations along the way, also allows your collaborators to pick up where you left off to easily continue an analysis project.
\item
  \textbf{Increases efficiency}: Documenting and automating tasks reduces duplication of efforts for repeating tasks, especially in longitudinal studies.
\item
  \textbf{Reduces burden and saves time, energy, and resources}: Taking the time to implement quality data management through the entire research study reduces data curation debt caused by suboptimal data management practices \autocite{butters_recognizing_2020}. Having poorly managed or documented data may make your data unusable, either permanently or until errors are corrected. Decreasing or removing this debt reduces the time, energy, and resources spent at the end of your study scrambling to fix errors made in poorly designed data collection instruments, gathering duplicate data that was lost, or documenting efforts long after most information has been forgotten.
\item
  \textbf{Shortens publication time}: Being able to find and understand your data when you need it is a huge benefit. It allows for the easy use and re-use of your data, and hastens efforts like the publication process \autocite{markowetz_five_2015}. Not having to search around for numbers of consented participants or asking which version of the data you should use allows you to spend more time analyzing and writing and less time playing detective.
\item
  \textbf{Increases reliability}: Errors come in many forms, from both humans and technology. We've seen evidence of this in the papers cited as being retracted for ``unreliable data'' in the blog \href{https://retractionwatch.com/}{Retraction Watch}. Implementing quality control procedures reduces the chances of errors occurring and allows you to have confidence in your data. Without implementing these practices, your research findings could include extra noise, missing data, or erroneous or misleading results.
\item
  \textbf{Improves data security}: Quality data management practices reduce the risk of lost or stolen data, the risk of data becoming corrupted or inaccessible, and the risk of breaking confidentiality agreements.
\end{enumerate}

\hypertarget{existing-frameworks}{%
\section{Existing Frameworks}\label{existing-frameworks}}

\hypertarget{terminology}{%
\section{Terminology}\label{terminology}}

\hypertarget{the-research-life-cycle}{%
\section{The Research Life Cycle}\label{the-research-life-cycle}}

\hypertarget{dmp}{%
\chapter{Data Management Plan}\label{dmp}}

\hypertarget{history-and-purpose}{%
\section{History and purpose}\label{history-and-purpose}}

\hypertarget{what-is-it}{%
\section{What is it?}\label{what-is-it}}

\hypertarget{why-are-dmps-important}{%
\section{Why are DMPs important?}\label{why-are-dmps-important}}

\hypertarget{what-to-include}{%
\section{What to include?}\label{what-to-include}}

\hypertarget{getting-help}{%
\section{Getting help}\label{getting-help}}

\hypertarget{budgeting}{%
\section{Budgeting}\label{budgeting}}

\hypertarget{planning-data-management}{%
\chapter{Planning Data Management}\label{planning-data-management}}

\hypertarget{why-spend-time-on-planning}{%
\section{Why spend time on planning?}\label{why-spend-time-on-planning}}

\hypertarget{planning-checklists}{%
\section{Planning checklists}\label{planning-checklists}}

\hypertarget{how-to-move-from-a-planning-checklist-to-a-workflow}{%
\section{How to move from a planning checklist to a workflow}\label{how-to-move-from-a-planning-checklist-to-a-workflow}}

\hypertarget{project-roles-and-responsibilities}{%
\chapter{Project Roles and Responsibilities}\label{project-roles-and-responsibilities}}

\hypertarget{why-its-important-to-assign-roles}{%
\section{Why it's important to assign roles}\label{why-its-important-to-assign-roles}}

\hypertarget{typical-roles-in-a-research-project}{%
\section{Typical roles in a research project}\label{typical-roles-in-a-research-project}}

\hypertarget{documentation}{%
\chapter{Documentation}\label{documentation}}

\hypertarget{what-is-documentation}{%
\section{What is documentation?}\label{what-is-documentation}}

\hypertarget{why-is-documentation-important}{%
\section{Why is documentation important?}\label{why-is-documentation-important}}

\hypertarget{team-level}{%
\section{Team Level}\label{team-level}}

\hypertarget{project-level}{%
\section{Project Level}\label{project-level}}

\hypertarget{dataset-level}{%
\section{Dataset Level}\label{dataset-level}}

\hypertarget{variable-level}{%
\section{Variable Level}\label{variable-level}}

\hypertarget{data-collection}{%
\chapter{Data Collection}\label{data-collection}}

\hypertarget{why-consider-data-management-in-data-collection}{%
\section{Why consider data management in data collection?}\label{why-consider-data-management-in-data-collection}}

\hypertarget{consents}{%
\section{Consents}\label{consents}}

\hypertarget{electronic-data-collection-instruments}{%
\section{Electronic data collection instruments}\label{electronic-data-collection-instruments}}

\hypertarget{paper-data-collection-instruments}{%
\section{Paper data collection instruments}\label{paper-data-collection-instruments}}

\hypertarget{interviewscocus-groups}{%
\section{Interviews/cocus groups}\label{interviewscocus-groups}}

\hypertarget{data-capture}{%
\chapter{Data Capture}\label{data-capture}}

\hypertarget{electronic-data-capture}{%
\section{Electronic data capture}\label{electronic-data-capture}}

\hypertarget{paper-data-capture}{%
\section{Paper data capture}\label{paper-data-capture}}

\hypertarget{extant-data}{%
\section{Extant data}\label{extant-data}}

\hypertarget{data-storage-and-security}{%
\chapter{Data Storage and Security}\label{data-storage-and-security}}

\hypertarget{types-of-data-youll-be-storing}{%
\section{Types of data you'll be storing}\label{types-of-data-youll-be-storing}}

\hypertarget{general-security-rules}{%
\section{General security rules}\label{general-security-rules}}

\hypertarget{participant-tracking-database}{%
\section{Participant tracking database}\label{participant-tracking-database}}

\hypertarget{electronic-data}{%
\section{Electronic data}\label{electronic-data}}

\hypertarget{detachable-media}{%
\section{Detachable media}\label{detachable-media}}

\hypertarget{audiovisual-data}{%
\section{Audio/visual data}\label{audiovisual-data}}

\hypertarget{paper-data}{%
\section{Paper data}\label{paper-data}}

\hypertarget{sharing-data}{%
\section{Sharing data}\label{sharing-data}}

\hypertarget{data-cleaning}{%
\chapter{Data Cleaning}\label{data-cleaning}}

\hypertarget{foundational-knowledge}{%
\section{Foundational knowledge}\label{foundational-knowledge}}

\hypertarget{data-structure}{%
\section{Data structure}\label{data-structure}}

\hypertarget{data-cleaning-plan}{%
\section{Data cleaning plan}\label{data-cleaning-plan}}

\hypertarget{data-validation}{%
\section{Data validation}\label{data-validation}}

\hypertarget{why-use-code}{%
\section{Why use code?}\label{why-use-code}}

\hypertarget{data-sharing}{%
\chapter{Data Sharing}\label{data-sharing}}

\hypertarget{why-share-your-data}{%
\section{Why share your data?}\label{why-share-your-data}}

\hypertarget{considering-fair-principles}{%
\section{Considering FAIR principles}\label{considering-fair-principles}}

\hypertarget{best-practices}{%
\section{Best practices}\label{best-practices}}

\hypertarget{retractions-and-revisions}{%
\section{Retractions and revisions}\label{retractions-and-revisions}}

\hypertarget{wrapping-it-up}{%
\chapter{Wrapping It Up}\label{wrapping-it-up}}

\hypertarget{connecting-practices-to-outcomes}{%
\section{Connecting practices to outcomes}\label{connecting-practices-to-outcomes}}

\hypertarget{putting-in-the-work}{%
\section{Putting in the work}\label{putting-in-the-work}}

\hypertarget{call-to-action}{%
\chapter{Call to Action}\label{call-to-action}}

\hypertarget{last-thoughts}{%
\section{Last thoughts}\label{last-thoughts}}

\hypertarget{training-for-future-researchers}{%
\section{Training for future researchers}\label{training-for-future-researchers}}

\hypertarget{investing-in-data-management-and-data-managers}{%
\section{Investing in data management and data managers}\label{investing-in-data-management-and-data-managers}}

\hypertarget{appendices}{%
\chapter{Appendices}\label{appendices}}

\printbibliography

\end{document}
