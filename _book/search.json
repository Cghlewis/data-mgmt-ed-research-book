[{"path":"index.html","id":"preamble","chapter":"1 Preamble","heading":"1 Preamble","text":"-progress version Data Management Large-Scale Education Research. see previous version material, please visit website.results educational research studies accurate data used produce .\n- Aleata Hubbard1","code":""},{"path":"index.html","id":"introduction","chapter":"1 Preamble","heading":"1.1 Introduction","text":"2013, without knowing term research data management existed, accepted job research associate research center. job coordinate collection management data federally funded randomized controlled trial efficacy studies taking place K-12 schools, along team PIs, full-time staff, part-time data collectors, graduate students. experience analyzing working education data, .e. ECLS-K, experience running research grants, collecting original data, managing research data, excited learn.time position learned plan, schedule, track data collection activities, create data collection tools, organize document data inputs, produce usable data outputs; didn’t learn things formal training. books, courses, workshops learned . learned colleagues large amount trial error. Since , met PIs, data managers, project coordinators education research, realize common method learning data management (mentoring “winging ”). learning data management informal methods helps us get , ramifications unstandardized system felt project team future data users.","code":""},{"path":"index.html","id":"why-this-book","chapter":"1 Preamble","heading":"1.2 Why this book","text":"Research data management becoming complicated. collecting data, sometimes novel ways, using complex technologies, increasing visibility work push data sharing open science practices.2 Ad hoc data management practices may worked us past, now others need understand processes well, requiring researchers thoughtful planning data management routines.","code":""},{"path":"index.html","id":"lack-of-training-resources-and-standards","chapter":"1 Preamble","heading":"1.2.1 Lack of training, resources, and standards","text":"order implement thoughtful standardized data management practices, researchers need training. Yet clear lack data management training higher education. survey 274 psychology researchers, Borghi Van Gulick3 found 33% respondents learned data management college level coursework, 64% learned collaborators, 52% learned self-education. survey 202 education researchers (PIs Co-PIs), Ceviren Logan4 found 60% respondents reported formal training data management, yet across eight different data management practices, respondents responsible data management activities anywhere 25-50% time.Without training, resources formal support systems next best option learning best practices. data management journey discovered excellent support system professionals university systems, .e. research data librarians, can consult research teams data management planning, also come across solid existing research data management books manuals link book. However, education researchers starting put excellent resources,5 still find dearth tangible guides researchers refer building data management workflow field education, especially working large-scale longitudinal research grants many moving pieces. Researchers often collecting data real-world environments, school systems, keeping data secure reliable deliberate orderly way can overwhelming.Last, unfortunately, fields research, psychology, appear banding together develop standards around structure document data,6 field education yet develop agreed upon rules things data documentation data formats. lack standards leads inconsistencies quality data products across field.7","code":""},{"path":"index.html","id":"consequences","chapter":"1 Preamble","heading":"1.2.2 Consequences","text":"lack training data management practices absence agreed upon standards field education leads consequences. Implementing subpar inconsistent data management practices, typically resulting frustration time lost, also potential devastating, resulting analyzing erroneous data even unusable lost data. review 1,082 retracted publications journal PubMed 2013-2016, authors found 32% retractions due data management errors.8 2013 study surveying 360 graduate students data management practices, 14% students indicated recollect data previously collected find file file corrupted, 17% students said lost file unable recollect .9 2021 study 488 researchers published psychology journal 2010 2018, Kovacs et al.10 asked respondents data management mistakes found serious data management mistakes reported led range consequences including time loss, frustration, even erroneous conclusions.Poor data management can even prevent researchers implementing good open science practices. waves 1 2 Open Scholarship Survey collected Center Open Science, team found education researchers surveyed currently publicly sharing research data, 10% mentioned “nervous mistakes” reason sharing.11 well known replication crisis another reason concerned data management. Failure implement practices quality documentation standardization practices (among many reasons), resulted one study finding across 1,500 researchers surveyed, 70% tried failed reproduce another researcher’s study.12","code":""},{"path":"index.html","id":"about-this-book","chapter":"1 Preamble","heading":"1.3 About this book","text":"field whole may agreed upon guidelines data management, still practices proven result secure, reproducible, reliable data. hope book can foundation help researchers think build quality, standardized data management workflow works team projects. suggested title book, content designed specifically help teams navigate complicated workflows associated large-scale research studies, randomized controlled trial studies, ultimately practices applicable research project, matter scale.book viewed handbook referenced regularly necessarily meant read entirety one sitting. perusing entire book better understand entire research data life cycle helpful, book also intended chapters referenced needed ready start planning specific phase project.","code":""},{"path":"index.html","id":"what-this-book-will-cover","chapter":"1 Preamble","heading":"1.3.1 What this book will cover","text":"book begins, like many books subject area, describing research life cycle data management fits within larger picture. remaining chapters organized phase life cycle, examples best practices provided phase. Considerations whether implement, integrate practices workflow discussed.","code":""},{"path":"index.html","id":"what-this-book-will-not-cover","chapter":"1 Preamble","heading":"1.3.2 What this book will not cover","text":"important also point book cover. book intended tool agnostic provide suggestions anyone can use, matter tools work , especially comes data cleaning. Therefore, might mention options tools can use different tasks, advocate specific tools.also specific coding practices actual syntax included book. honest, many ways feel actual “data cleaning” phase data management easiest phase implement, long implement good practices point. , book introduces practices phases leading data cleaning prepare data minimal cleaning. said, provide examples expect see data cleaning process, just provide steps specific software system. beyond scope book.book also talk analysis preparing data analysis means data imputation, removal legitimate outliers, calculating analysis specific variables. book written perspective data manager, perspective build datasets general data sharing. means cover practices keep data complete true, usable form, future researcher analyze way works best .","code":""},{"path":"index.html","id":"who-this-book-is-for","chapter":"1 Preamble","heading":"1.4 Who this book is for","text":"book anyone involved research study involving original data collection. book particular focuses quantitative, observational data collection, think many practices covered can also apply qualitative data well. book also applies team member, ranging PIs, data managers, project staff, students, contractual data collectors. contents book useful anyone may part planning, collecting, organizing research study data.","code":""},{"path":"index.html","id":"final-note","chapter":"1 Preamble","heading":"1.5 Final note","text":"Planning implementing new data management practices top planning implementation entire research grant can feel overwhelming. However, idea book find practices work team implement consistently. teams may look like implementing just suggestions mentioned others may involve implementing suggestions. Improving data management workflow process becomes easier time practices become part normal routine. point may even find enjoy working data management processes start see benefits implementation!","code":""},{"path":"index.html","id":"acknowledgements","chapter":"1 Preamble","heading":"1.6 Acknowledgements","text":"book compilation lessons learned personal experiences data manager, knowledge collected existing books papers (many written librarians involved open science movement), well advice stories collected interviews researchers work data. want clear formally study research data management, unlike research data librarians experts content. Much book based lessons learned firsthand experience book attempt hopefully save others making mistakes personally made seen others make. can emphasize enough work university opportunity consult librarian project, absolutely !said, long list people like acknowledge contributions book supporting process.Interviewees:Others:","code":""},{"path":"research-data-management.html","id":"research-data-management","chapter":"2 Research Data Management","heading":"2 Research Data Management","text":"","code":""},{"path":"research-data-management.html","id":"what-is-research-data-management","chapter":"2 Research Data Management","heading":"2.1 What is research data management?","text":"Research data management (RDM) involves organization, storage, preservation, dissemination research study data.13 Research study data includes materials generated collected throughout research process.14 can imagine, broad definition includes much just management digital datasets. also includes physical files, documentation, artifacts, recordings, . RDM substantial undertaking begins long data ever collected, planning phase, continues well research project ends archiving phase.","code":""},{"path":"research-data-management.html","id":"standards","chapter":"2 Research Data Management","heading":"2.2 Standards","text":"Data management standards refer rules data stored, organized, described.15 fields adopted standards across research life cycle, CDISC standards used clinical researchers,16 fields adopted standards specifically around metadata, TEI standards used digital humanities,17 grassroots efforts, fields psychology developing standards things data structure documentation based FAIR principles.18 Yet, common knowledge currently agreed-upon norms structure share data field education.19 rules data produced documented often left individual team, long external compliance requirements met.20 However, growing interest open science practices expanding requirements federally funded research make data publicly available,21 data repositories likely begin play stronger role promoting standards around data formats documentation.22While field standards structure format publicly shared products aid preservation re-use data much needed, actually good reasons impose standardization data management activities across field. Granting flexibility process managing data active data collection allows teams implement best practices work projects, long projects implement practices consistently project produce similar quality outputs across field.","code":""},{"path":"research-data-management.html","id":"why-care-about-research-data-management","chapter":"2 Research Data Management","heading":"2.3 Why care about research data management?","text":"Without current agreed-upon standards field, important research teams develop data management standards apply within across projects. Developing internal standards, implemented reproducible data management workflow, allows practices implemented consistently fidelity. external pressures personal reasons care developing research data management standards projects.","code":""},{"path":"research-data-management.html","id":"external-reasons","chapter":"2 Research Data Management","heading":"2.3.1 External Reasons","text":"Funder compliance: researcher applying federal funding required submit data management plan (DMP) along grant proposal23. contents plans may vary slightly across agencies shared purpose documents facilitate good data management practices mandate open sharing data maximize scientific outputs benefits society. Along mandatory data sharing policy, comes incentive manage data purposes data sharing.24Funder compliance: researcher applying federal funding required submit data management plan (DMP) along grant proposal23. contents plans may vary slightly across agencies shared purpose documents facilitate good data management practices mandate open sharing data maximize scientific outputs benefits society. Along mandatory data sharing policy, comes incentive manage data purposes data sharing.24Journal compliance: Depending journal publish , providing open access data associated publication may requirement (see PLOS ONE25 AMPPS26 examples). , along data sharing, comes incentive manage data thoughtful, responsible, organized way.Journal compliance: Depending journal publish , providing open access data associated publication may requirement (see PLOS ONE25 AMPPS26 examples). , along data sharing, comes incentive manage data thoughtful, responsible, organized way.Compliance legal ethical mandates: required submit research project Institutional Review Board (IRB), monitor manage data. IRB concerned welfare, rights, privacy research participants rules data managed stored securely. Additionally organization may institutional data policies mandate data must cared secured.27Compliance legal ethical mandates: required submit research project Institutional Review Board (IRB), monitor manage data. IRB concerned welfare, rights, privacy research participants rules data managed stored securely. Additionally organization may institutional data policies mandate data must cared secured.27Open science practices: growing interest open science practices, sharing well managed documented data helps build trust research process.28 Sharing data curated reproducible way “strong indicator fellow researchers rigor, trustworthiness, transparency scientific research” (Alston & Rick, 2021, p.2).29 also allows others replicate learn work, validate results strengthen evidence, well potentially catch errors work, preventing decisions made based incorrect data.30 Well-managed data sufficient documentation can also lead collaboration greater impact collaborators able access understand data ease.31Open science practices: growing interest open science practices, sharing well managed documented data helps build trust research process.28 Sharing data curated reproducible way “strong indicator fellow researchers rigor, trustworthiness, transparency scientific research” (Alston & Rick, 2021, p.2).29 also allows others replicate learn work, validate results strengthen evidence, well potentially catch errors work, preventing decisions made based incorrect data.30 Well-managed data sufficient documentation can also lead collaboration greater impact collaborators able access understand data ease.31","code":""},{"path":"research-data-management.html","id":"personal-reasons","chapter":"2 Research Data Management","heading":"2.3.2 Personal reasons","text":"Even never plan share data outside research group, still many compelling reasons manage data reproducible standardized way.Reduces data curation debt: Taking time plan implement quality data management entire research study reduces data curation debt caused suboptimal data management practices.32 poorly collected, managed, documented data may make data unusable, either permanently errors corrected. Decreasing removing debt reduces time, energy, resources spent possibly recollecting data scrambling end study get data acceptable standards.Reduces data curation debt: Taking time plan implement quality data management entire research study reduces data curation debt caused suboptimal data management practices.32 poorly collected, managed, documented data may make data unusable, either permanently errors corrected. Decreasing removing debt reduces time, energy, resources spent possibly recollecting data scrambling end study get data acceptable standards.Facilitates use data: Every member research team able find understand project data documentation huge benefit. allows easy use re-use data, hastens efforts like publication process.33 search around numbers consented participants asking version data use allows team spend time analyzing less time playing detective.Facilitates use data: Every member research team able find understand project data documentation huge benefit. allows easy use re-use data, hastens efforts like publication process.33 search around numbers consented participants asking version data use allows team spend time analyzing less time playing detective.Encourages validation: Implementing reproducible data management practices encourages allows team internally replicate validate processes ensure outputs accurate.Encourages validation: Implementing reproducible data management practices encourages allows team internally replicate validate processes ensure outputs accurate.Improves continuity: Data management practices documentation ensures project continuity staff turnover. developed thorough protocols allows new staff pick right former staff member left implement project fidelity.34 Furthermore, good data management enables continuity handing projects collaborators picking projects long hiatus.35Improves continuity: Data management practices documentation ensures project continuity staff turnover. developed thorough protocols allows new staff pick right former staff member left implement project fidelity.34 Furthermore, good data management enables continuity handing projects collaborators picking projects long hiatus.35Increases efficiency: Documenting automating tasks reduces duplication efforts repeating tasks, especially longitudinal studies.Increases efficiency: Documenting automating tasks reduces duplication efforts repeating tasks, especially longitudinal studies.Upholds research integrity: Errors come many forms, humans technology36. ’ve seen evidence papers cited retracted “unreliable data” blog Retraction Watch.37 Implementing quality control procedures reduces chances errors occurring allows confidence data. Without implementing practices, research findings include extra noise, missing data, erroneous misleading results.Upholds research integrity: Errors come many forms, humans technology36. ’ve seen evidence papers cited retracted “unreliable data” blog Retraction Watch.37 Implementing quality control procedures reduces chances errors occurring allows confidence data. Without implementing practices, research findings include extra noise, missing data, erroneous misleading results.Improves data security: Quality data management practices reduce risk lost stolen data, risk data becoming corrupted inaccessible, risk breaking confidentiality agreements.Improves data security: Quality data management practices reduce risk lost stolen data, risk data becoming corrupted inaccessible, risk breaking confidentiality agreements.","code":""},{"path":"research-data-management.html","id":"existing-frameworks","chapter":"2 Research Data Management","heading":"2.4 Existing Frameworks","text":"Data management live space alone. co-exists frameworks impact data managed important familiar provide foundation build data management structures.","code":""},{"path":"research-data-management.html","id":"fair","chapter":"2 Research Data Management","heading":"2.4.1 FAIR","text":"2016, FAIR Principles38 published Scientific Data, outlining four guiding principles scientific data management stewardship. principles created improve support reuse scholarly data, specifically ability machines access read data, foundation digital data publicly shared.39 principles :F: FindableAll data findable persistent identifier thorough, searchable metadata. move towards automation work life, need machine-readable data metadata becomes prevalent automatic discovery information.: AccessibleUsers able access data. can mean data available repository request system. minimum, user able access metadata, even actual data available.: InteroperableYour data metadata use standardized vocabularies well formats. humans machines able read interpret data. Software licenses pose barrier usage. Data available open formats can accessed software (ex: .csv, .txt, .dat).R: ReusableIn order provide context reuse data, metadata give insight data provenance, providing project description, overview data workflow, well authors cite appropriate attribution. also clear licensing data use.","code":""},{"path":"research-data-management.html","id":"seer","chapter":"2 Research Data Management","heading":"2.4.2 SEER","text":"addition FAIR principles, SEER principles, developed 2018 Institute Education Sciences (IES), provide Standards Excellence Education Research.40 principles broadly cover entire life cycle research study, provide context good data management within education research study. SEER principles include:Pre-register studiesMake findings, methods, data openIdentify interventions’ core componentsDocument treatment implementation contrastAnalyze interventions’ costsFocus meaningful outcomesFacilitate generalization study findingsSupport scaling promising results","code":""},{"path":"research-data-management.html","id":"open-science","chapter":"2 Research Data Management","heading":"2.4.3 Open Science","text":"concept Open Science pushed quality data management forefront, bringing visibility cause, well advances practices urgency implement . Open Science aims make scientific research dissemination accessible , making need good data management practices absolutely necessary. Open science advocates transparent reproducible practices means open data, open analysis, open materials, preregistration, open access.41 Organizations Center Open Science,42 become well-known proponents open science, offering open science framework (OSF)43 tool promote open science entire research life cycle. Furthermore, many education funders aligned fundee requirements open science practices, openly sharing study data pre-registration study methods.44","code":""},{"path":"research-data-management.html","id":"terminology","chapter":"2 Research Data Management","heading":"2.5 Terminology","text":"diving content training, think helpful cover terminology used data management. Many concepts education research multiple terms can used interchangeably. Across different institutions, researchers may use terms.","code":""},{"path":"research-data-management.html","id":"the-research-life-cycle","chapter":"2 Research Data Management","heading":"2.6 The Research Life Cycle","text":"remainder book organized chapters dive phases research data life cycle. imperative understand research life cycle order see flow data project, well see everything project connected. phases skipped, whole project suffer.can see image , throughout project, data management roles project coordination roles work parallel collaboratively. teams may made people different members, either way, workflows must happen must work together.\nFigure 2.1: research project life cycle\nLet’s walk chart.typical study first begin generating ideas, deciding want study., likely, look grant funding implement study. two paths begin diverge. team applying federal funding, proposal budget created project management track, supplemental required data management plan created data track. , may people working pieces.Next, grant awarded, project team begin planning things hiring, recruitment, data collection, implement intervention. time, working data team begin plan specifically implement 2-5 page data management plan submitted funder start putting necessary structures place.planning complete, team moves cycle data collection. called cycle study longitudinal, every step occur cyclically. one phase data collection wraps , team re-enters cycle next phase data collection, data collection complete entire project.\ndata management project management team begin cycle starting documentation. can see phase occurs collaboratively denoted double outline. teams begin developing documentation data dictionaries standard operating procedures.\ndocumentation started, teams collaboratively begin create necessary data collection instruments. instruments created input documentation. phase teams may also develop participant tracking database.\nNext, project management team moves data collection phase. addition actual data collection, may also involve preliminary activities recruitment consenting participants, well hiring training data collectors. point, data management team just provides support needed.\ndata collected, project team track data collected participant tracking database. data management team collaborate project management team help troubleshoot anything related actual tracking database issues discovered data tracking.\nNext, data collected, teams move data capture phase. teams actively retrieving converting data. electronic data may look like downloading data platform data sent team via secure transfer. physical data, may look like teams entering paper data database. Oftentimes, collaborative effort project management team data team.\ndata captured, needs stored. data team may charge setting monitoring storage efforts, project team may ones actively retrieving storing data.\nNext teams move cleaning validation phase. time data team reviewing data cleaning plans, writing data cleaning scripts, actively cleaning data recent data collection round.\nlast, data team version data updated errors found.\ndata management project management team begin cycle starting documentation. can see phase occurs collaboratively denoted double outline. teams begin developing documentation data dictionaries standard operating procedures.documentation started, teams collaboratively begin create necessary data collection instruments. instruments created input documentation. phase teams may also develop participant tracking database.Next, project management team moves data collection phase. addition actual data collection, may also involve preliminary activities recruitment consenting participants, well hiring training data collectors. point, data management team just provides support needed.data collected, project team track data collected participant tracking database. data management team collaborate project management team help troubleshoot anything related actual tracking database issues discovered data tracking.Next, data collected, teams move data capture phase. teams actively retrieving converting data. electronic data may look like downloading data platform data sent team via secure transfer. physical data, may look like teams entering paper data database. Oftentimes, collaborative effort project management team data team.data captured, needs stored. data team may charge setting monitoring storage efforts, project team may ones actively retrieving storing data.Next teams move cleaning validation phase. time data team reviewing data cleaning plans, writing data cleaning scripts, actively cleaning data recent data collection round.last, data team version data updated errors found.teams move active data collection phase data collection project complete. time project team begins analyzing study data working publications well final grant reports. able organized processes implemented data collection cycle. Since data managed cleaned throughout, data ready analysis soon data collection complete. , project team analyzing data, data team additional preparation archive data public sharing.Last, grant closing , team submits data public sharing.work remaining chapters book, chart guide navigating phase practices fits larger picture.","code":""},{"path":"data-structure.html","id":"data-structure","chapter":"3 Data Structure","heading":"3 Data Structure","text":"data management made just , data, need basic understanding data looks like. Understanding basic structure data helps us write Data Management Plan, organize data management process, create data dictionaries, build data collection tools, clean data, ways allow us analyzable data.","code":""},{"path":"data-structure.html","id":"basics-of-a-dataset","chapter":"3 Data Structure","heading":"3.1 Basics of a dataset","text":"education research, data often collected internally team using instrument questionnaire, observation, interview, assessment. However, data may also collected external entities, districts, states, agencies.data come many forms (ex: video, transcripts, documents, files), represented text, numbers, multimedia.45 world quantitative education research, often working digital data form dataset, structured collection data. datasets organized rectangular format allow data machine-readable. Even qualitative research, often wrangling data format analyzable allows categorization.rectangular (also called tabular) datasets made columns rows.\nFigure 3.1: Basic format dataset\n","code":""},{"path":"data-structure.html","id":"columns","chapter":"3 Data Structure","heading":"3.1.1 Columns","text":"columns dataset consist one following types variables:Variables collect (instrument external source)Variables create/add (ex: cohort, intervention, time, derivations)Unless data collected anonymously, every dataset must also following:One variables unique identifiers, sometimes called primary keys. variables uniquely define rows dataset (.e. help identify duplicate rows), also allow link data contain identifiers (example link student data).plan link datasets across entities (ex: link teachers schools students teachers) also need secondary unique identifiers dataset (also called foreign keys) allow link across datasets.talk creating identification variables data tracking section.","code":""},{"path":"data-structure.html","id":"column-attributes","chapter":"3 Data Structure","heading":"3.1.1.1 Column attributes","text":"important know variables following attributes:Unique names (variable name dataset can repeat). talk variable naming discuss style guides.measurement type (ex: numeric, character, date) can also narrowly defined needed (ex: continuous, categorical)Acceptable values (ex: yes/) expected ranges (ex: 1-25 2021-08-01 2021-12-15). Anything outside acceptable values ranges considered error.Labels, descriptions variable represents. may label variable creator assigns (ex: “Treatment condition”) may actual wording item (ex: “enjoy pizza?”).","code":""},{"path":"data-structure.html","id":"rows","chapter":"3 Data Structure","heading":"3.1.2 Rows","text":"rows dataset aligned participants cases data. Participants data may students, teachers, schools, locations, forth. unique identifier variable mentioned denote row belongs participant.","code":""},{"path":"data-structure.html","id":"cells","chapter":"3 Data Structure","heading":"3.1.3 Cells","text":"cells observations associated participant. Cells made key/value pairs, created intersection column row. Consider example collect survey students. dataset, row made unique student study, column item survey, cell contains value/observation corresponds row/column pair (participant question).\nFigure 2.1: Representation cell value\n","code":""},{"path":"data-structure.html","id":"dataset-organization-rules","chapter":"3 Data Structure","heading":"3.2 Dataset organization rules","text":"order dataset machine-readable analyzable, adhere set structural rules.46The first rule data make rectangle. first row data variable names (use one row ). remaining data made values cells.\nFigure 3.2: comparison non-rectangular rectangular data\ncolumns adhere variable type.\nexample, numeric variable, age, add cell value text, variable longer adheres variable type. Machines now read variable text.\nexample, numeric variable, age, add cell value text, variable longer adheres variable type. Machines now read variable text.\nFigure 3.3: comparison variables adhering adhering data type\nvariable collect one piece information. variable contains one piece information may following issues:\nlose granularity information (ex: location = Los Angeles, CA less granular city variable state variable separately)\nvariable may become unanalyzable (ex: variable value 220/335 analyzable numeric variable). interested rate, can calculate rate variable value .657.\nmay lose variable type (ex: want incident_rate variable numeric, assign value 220/335, variable longer numeric)\nlose granularity information (ex: location = Los Angeles, CA less granular city variable state variable separately)variable may become unanalyzable (ex: variable value 220/335 analyzable numeric variable). interested rate, can calculate rate variable value .657.may lose variable type (ex: want incident_rate variable numeric, assign value 220/335, variable longer numeric)\nFigure 3.4: comparison two things measured one variable two things measured across two variables\ncell values explicit. means cells filled physical value.\ncells empty\nvalue actually missing, make sure contains value denote missing data (ex: NA) show cell left blank unintentionally\ncell left empty “implied” value , cells filled actual data\nvalue cell “implied” 0, fill cells 0\n\ncells empty\nvalue actually missing, make sure contains value denote missing data (ex: NA) show cell left blank unintentionally\ncell left empty “implied” value , cells filled actual data\nvalue cell “implied” 0, fill cells 0\nvalue actually missing, make sure contains value denote missing data (ex: NA) show cell left blank unintentionallyIf cell left empty “implied” value , cells filled actual dataIf value cell “implied” 0, fill cells 0\nFigure 3.5: comparison variables empty cells variables empty cells\nvalues implied using color coding\nwant indicate information, add indicator variable rather cell coloring\nwant indicate information, add indicator variable rather cell coloring\nFigure 3.6: comparison variables implicit values variables explicit values\ndata contain duplicate rows. want duplicate rows measurement collected participant, time period. Different types duplicate rows can occur:\ntrue duplicate row entire row duplicated (row values every variable). may happen someone enters form twice.\nunique identifier duplicated row values may may across variables. happen one three reasons:\ninstrument accidentally collected participant collection period. type duplicate need remedied.\nunique identifier entered incorrectly. case don’t actually duplicate, just incorrect unique identifier. error need remedied.\none variable used identify unique participants row actually duplicate.\nTake example student id class id. Multiple unique identifiers may used data collected participants multiple locations treated unique data. case, data truly duplicate combined identifiers unique.\nAnother example data organized long format (discussed ). case unique study identifiers may repeat data repeat form time period data.\n\n\ntrue duplicate row entire row duplicated (row values every variable). may happen someone enters form twice.unique identifier duplicated row values may may across variables. happen one three reasons:\ninstrument accidentally collected participant collection period. type duplicate need remedied.\nunique identifier entered incorrectly. case don’t actually duplicate, just incorrect unique identifier. error need remedied.\none variable used identify unique participants row actually duplicate.\nTake example student id class id. Multiple unique identifiers may used data collected participants multiple locations treated unique data. case, data truly duplicate combined identifiers unique.\nAnother example data organized long format (discussed ). case unique study identifiers may repeat data repeat form time period data.\n\ninstrument accidentally collected participant collection period. type duplicate need remedied.unique identifier entered incorrectly. case don’t actually duplicate, just incorrect unique identifier. error need remedied.one variable used identify unique participants row actually duplicate.\nTake example student id class id. Multiple unique identifiers may used data collected participants multiple locations treated unique data. case, data truly duplicate combined identifiers unique.\nAnother example data organized long format (discussed ). case unique study identifiers may repeat data repeat form time period data.\nTake example student id class id. Multiple unique identifiers may used data collected participants multiple locations treated unique data. case, data truly duplicate combined identifiers unique.Another example data organized long format (discussed ). case unique study identifiers may repeat data repeat form time period data.\nFigure 3.7: comparison data duplicate cases data duplicate cases\n","code":""},{"path":"data-structure.html","id":"linking-data","chapter":"3 Data Structure","heading":"3.3 Linking data","text":"now talking one, standalone dataset. However, likely research project made multiple datasets, collected different participants, variety instruments, possibly across different time points. point likely need link datasets together.order think link data, need discuss two things: data structure database design.","code":""},{"path":"data-structure.html","id":"database-design","chapter":"3 Data Structure","heading":"3.3.1 Database design","text":"database “organized collection data stored multiple datasets.”47 Sometimes database actually housed database software system (SQLite FileMaker), times loosely using term database simply define linking disparate datasets together stored individually file system. matter storage system, general concepts applicable.database terminology, dataset considered “table”. table primary key identifies unique entries within table table can connected primary foreign keys. linking tables creates relational database talk structure discuss participant data tracking.Let’s take simplest example, primary keys data. collected two pieces data students (survey assessment) one time period. image shows variables collected instrument table can linked together primary key (circled yellow).\nFigure 3.8: Linking data primary keys\nHowever, often collecting data across different forms, also collecting nested data across different participants (ex: students, nested classrooms, nested schools, ). Let’s take another example collected data three instruments, student assessment, teacher survey, school intake form. image shows variables exist dataset (primary keys still circled yellow) table can linked together foreign key (circled blue).\nFigure 3.9: Linking data foreign keys\ncan imagine, add forms, begin collect data across time, database structure begins become even complex. another example collected two forms students (survey assessment), two forms teachers (survey observation), one form schools (intake form). linking structure begins look complex, see can still link data primary foreign keys. Forms within participants can linked primary keys, forms across participants can linked foreign keys.\nFigure 3.10: Linking data primary foreign keys\n","code":""},{"path":"data-structure.html","id":"structure","chapter":"3 Data Structure","heading":"3.3.2 Data structure","text":"comes time link data, two ways often think linking structuring data, wide long.Wide formatWhen structure data wide format, data collected unique participant one row. Participants duplicated data format.type format can used following situations:link forms within timeTo link forms across timeTo link forms across participantsThe easiest scenario think format repeated measure data. collect survey participants wave 1 2, waves data row (joined together unique ID) wave data collection appended variable name create unique variable names. dive deeper different types joins data cleaning section.Limitations: important note , data unique identifiers (primary /foreign keys), unable merge data wide format.\nFigure 3.11: Data structured wide format\nLong formatIn education research, long data mostly used specific way structure data collected time. long data participant can repeat dataset., straight forward way think repeated measure data, row new time point participant. instead merging forms unique id, stack forms top , often called appending data. Rows stacked top one another variables aligned variable name. Now instead linking data id, data now “linked” variable names. important variable names types stay identical time order structure work.scenario, longer add data collection wave variable names. However, need add time period variable denote wave associated row data.\nFigure 3.12: Data structured long format\nChoosing wide vs longThere different reasons constructing data one way another. may store share data one format, restructure data another format comes time analysis.Storing data long format usually considered efficient, potentially requiring less memory. However, comes time analysis, specific data structures may required. example, repeated measure procedures typically require data wide format, unit analysis subject. mixed model procedures typically required data long format, unit analysis measurement subject.48 review decision making around data structure data cleaning chapter.","code":""},{"path":"data-structure.html","id":"file-types","chapter":"3 Data Structure","heading":"3.4 File types","text":"rectangular datasets can saved variety file types. common file types education research include interoperable formats .csv, .txt, .dat, .tsv, proprietary formats .xlsx, .sav, .dta.save files, file size. number columns well number rows dataset contribute file size. Just get feel size files might , small datasets (example 5 columns <100 rows) may less 100 KB. Datasets several hundred variables several thousand cases may start 1,000-5,000 KB range. type file use also changes size data. Saving data format contains embedded metadata (variable value labels), .sav file, greatly increase file size. talk pros cons different file formats chapter data sharing.","code":""},{"path":"dmp.html","id":"dmp","chapter":"4 Data Management Plan","heading":"4 Data Management Plan","text":"\nFigure 3.1: Data management plan research project life cycle\n","code":""},{"path":"dmp.html","id":"history-and-purpose","chapter":"4 Data Management Plan","heading":"4.1 History and purpose","text":"Since 2013, even earlier National Science Foundation, federal agencies education researchers work required data management plan (DMP) part funding application. focus plans mostly future outcome data sharing, data management plan means ensuring researchers thoughtfully plan research study result data can shared confidence, free errors, uncertainty, violations confidentiality. President Obama’s May 2013 Executive Order declared “default state new modernized government information resources shall open machine readable.”49 August 2022, Office Science Technology Policy (OSTP) doubled data sharing policy issued memorandum stating federal agencies must update public access policies later December 31, 2025, make federally funded publications supporting data accessible public embargo release.50 Even sooner , organizations like National Institutes Health mandated grant applicants, beginning January 2023, must submit plan managing sharing project data51.","code":""},{"path":"dmp.html","id":"why-are-dmps-important","chapter":"4 Data Management Plan","heading":"4.1.1 Why are DMPs important?","text":"Funding agencies see DMPs important maximizing scientific outputs investments increasing transparency. Mandating data sharing federally funded projects leads many benefits including accelerating discovery, greater collaboration, building trust among data creators users. addition benefits viewed funders, intrinsic benefits come write data management plan. thoughtfully plan transparency plan leads better data management. Knowing eventually sharing data documentation others outside team can motivate researchers think hard organize data management practices way produce data trust share outside world52.","code":""},{"path":"dmp.html","id":"what-is-it","chapter":"4 Data Management Plan","heading":"4.2 What is it?","text":"Generally, data management plan supplemental 2-5 page document, submitted grant application, contains details plan store, manage, share research data products. funders DMPs part scoring process, reviewed panel program officer. funders may provide feedback ask revisions believe plan /budget associated costs adequate.","code":""},{"path":"dmp.html","id":"what-to-include","chapter":"4 Data Management Plan","heading":"4.2.1 What to include?","text":"include DMP varies across funding agencies. check funding agency’s site specific DMP requirements, typically 10 common categories covered data management plan53 . categories :Roles responsibilities\nstaff roles management long-term preservation data?\nensures accessibility, reliability, quality data?\nplan core team member leaves project institution?\nstaff roles management long-term preservation data?ensures accessibility, reliability, quality data?plan core team member leaves project institution?Types data\ndata captured? (Ex: surveys, assessments, observations)\ndata item-level summary scores?\nshare raw data clean data?\nexpected number files? Expected number rows file?\ndata captured? (Ex: surveys, assessments, observations)data item-level summary scores?share raw data clean data?expected number files? Expected number rows file?Format data\ndata electronic format?\nprovided non-proprietary format? (Ex: csv)\none format provided? (Ex: sav csv)\ntools needed manipulate shared data?\ndata electronic format?provided non-proprietary format? (Ex: csv)one format provided? (Ex: sav csv)tools needed manipulate shared data?Documentation\nmetadata create? (Consider project level, dataset level variable level metadata)\nformat documentation ? (Ex: xml, csv, pdf)\ndocumentation plan include sharing data? (Ex: code, data collection instruments, protocols)\nmetadata create? (Consider project level, dataset level variable level metadata)format documentation ? (Ex: xml, csv, pdf)documentation plan include sharing data? (Ex: code, data collection instruments, protocols)Standards\ndata documentation standards used? (Ex: DDI)\ndata documentation standards used? (Ex: DDI)Method data sharing\nshare data? (Ex: Institutional archive, data repository, PI website)\ndata restricted data enclave required?\ndata use agreement required?\nlicense data?\ndata persistent unique identifiers?\nshare data? (Ex: Institutional archive, data repository, PI website)data restricted data enclave required?data use agreement required?license data?data persistent unique identifiers?Circumstances preventing data sharing\ndata covered FERPA/HIPAA doesn’t allow data sharing?\nwork partners allow share data? (Ex: School districts, tribal regulations)\nworking proprietary data?\ndata covered FERPA/HIPAA doesn’t allow data sharing?work partners allow share data? (Ex: School districts, tribal regulations)working proprietary data?Privacy rights participants\nprevent disclosure personally identifiable information share data? anonymize data (applicable)?\nparticipants sign informed consent agreements? consent communicate participant data expected used shared?\nprevent disclosure personally identifiable information share data? anonymize data (applicable)?participants sign informed consent agreements? consent communicate participant data expected used shared?Data security\nmaintain participant privacy confidentiality project?\nprevent unauthorized access data?\nConsider IRB requirements .\nmaintain participant privacy confidentiality project?prevent unauthorized access data?Consider IRB requirements .Schedule data sharing\nshare study data long?\nshare study data long?Pre-registration (less commonly required)\npre-register study?\npre-register study?, specifics included category vary funder. sites visit learn four common federal education research funder DMP requirements.Institute Education Sciences54National Institutes Health55National Institute Justice56National Science Foundation57","code":""},{"path":"dmp.html","id":"getting-help","chapter":"4 Data Management Plan","heading":"4.3 Getting help","text":"Since DMPs written project funded, therefore additional staff members may hired, oftentimes investigators developing grant proposal ones write DMP. However, constructing DMP well worth time enlist help. existing data manager data team, certainly want consult writing plan ensure decisions feasible. work university system, research data librarians also excellent resources wealth knowledge writing comprehensive data management plans. last, plan share final data repository institutional archive want contact repository writing plan well. repository may requirements data must shared helpful outline guidelines data management plan time submission. can also specifically write name repository data management plan well. Last, may want obtain help colleagues. colleagues likely written DMPs many people willing share plans way help others better understand include.DMP living document can always update plan project completion. may helpful keep contact program officer regarding potential changes throughout project.looking guidance writing DMP, variety generic DMP templates different federal agencies available, well actual copies submitted DMPs researchers graciously make publicly available example purposes.","code":""},{"path":"dmp.html","id":"budgeting","chapter":"4 Data Management Plan","heading":"4.4 Budgeting","text":"briefly mention , funding agencies acknowledge costs associated implementing data management plan allow explain costs budget narrative. Costs associated entire data life cycle considered may include data management personnel costs, fees, infrastructure, tools needed organize, document, store, share study data.61 Make sure review funder’s documentation information allowable costs62. Examples potential allowable costs include:63Costs associated curating de-identifying dataCosts associated developing data documentationFees associated depositing data long-term sharing repositoryIt can difficult estimate costs everything associated vast landscape managing data. Luckily organizations developed resources aid estimating costs. UK Data Service64, University Twente65, Utrecht University66, DataOne67 put together checklists help think various potential data management costs.","code":""},{"path":"plan.html","id":"plan","chapter":"5 Planning Data Management","heading":"5 Planning Data Management","text":"\nFigure 3.1: Planning research project life cycle\nPlanning data management distinct 2-5 page data management plan (DMP) discussed previous chapter. spending weeks, maybe months, meeting regularly team gathering information develop detailed instructions plan manage data according DMP. data management planning happens time project team planning project implementation (things like collect data, hire staff, supplies needed, recruit participants, communicate sites, etc). Team members PIs, project coordinators, data managers, may assisting planning processes.","code":""},{"path":"plan.html","id":"why-spend-time-on-planning","chapter":"5 Planning Data Management","heading":"5.1 Why spend time on planning?","text":"Funder required data management plans hopeful outlines future practices. However, broad theory behind DMPs actually prepare us complex implementation plans practice68. Therefore, important spend time, project begins, planning preparing data management. upfront time investment sort slow science leads better data outcomes. Reproducibility begins planning phase. Taking time create, document, train staff data management standards project begins helps ensure processes implemented fidelity can replicated consistently throughout entire study.Planning day day management project data many benefits well. allows anticipate overcome barriers managing data, communication issues, training needs, potential tool issues. type planning also saves time long run, removing last minute scrambling can occur trying organize data end project. Last, type planning can mitigate errors. Viewing errors problems created poorly planned workflows, rather individual failures, helps us see data management planning can lead better data69. data management planning can remove chances errors creeping data70, can certainly reduce errors prevent “compounding time”(Alston & Rick, 2021, p.4).71","code":""},{"path":"plan.html","id":"goals-of-planning","chapter":"5 Planning Data Management","heading":"5.2 Goals of planning","text":"planning phase include series regular meetings core decision makers. many aspects research study plan also occur time (ex: planning intervention, planning analyses), focusing planning data management (including data collection). likely want PI/Co-PIs attendance along core project staff data management team. planning time, several goals keep mind.finalize project goals laid grant proposal (.e. data collected)finalize timeline goals (.e. data collected)lay specific tasks needed accomplish goals (.e. data collected, stored, managed)assign roles responsibilities (.e. responsible tasks)make decisions around task management communication (.e. tasks monitored communication tracked)Make sure come every meeting agenda stay track take detailed notes. notes basis creating documentation next phase. meeting notes can stored central location planning folder notes ordered date running document.end planning period, team clear plan project goals , goals accomplished, goals accomplished, charge completing tasks associated goals, additional resources needed accomplish goals.","code":""},{"path":"plan.html","id":"checklist","chapter":"5 Planning Data Management","heading":"5.3 Planning checklists","text":"Along existing data management plan, checklists great tools help guide discussions work planning process team. sample checklists, one phase research cycle. checklists can added amended brought planning meetings help team think various data management decisions need made phase research project.Roles Responsibilities72Task Management73Documentation74Data Collection75Data Tracking76Data Capture77Data Storage Security78Data Cleaning79Data Sharing80","code":""},{"path":"plan.html","id":"decision-making-process","chapter":"5 Planning Data Management","heading":"5.3.1 Decision-making process","text":"move remaining chapters book, begin learn recommended practices phase research cycle. Going checklist , can start fill practices work project phase study.decision-making process personalized. Borghi Van Gulick81 view process series steps research team chooses, many possibilities chosen. Maybe won’t always able implement “best practices” can decide good enough team based motivations, incentives, needs, resources, skill set, rules regulations.example, one team may collect survey data paper participants young children, hand enter Excel tool access , double enter 20% don’t capacity enter . Another team may collect paper data collecting data field, hand enter data FileMaker tool team familiar , double enter 100% budget capacity .simplified example decision making process, based Borghi Van Gulick82 flow chart. course real life often choosing many just two options!\nFigure 2.1: simplified decision-making process\n","code":""},{"path":"plan.html","id":"checklist-considerations","chapter":"5 Planning Data Management","heading":"5.3.2 Checklist considerations","text":"’s important consider team project unique work planning checklists. technique might work well one team, may work well another. Make sure consider following:external requirements\npractices align plan laid DMP? , may need revise DMP match new decisions - remember DMP living document.\npractices meet external compliance requirements Institutional Review Board, institutional policies, project partner requirements, government mandates?\npractices align plan laid DMP? , may need revise DMP match new decisions - remember DMP living document.practices meet external compliance requirements Institutional Review Board, institutional policies, project partner requirements, government mandates?skill set team\nskill set team align practices plan implement? additional training required?\nskill set team align practices plan implement? additional training required?available tools\ntools available team?\norganization allow use certain platforms data storage?\ncomplexity tools? additional training needed?\ntools available team?organization allow use certain platforms data storage?complexity tools? additional training needed?budget\nbudget implement practices want implement need plan something feasible?\nbudget implement practices want implement need plan something feasible?Complexity project\nsize project, amount types data collecting, number participants populations collecting data , sensitivity level data collecting, number sites collecting data , number partners decision makers working , factor data management planning\nsize project, amount types data collecting, number participants populations collecting data , sensitivity level data collecting, number sites collecting data , number partners decision makers working , factor data management planningShared investment\nentire team invested quality data management?\nentire team motivated adhere standards instructions laid data management planning? , safeguards can implement help prevent errors creeping data?\nentire team invested quality data management?entire team motivated adhere standards instructions laid data management planning? , safeguards can implement help prevent errors creeping data?","code":""},{"path":"plan.html","id":"data-management-workflow","chapter":"5 Planning Data Management","heading":"5.4 Data management workflow","text":"last step planning phase build workflows. Workflows allow data management seamlessly integrated data collection process. Often illustrated flow diagram, workflow series repeatable tasks help move stages research life cycle “organized efficient manner”83. walk checklists, can begin enter decisions workflow diagram show actionable steps data management process. order steps follow general order data management life cycle (specifically data collection cycle). want workflow diagram every piece data collect. example, collect following three items , three workflow diagrams.Student online surveyStudent paper assessmentStudent district level administrative dataYour diagrams include , , , task process. Adding details make process actionable.84 diagram can displayed format works can simple detailed want . template like one works well thinking high level workflows. Remember, repeatable process. diagram linear (steps laid chronological order expect happen), process repeated every time collect piece data.\nFigure 3.2: simple workflow template\nmight complete diagram student survey.\nFigure 3.3: Example student survey workflow\nformat truly matter. diagram student survey workflow , detailed added, time using swimlane template instead, lane displays tasks associated individual iterative processes occur within across lanes.\nFigure 3.4: Example student survey workflow using swimlane template\nworking data collection timeline already created, can even build time workflow. another example survey workflow , time displayed using Gantt chart85 order better capture expected timeline.workflow diagrams excellent high level views process , can see unable put fine details visual. last step creating workflow put steps standard operating procedure (SOP). SOP add necessary details process. can also attach diagram addendum link SOPs diagrams ways reference. talk creating SOPs chapter documentation.","code":""},{"path":"plan.html","id":"benefits-to-visualizing-a-workflow","chapter":"5 Planning Data Management","heading":"5.4.1 Benefits to visualizing a workflow","text":"Visualizing decisions diagram format many benefits. First, allows team conceptualize specific tasks process, timing tasks occur, dependencies associated tasks. also allows team see roles responsibilities fit larger research process86. Showing data management integrated larger research workflow can help team members view data management part daily routine, rather “extra work”87. last, reviewing workflows team allowing members provide feedback may help create buy-data management processes, potentially leading better adherence practices.","code":""},{"path":"plan.html","id":"workflow-considerations","chapter":"5 Planning Data Management","heading":"5.4.2 Workflow considerations","text":"Similar questions need consider reviewing planning checklists, also need evaluate following things developing personalized workflow.flow preserve integrity data? point might lose comprise data?88Is point flow data handled securely? Someone gains access identifiable information access?flow accordance compliance requirements (IRB, FERPA, HIPAA, Institutional Data Policies, etc.)?flow feasible team (based size, skill level, motivation, etc.)?flow feasible budget available resources?flow feasible amount types data collecting?bottlenecks workflow? Areas resources training needed? areas tasks re-directed?","code":""},{"path":"plan.html","id":"task-management-systems","chapter":"5 Planning Data Management","heading":"5.5 Task management systems","text":"tools checklists, workflow diagrams, SOPs allow us document share processes, can tricky manage day day implementation processes. planning phase great time choose task management system89. Keeping track various deadlines communications across scattered sources can overwhelming using task management system may help remove ambiguity status task progress. Rather regularly check via email status updates reading various meeting notes learn decisions made, task management system allows assign tasks responsible parties, set deadlines based timelines, track progress, capture communication decisions one location.many existing tools allow teams assign track tasks, schedule meetings, track project timelines, document communication. Without endorsing particular product, project/task management tools know education research teams used include:TrelloSmartsheetTodoistMicrosoft PlannerNotionBasecampConfluenceAsanaOf course, processes ’ve discussed far, task management system useful team trained use , invested using , actually uses part daily routine. make sure consider choose tool, , right .","code":""},{"path":"roles.html","id":"roles","chapter":"6 Project Roles and Responsibilities","heading":"6 Project Roles and Responsibilities","text":"\nFigure 3.1: Planning research project life cycle\nPart DMP planning data management phase, noted previous chapters, include assigning roles responsibilities. terms data management, important assign document roles, just presume roles90 many reasons including security data, continuity practices, standardization workflows.","code":""},{"path":"roles.html","id":"typical-roles-in-a-research-project","chapter":"6 Project Roles and Responsibilities","heading":"6.1 Typical roles in a research project","text":"diving assign document roles project, important get understanding typical roles education research project team. team may lucky enough (multiple ) roles. times, just one person, Principal Investigator (PI), may take multiple roles. said, budget allows , highly recommend hiring individuals fill roles mentioned allow team members specialize excel area expertise. learning aspects project highly recommended create cohesive team works collaboratively, team members take many project roles can spread thin project goals may suffer.","code":""},{"path":"roles.html","id":"pi-and-co-pi","chapter":"6 Project Roles and Responsibilities","heading":"6.1.1 PI and Co-PI","text":"PIs (project directors), well Co-PIs, individuals prepare submit grant proposal responsible administration grant. often one PI project including least someone content area knowledge well methodologist. PIs Co-PIs varying levels involvement research projects typically, always, hands day day administration. Even tasks delegated research staff, PIs Co-PIs ultimately responsible Institutional Review Board (IRB) submissions meeting IRB requirements, well submitting MOUs, budgets, effort reporting, continuing review reports, final technical finding reports.","code":""},{"path":"roles.html","id":"project-coordinator","chapter":"6 Project Roles and Responsibilities","heading":"6.1.2 Project Coordinator","text":"project coordinator (project manager) essential member research team. name implies, person typically coordinates research activities ensures compliance agencies Institutional Review Board. Tasks may oversee include recruitment consenting participants, creation data collection materials, creation protocols, training data collectors, data collection scheduling, . project coordinator may also supervise many research team roles, research assistants.","code":""},{"path":"roles.html","id":"data-manager","chapter":"6 Project Roles and Responsibilities","heading":"6.1.3 Data Manager","text":"data manager also essential member team. person responsible organizing, cleaning, documenting, storing, dissemination research project data. team member works closely project coordinator, well PI, ensure data management considered throughout project life cycle. Tasks data manager may oversee include data storage, security access, building data collection tracking tools, cleaning validating data, data documentation, organizing data sharing purposes.role vital maintaining standardization data practices. budget hire full-time data manager, make sure assign someone team oversee flow data, ensuring throughout project, data documented, collected, entered, cleaned stored consistently securely.","code":""},{"path":"roles.html","id":"project-team-members","chapter":"6 Project Roles and Responsibilities","heading":"6.1.4 Project Team Members","text":"role refers staff hired help implement research project may include full-time staff members, titles research project assistants instance, may include part-time graduate students. Project team members typically field, collecting data, may also assist areas preparing data collection materials assisting data management. Senior project team members may also assist implementing training acting data collection leads field.","code":""},{"path":"roles.html","id":"other-roles","chapter":"6 Project Roles and Responsibilities","heading":"6.1.5 Other Roles","text":"size research team roles exist dependent factors funding, type research study, intervention studied, organization specific research institution. teams may include additional roles, mentioned , research director, lab manager, software engineer, database manager, postdoc, analyst, statistician, administrative professional, hourly data collector, outreach coordinator, coach/interventionist, may assist research cycle ways. roles assist research data life cycle seen diagram . may path hidden diagram still happening, behind scenes, alongside process. Take instance, role coach implementing intervention studied. tasks aren’t shown original diagram work happening alongside data collection cycle.\nFigure 2.1: Life cycle diagram updated show hidden processes\n","code":""},{"path":"roles.html","id":"goals-of-assigning-roles-and-responsibilities","chapter":"6 Project Roles and Responsibilities","heading":"6.2 Goals of Assigning Roles and Responsibilities","text":"several goals assigning roles responsibilities.91Appoint specific team members project roles delineate responsibilities rolesAssess equity responsibilities\nIncluding time needed complete tasks number responsibilities assigned team member (overloading one team member)\nIncluding time needed complete tasks number responsibilities assigned team member (overloading one team member)Assess skills needed responsibilitiesAssess training need fill gaps knowledgeEstimate costs associated rolesDevelop contingency plans\ntransitions role absenteeism\ntransitions role absenteeismEarly project start generally assign roles data management plan. Remember often required state responsible tasks data integrity security. , project funded start better idea goals budget, can flesh details roles. planning phase, using tools planning checklists help think specific responsibilities tasks associated role.","code":""},{"path":"roles.html","id":"assigning-roles-and-responsibilities","chapter":"6 Project Roles and Responsibilities","heading":"6.3 Assigning roles and responsibilities","text":"assigning roles responsibilities, several factors consider.Required skillsetIn assigning roles responsibilities, make sure consider skills needed successful position. example, considering role data manager responsibilities associated role, may look skill sets following buckets:Interpersonal skills (Detail oriented, organized, good communicator)Domain skills (Experience working education data, understands data privacy - FERPA, HIPAA)Technical skills (Understanding database structure, experience building data pipelines, coding experience, specific software/tool experience)specific skills needed role depend project needs well skill sets members team.Training needsIn addition considering skills needed certain roles, also consider training needed fulfill assigned responsibilities. roles work data, training may include mandated courses program like Collaborative Institutional Training Initiative (CITI) may signing training use specific tool software. Make sure team members well-equipped perform responsibilities project begins.Estimate costsIf working roles responsibilities grant funded, grant budget already submitted. However, can still helpful thinking costs associated overall roles (based experience/skillset person filling role) even broken associated responsibilities (based things like percent effort time complete task). discrepancies original budget updated costs found, often funders allow PIs amend budgets.Contingency plansYou also beging thinking backup plans staff member leave project absent extended period time. may include cross training staff plan training replacement staff.","code":""},{"path":"roles.html","id":"roledoc","chapter":"6 Project Roles and Responsibilities","heading":"6.4 Documenting roles and responsibilities","text":"roles responsibilities assigned, decisions documented avoid ambiguity . documentation topic covered next chapter, think helpful break rules discuss just one document covering topic assigning roles.general roles responsibilities document one way document decisions.92 addition planning document can help assign tasks appropriate staff member, can also serve reference document allows team easily see project team, roles play, contact questions regarding various project aspects (example - contact data storage access).document can laid format conveys information clearly team. two example templates. Note templates list overarching responsibilities, specific tasks. Specific actionable steps laid process documentation standard operating procedures names attached task.\nFigure 3.2: Roles responsibilities document organized role\n\nFigure 3.3: Roles responsibilities document organized phase\nReviewing roles responsibilities format like allows start see responsibilities assigned decide tasks need redistributed way. can also start fill details needed.Since one template creating roles responsibility document, can really add whatever information helps clearly convey information. additional columns may consider adding include:Links related standard operating procedures (ex: building participant tracking database may link specific SOP lays steps building tool)Names staff members () assist also contribute responsibilityTiming responsibility (ex: weekly, ongoing, month February)","code":""},{"path":"roles.html","id":"data-management-role","chapter":"6 Project Roles and Responsibilities","heading":"6.5 Data Management Role","text":"Like mentioned earlier, highly recommend hiring full-time data manager able budget allows team member narrow responsibilities implement tasks better precision. However, everyone capacity . , vitally important still assign data management responsibilities specific team members. choosing assign tasks , want consider several things appropriate skill set manage data, interest data management tasks, time commit data management. Oftentimes responsibility falls full-time project coordinator ones intimately familiar data, since full-time, able carve hours data management tasks. times may collaboration project coordinator another staff member, part-time graduate student (may technical skills terms data wrangling). matter assign roles , just ensure documented information disseminated team.","code":""},{"path":"documentation.html","id":"documentation","chapter":"7 Documentation","heading":"7 Documentation","text":"\nFigure 3.1: Data documentation research project life cycle\nDocumentation collection files contain procedural descriptive information team, project, workflows, data. Collecting thorough documentation study unequivocally important collecting data. Documentation serves many purposes including:Standardizing proceduresSecuring data protecting confidentialityTracking data provenanceDiscovering errorsEnabling reproducibilityEnsuring others use interpret data accuratelyProviding searchability metadataWe going cover four levels documents chapter: team level, project level, dataset level, variable level. documentation discuss fall within documentation phase research life cycle, documents created earlier later timing discussed section. project, actively using documents, format documents matter. Choose format human-readable works well team (ex: Word, PDF, plain text file, Google Doc, Excel, HTML, OneNote, etc.). projects closing preparing share data, can consider, time, best make documents sustainable, interoperable, searchable. See chapter data sharing information.documents recommended help successfully run project. can choose create many documents wish. choose documents create based best project team, well required funder (see Data Management Plan), governing bodies Institutional Review Board. matter documents choose implement, important template documents implement consistently within, even across projects. Implementing documentation using templates, consistent formats fields, reduces duplication efforts (need reinvent wheel) allows team easily interpret document.Creating maintaining documents investment (make sure account time proposal budget), return investment well worth effort. documents best created team member directly oversees process sometimes may include collaborative effort (example project coordinator data manager may build documents together).review documents, remember every single one mentioned living document updated procedures change new information received. seen cyclical section diagram , team members revisit documentation time new data collected, often needed. changes made added documentation long periods time, find longer remember happened information lost. also important version documents along way staff know working recent version can see documents updated .","code":""},{"path":"documentation.html","id":"team-level","chapter":"7 Documentation","heading":"7.1 Team Level","text":"Team level data documentation typically contain data governance rules apply entire team, across projects. documents can amended time, really started long apply grant, lab, center, institution formed.\nFigure 2.1: Team level documentation research project life cycle\n","code":""},{"path":"documentation.html","id":"lab-manual","chapter":"7 Documentation","heading":"7.1.1 Lab Manual","text":"One example team level document lab manual, team handbook. lab manual creates common knowledge across team.93 provides staff consistent information team works things . sets expectations, provides guidelines, can even place passing along helpful career advice.94 lab manual mostly consist administrative, procedural, interpersonal types information, can helpful also include data management content well, including general rules access, store, share, work data securely ethically.Example lab manuals","code":""},{"path":"documentation.html","id":"wiki","chapter":"7 Documentation","heading":"7.1.2 Wiki","text":"Another option can either created alongside lab manual alternative lab manual team wiki. wiki webpage allows users collaboratively edit manage content. can created housed many tools SharePoint, Teams, Notion, GitHub, OSF, . lab wikis public (’ll see examples ), can restricted invited users. great way keep disparate documents pieces information, administrative data related purposes, organized central, accessible location. wiki can include links important documents, can also add text directly wiki describe certain procedures. Rather sending team members multiple different folders frequently requested information, can refer one wiki page.\nFigure 3.2: Example team wiki links frequently requested information\n* Note: Project level wikis can also created useful centralizing frequently referenced information pertaining specific projects.Example wikis","code":""},{"path":"documentation.html","id":"onboardingoffboarding","chapter":"7 Documentation","heading":"7.1.3 Onboarding/Offboarding","text":"onboarding checklists mostly consist non-data related, administrative information sign email get set laptop, also contain several data specific pieces information get new staff generally acclimated working data, project, new role.Similarly, offboarding checklists contain lot procedural information returning equipment forth, also contain basic data tasks help maintain data integrity security.Data related topics consider adding onboarding offboarding checklists included .\nFigure 3.3: Sample data topics add onboarding offboarding checklists\n","code":""},{"path":"documentation.html","id":"data-use-agreement","chapter":"7 Documentation","heading":"7.1.4 Data Use Agreement","text":"Typically think data use agreement (DUA) think document draft conjunction external partner like access data (want access ). usually covers terms someone allowed use data, considering things like access controls, research participant privacy, data destruction rules, .101 However, can really helpful document terms conditions data use staff, minimum, review even sign internal statement saying reviewed team policies regarding working securely data.102 rules working data can added lab manual, many people , can added separate data use agreement staff members can sign check box acknowledging read understand policies.Ideas content include DUA included .\nFigure 3.4: Example content include internal data use agreement\n","code":""},{"path":"documentation.html","id":"styleshort","chapter":"7 Documentation","heading":"7.1.5 Style Guide","text":"style guide set standards formatting information.103 improves consistency within across files projects. document includes conventions procedures variable naming, variable value coding, file naming, versioning, file structure, even coding practices. can created one large document separate files type procedure. highly recommend applying style guide consistently across projects, hence included team documentation. Since style guides important, many recommended practices cover, given document chapter. See chapter style guides information.Example style guides","code":""},{"path":"documentation.html","id":"project-level","chapter":"7 Documentation","heading":"7.2 Project Level","text":"Project level documentation descriptive information project contained, well planning decisions process documentation specifically related project. , documents created documentation phase, documents DMP (started project funded), checklists meeting notes (started planning phase), CONSORT diagram (started data collected) begin points throughout cycle.","code":""},{"path":"documentation.html","id":"data-management-plan","chapter":"7 Documentation","heading":"7.2.1 Data Management Plan","text":"first project level document created research project life cycle. See Data Management Plan review details document. note mention DMP can continue modified throughout entire study. major changes made, may helpful reach program officer keep loop well.","code":""},{"path":"documentation.html","id":"checklists-and-meeting-notes","chapter":"7 Documentation","heading":"7.2.2 Checklists and meeting notes","text":"Since ’ve already discussed documents previous chapter won’t say much acknowledge documents also part portfolio documentation really key planning documents start build project well data variable level documents.","code":""},{"path":"documentation.html","id":"roles-and-responsibilites-document","chapter":"7 Documentation","heading":"7.2.3 Roles and responsibilites document","text":"Using checklists planning phase, hopefully decided assigned roles responsibilities project. Now time formally document decisions way can share others. previous chapter reviewed ways structure document. document created, make sure store central location easy referral update document needed.Example roles responsibilities","code":""},{"path":"documentation.html","id":"research-protocol","chapter":"7 Documentation","heading":"7.2.4 Research Protocol","text":"research protocol comprehensive project summary document. submitting study Institutional Review Board, likely required submit document part application. research protocol provides means board determine methods provide adequate protection human subjects. addition serving required purpose, research protocol also excellent document deposit along data time data sharing, well excellent resource writing technical reports manuscripts. document provides context needed others effectively interpret use data. generally provides , , , , study. Make sure follow university’s specific template provided, common items typically included protocol seen .\nFigure 3.5: Common research protocol elements\ncomes time submit data repository, protocol can revised contain information helpful data end user. Content risks benefits participants might removed, numbers final study sample count updated show final numbers. Additional supplemental information can also added needed.Example protocols","code":""},{"path":"documentation.html","id":"supplement","chapter":"7 Documentation","heading":"7.2.5 Supplemental Documents","text":"series documents, can absolutely standalone documents, calling supplemental documents can added research protocol addendum point clarify specifics project.TimelineThe first supplemental document highly recommend creating visual representation data collection timeline. can helpful planning tool (project data teams) preparing times heavier lighter workloads, well excellent document share future data users better understand waves data collection. one format create document. example one way visualize data collection timeline.\nFigure 3.6: Example data collection timeline\nCONSORT DiagramA CONSORT (Consolidated Standards Reporting Trials) diagram displays flow participants program.111 visually portrays enrollment, randomization, well attrition study. can imagine though, diagram created least one wave data collected, must updated waves collected. participant tracking database, discuss tracking chapter, inform creation diagram.\nFigure 3.7: 2010 CONSORT flow diagram template\nInstrumentsActual copies instrument can included supplemental documentation. includes copies surveys, assessments, forms, forth. can also include technical documents associated instruments measures (.e. technical document assessment publication associated measure used).Flowchart data collection instruments/screenersYou can also include flowcharts participants provided assigned different instruments screeners help users better understand issues missing data.112\nFigure 3.8: Flowchart ECLS-K:2011 kindergarten assessment\nConsent FormsConsent forms can also added addendum research protocols give insight information provided study participants.Related publicationsYou may also choose attach publications come data addendum protocol.","code":""},{"path":"documentation.html","id":"sop","chapter":"7 Documentation","heading":"7.2.6 Standard Operating Procedures","text":"research protocol provides summary information procedures associated project, still need documents inform procedures actually implemented daily basis.113 recall planning chapter, every step added data collection workflow added standard operating procedure (SOP) details fleshed . SOP type data collecting (survey, assessments, observations), can also SOPs types decisions well. Many decisions laid protocol, detailed SOP. Examples procedures include SOP seen .\nFigure 3.9: Examples processes decisions develop SOP \nSOPs help staff know perform tasks, also create transparency, allow continuity staff turnover go leave, create standardization practices, last, SOP include versioning information, allow accurately report changes project procedures throughout project. want create template used consistently across procedures, staff build SOPs.\nFigure 3.10: Standard operating procedure minimal template\ndeveloping template, SOP begin general information scope purpose procedure, well tools terminology. provides context user gives background use interpret SOP. next section, procedures, lists procedures order. step provides name staff member/s associated step ensure ambiguity. step detailed possible hand SOP new staff member, background process, can implement procedure little trouble. Specifics names files links locations, names contacts, methods communication (ex: email vs instant message), forth included. Additions screenshots, links SOPs, even links tutorials can embedded well. Last, time update made SOP, clarifying information update added revision section. allows keep track changes time: changes made, made changes, .Example SOPS","code":""},{"path":"documentation.html","id":"dataset-level","chapter":"7 Documentation","heading":"7.3 Dataset Level","text":"next type documentation applies solely datasets includes information data contain related. also includes things planned transformations data, potential issues aware , alterations data. addition helpful descriptive documentation keep, huge reason creating dataset documentation authenticity. Datasets go many iterations processing can result multiple versions dataset.117 Preserving data lineage tracking data errors transformations key ensuring know data come , processing already completed, using correct version data.dataset level documentation created documentation phase talk timing review document.","code":""},{"path":"documentation.html","id":"readme","chapter":"7 Documentation","heading":"7.3.1 Readme","text":"readme plain text document contains information files. grew computer science now prevalent research world. documents way convey pertinent information collaborators simple, frills manner. Readmes can used many different ways going cover three ways often used context data management.conveying information colleaguesAn example study participant reaches project coordinator let know entered incorrect ID survey. project coordinator downloads raw data file cleaned data manager, also create file named “readme.txt” contains information saved alongside file raw data folder. way data manager goes retrieve file, see readme included know review document first.\n- ID 5051 entered incorrectly. 5015.\n- ID 5089 completed survey twice  \n    - first survey partially completedAn example study participant reaches project coordinator let know entered incorrect ID survey. project coordinator downloads raw data file cleaned data manager, also create file named “readme.txt” contains information saved alongside file raw data folder. way data manager goes retrieve file, see readme included know review document first.conveying steps process (sometimes also called setup file)may times specific data pipeline reporting process requires multiple steps, opening different files running different scripts. information can go SOP, programmatic type process done using series scripts, might easiest put simple file named “readme_setup.txt” folder scripts someone can easily open file see need run.\nStep 1: Run file 01_clean_data.R clean data  \nStep 2: Run file 02_check_errors.R check errors  \nStep 3: Run file 03_run_report.R create report  may times specific data pipeline reporting process requires multiple steps, opening different files running different scripts. information can go SOP, programmatic type process done using series scripts, might easiest put simple file named “readme_setup.txt” folder scripts someone can easily open file see need run.providing information set files directoryIf colleagues accessing clean datasets project directory, can helpful add readmes top directories provide information datasets available directory, well pertinent information datasets, including datasets related/can linked.118\nFigure 3.11: Institute Education Sciences example readme conveying information files directory\n","code":"- ID 5051 entered incorrectly. Should be 5015.\n- ID 5089 completed the survey twice  \n    - first survey is only partially completedStep 1: Run the file 01_clean_data.R to clean the data  \nStep 2: Run the file 02_check_errors.R to check for errors  \nStep 3: Run the file 03_run_report.R to create report  "},{"path":"documentation.html","id":"change","chapter":"7 Documentation","heading":"7.3.2 Changelog","text":"changelog record versions data code. automatic ways track data code programs Git GitHub, field education researchers often working human subject, identifiable data, users often keeping study data active project, remote repository. Data usually kept institution approved storage location. Even storage location versioning Box SharePoint, unless also way commit messages along versions (like commit message Git), still want keep changelog.changelog provides data lineage, allowing user understand data originated well transformations made data. also supports data confidence, allowing user understand version data currently using see recent versions created .simplest form changelog contain file name (versioned consistently), date created, description dataset (including changes made compared previous version). include additional information well made change, link code used transform data.119\nFigure 3.12: Example simple changelog clean student survey data file\nchangelogs likely created data capture data cleaning phases life cycle data transformations begin happening, can updated point needed.","code":""},{"path":"documentation.html","id":"data-cleaning-plan","chapter":"7 Documentation","heading":"7.3.3 Data Cleaning Plan","text":"data cleaning plan written proposal outlining plan transform raw data clean, usable data. document contains code technical skills dependent. data cleaning plan created dataset plan collect (ex: student survey, student assessment, teacher survey, district student demographic data). document lays intended transformations raw dataset, allows team member provide feedback data cleaning process.document can started documentation phase, likely continue updated throughout study, especially start digging collected raw data seeing additional transformations needed. Typically person responsibility cleaning data write data cleaning plans, documents can brought planning meeting allowing team members, PIs, provide input plan. ensures everyone agrees transformations performed. finalized, data cleaning plan serves guide cleaning process. talk much types transformations go data cleaning plan data cleaning chapter book.\nFigure 7.1: simplistic data cleaning plan\n","code":""},{"path":"documentation.html","id":"variable-level","chapter":"7 Documentation","heading":"7.4 Variable Level","text":"last category documentation variable level documentation. think data management, think likely first type documentation pops people’s minds. documentation tells us pertinent information variables exist datasets: variable names, descriptions, types, forth. variable level documentation often used interpretation existing datasets, can also serve many vital purposes including guiding construction data collection instruments, assisting data cleaning, validating accuracy data,120 discuss throughout chapters book.","code":""},{"path":"documentation.html","id":"data-dictionary","chapter":"7 Documentation","heading":"7.4.1 Data dictionary","text":"data dictionary rectangular format collection names, definitions, attributes variables dataset.121 document planning tool tool used interpretation, useful created documentation phase, project begins, integral many phases study.data dictionary typically created rectangular format. tool use build data dictionary , key pieces information included, well optional fields can helpful well.122\nFigure 7.2: Fields include data dictionary\n","code":""},{"path":"documentation.html","id":"creating-a-data-dictionary-for-an-original-data-source","chapter":"7 Documentation","heading":"7.4.1.1 Creating a data dictionary for an original data source","text":"begin build dictionaries need following:style guide already created: talk style guides next chapter, document provide standards name variables code response values.Documentation measures: collecting data using existing measures, want collect documentation measures technical documents copies instruments. want documentation provide information :items make measures/scales? exact wording items?items coded?calculations/reverse coding needed?build one data dictionary instrument plan collect (ex: student survey data dictionary, teacher survey data dictionary, student assessment data dictionary). measures/items instrument included data dictionary.build data dictionary, consider following:variable names meeting requirements laid style guide?items come existing scale, value coding align coding laid documentation? items come existing scale, value coding align requirements style guide?additional items make final dataset (items plan add data collected, .e. treatment, unique identifiers, calculated variables)?demonstration purposes , following data dictionary uses items Patterns Adaptive Learning Scales (PALS).123 actual research study dictionary likely include many items variety measures.\nFigure 7.3: Example student survey data dictionary\nlast step creating data dictionary, every document create documentation phase, review team.everyone agreement variables named, values coded, variable types?everyone agreement gets item?team want adjust question/item wording?’ll also want confirm data dictionary includes everything team plans collect items missing.additional items added instruments later time points, adding fields (time periods available), can really helpful future users understanding items may missing data certain time points.","code":""},{"path":"documentation.html","id":"creating-a-data-dictionary-from-an-existing-data-source","chapter":"7 Documentation","heading":"7.4.1.2 Creating a data dictionary from an existing data source","text":"research study data gathered original data collection methods. may collecting external data sources organizations like school districts state departments education. cases begin building data dictionaries later cycle, data received, rather forward moving flow discussed dictionary built first, now work backwards answer questions data.first step building data dictionary now review existing data. Yet, turns tells exist data, exist data. Items incorrectly coded, columns assigned incorrect variable type, forth. review data, start collect questions :variables represent?\nwording item?\nwording item?received items?values represent?\nseeing full range values/categorical options item? range larger seeing?\nvalues data don’t make sense item?\nseeing full range values/categorical options item? range larger seeing?values data don’t make sense item?types items currently? types ?order answer questions, may need additional detective work.Contact person originally collected data learn instrument data.Contact person cleaned data (cleaned) see transformations completed raw data.Request access original instruments review exact question wording, item response options, skip patterns, forth.Request documentation . data dictionaries, codebooks, syntax might help understand going data?Ultimately end data dictionary structured similarly one . may add additional fields help keep track changes (ex: column old variable name column new variable name), transformations section may become verbose values assigned previously may align values prefer based style guide existing measures. Otherwise, data dictionary still constructed manner mentioned .","code":""},{"path":"documentation.html","id":"time-well-spent","chapter":"7 Documentation","heading":"7.4.1.3 Time well spent","text":"process described section manual, time consuming process. intentional. Building data dictionary information seeking journey take time understand dataset, create standardization items, plan data transformations. Spending time manually creating document collecting data prevents many potential errors time lost fixing data future. absolutely ways can automate creation data dictionary using existing dataset, time can imagine useful clean dataset confidently already verified accurate ready shared. However, data dictionary, mentioned , much document shared alongside public dataset. tool guiding many processes research data life cycle.Example data dictionaries","code":""},{"path":"documentation.html","id":"codebook","chapter":"7 Documentation","heading":"7.4.2 Codebook","text":"codebook documents contents, structure, layout data file126. enables user quickly ascertain details dataset without ever opening file. Unlike data dictionary, codebook created data collected cleaned value lies data interpretation data validation.codebook contains information overlaps data dictionary, summary document actually exists dataset.\nFigure 7.4: Codebook content overlaps unique data dictionary\nUltimately want export codebook contains variable level information like document United States Department Health \nHuman Services.127\nFigure 7.5: Example codebook content SCOPE Coach Survey\ncan see addition excellent resource users review data without ever opening file, document may also help catch errors data range unexpected values appear.can either create separate codebooks per datasets contained one document, clickable table contents. Unlike data dictionary recommend create manually, codebook created automated process. Automating codebooks save tons time, also reduce errors made manual entry. can use many tools create codebooks, including point click statistical programs SPSS, little programming knowledge can flexibly design codebooks using programs like R SAS. Fo example, R programming language many packages create export codebooks variety formats existing dataset just running functions128.Last, may notice review codebooks, many start several pages text, usually containing information project. ’s common people, comes time share data, combine information research protocol readme files, codebooks, rather sharing separate documents.Example codebooks","code":""},{"path":"documentation.html","id":"metadata","chapter":"7 Documentation","heading":"7.5 Metadata","text":"last type documentation discuss metadata, created “prepare archiving” phase. comes time deposit data repository, submit two types documentation, human-readable documentation, includes documents ’ve previously discussed, metadata. Metadata documentation meant processed machines serves purpose making files searchable.131 Metadata aids cataloging, citing, discovering, retrieving data creation critical step creating FAIR data132.part, additional work needed part create metadata depositing data repository. simply created part depositing process.133 deposit data, repository may fill form contains descriptive (description project files - enables discovery), administrative (licensing ownership), structural metadata (technical considerations).134 information form become metadata.135\nFigure 7.6: Example intake metadata form figshare repository\ncommon metadata elements included below136.\nFigure 7.7: Common metadata elements\nDepending repository, minimum enter basic project level metadata similar , may required option enter comprehensive information, project-level information covered research protocol. may also option enter additional levels metadata help make level searchable, dataset-level variable-level metadata.137 information needed metadata can gathered documents ’ve discussed earlier chapter.entered form, repository converts entries human-readable machine-readable, searchable formats XML138 JSON-LD. can see metadata looks like humans submitted. example ICPSR Open displays metadata information project page.139 Notice even option download XML formatted metadata files one two standards want well.\nFigure 7.8: Example metadata displayed ICPSR Open project page\nways metadata can gathered well. instance, variable-level metadata, rather users input metadata, repositories may create metadata deposited statistical data files contain inherent metadata (variable types labels) deposited documentation data dictionaries codebooks.140If repository provides limited forms metadata entry, can also choose increase searchability files creating machine-readable documents. several tools help users create machine-readable codebooks data dictionaries findable search engines Google Dataset Search Ruben C. Arslan141.","code":""},{"path":"documentation.html","id":"metastandards","chapter":"7 Documentation","heading":"7.5.1 Standards","text":"Metadata standards, typically field specific, establish common structuring meaning data improve data interoperability addition increasing ability users find understand data.142 Metadata standards can applied several ways.143Formats: machine-readable format metadata ?Schema: fields recommended verses mandatory project, dataset variable level metadata?Controlled vocabularies: controlled list terms used index retrieve data.Many fields chosen metadata standards adhere . fields, like psychology,144 developing metadata standards, including formats, schemas, vocabularies grounded FAIR principles Schema.org schema.145 Yet, Institute Education Sciences recognizes currently agreed upon standards field education.146\nFigure 7.9: sampling field metadata standards\ncan helpful see standards differ well overlap. DDI Alliance put together table instance, mapping DDI Elements (vocabularies) Dublin Core,147 two commonly used standards.\nFigure 7.10: comparison DDI Version 2 standards Dublin Core standards\ncan see metadata comparison actually looks like download Dublin Core DDI 2.5 XML format metadata files ICPSR Open project saw .148 can start see differences similarities across standards.\nFigure 7.11: Metadata comparison AERA Open project\nplan archive data, first check repository see follow standards. example, repository Dryad uses combination Dublin Darwin Core,149 ICPSR uses DDI.150 repository use certain standards, work ensure metadata adheres standards. repositories may even provide curation support free fee. mentioned earlier, depending repository, adding metadata project may require additional work part. repository may simply enter information form convert information .standards provided repository plan create metadata, can choose standard works . Oftentimes researchers may choose pick general standard DataCite Dublin Core,151 field education, researchers least familiar DDI standard another good option. Remember, choose adhere standard, decision documented data management plan.","code":""},{"path":"documentation.html","id":"wrapping-it-up","chapter":"7 Documentation","heading":"7.6 Wrapping it up","text":"point head might spinning amount documents ’ve covered. ’s important understand document discussed provides unique meaningul purpose, don’t create every document listed. Choose documents help organize project data processes best way. document create well maintained, improve data management workflow, decrease errors, enhance understanding data.","code":""},{"path":"style.html","id":"style","chapter":"8 Style guide","heading":"8 Style guide","text":"\nFigure 3.1: Data documentation research project life cycle\nstyle guide provides general agreed upon rules formatting information152. mentioned previous chapter, style guides can created standardize procedures variable naming, variable value coding, file naming, file versioning, file structure, even coding practices.benefits creating style guides using consistently include:Creating standardization (within across projects)Improving interpretation: Consistent clear structure, naming, coding allows files variables findable understandable humans computers.Increasing reproducibility: organization file paths, file naming, variable naming constantly change undermines reproducibility data management analysis code written.Style guides can created individual projects, can also created team level, applied across projects. importantly, created project kicks can implement soon project begins. team-wide style guide already created, likely want create project-level style guide planning phase can begin setting directory structures file naming standards start creating saving project-related files.Style guides can housed one large document, table contents used reference section, can created separate documents. Either way, style guides stored central location easily accessible team members (team project wiki), team members trained, periodically retrained, style guide ensure adherence rules. team members consistently implementing style guide, benefits guide lost.remainder chapter, spend time reviewing good practices rules add style guides following purposes:Structuring directoriesNaming filesNaming variablesAssigning variable valuesStyling syntax filesWhile best practices provided , ultimately rules choose add style guide chosen based practices work best projects team. Whatever rules settle , write style guide everyone following rules within across projects.","code":""},{"path":"style.html","id":"directory-structure","chapter":"8 Style guide","heading":"8.1 Directory structure","text":"deciding structure project directories (organization operating systems folders files), several things want consider.First, consider organizing directory hierarchical folder structure clearly delineate segments projects improve searchability\nalternative using folder structure using metadata tagging organize search files153\nalternative using folder structure using metadata tagging organize search files153When creating folder structure, strike balance deep shallow structure\nshallow leads many files one folder difficult sort \ndeep leads many clicks get one file, plus file paths can max many characters (example, SharePoint OneDrive path limit 400 characters154)\nshallow leads many files one folder difficult sort throughToo deep leads many clicks get one file, plus file paths can max many characters (example, SharePoint OneDrive path limit 400 characters154)Create folders specific enough can limit access\nexample want limit user access folders hold Personally Identifiable Information (PII)\nprotect files don’t want others accidentally edit (example clean datasets), also consider making files “read ”\nexample want limit user access folders hold Personally Identifiable Information (PII)protect files don’t want others accidentally edit (example clean datasets), also consider making files “read ”Decide want “archive” folder move old files want leave previous versions folderConsider setting character limit folder names (reduce problems hitting path character limits)Make folder names meaningful easy understandMake folder names machine-readable\nDon’t use spaces. can break URL shared.\nDon’t use special characters folder names, ,, %, !, \\, /, .. Computers assign specific meaning many special characters.\nConsider using _ - separate words\nDon’t use spaces. can break URL shared.Don’t use special characters folder names, ,, %, !, \\, /, .. Computers assign specific meaning many special characters.Consider using _ - separate wordsBe consistent capitalization (use lower case example)Example directory structure style guideExample directory structure created using style guide","code":"1. All project directories follow this hierarchical metadata structure  \n    - Level 1: Name of project  \n    - Level 2: Life cycle folders  \n    - Level 3: Data collection wave folders (if relevant)  \n    - Level 4: Participant folder (if relevent)\n    - Level 5: Specific content folder  \n    - Level 6: Archive folders  \n2. All folders should be named according to these rules  \n    - Meaningful name but no longer than 20 characters  \n    - No spaces or special characters in folder names  \n    - Only use lower case letters  \n    - Use `-` to separate words  \n3. All previous versions of files must be placed into their respective \"archive\" folder\n    - A changelog should be placed in each \"archive\" folder to document changes between document versions                               levelName\n1  project-new                          \n2   ¦--intervention                     \n3   ¦   °--cohort-1                     \n4   ¦       °--coaching_materials       \n5   ¦           °--archive              \n6   ¦               °--changelog.txt    \n7   ¦--project-mgmt                     \n8   ¦   °--cohort-1                     \n9   ¦       °--scheduling-materials     \n10  ¦           °--archive              \n11  ¦               °--changelog.txt    \n12  ¦--documentation                    \n13  ¦   ¦--sops                         \n14  ¦   ¦   °--archive                  \n15  ¦   ¦       °--changelog.txt        \n16  ¦   °--data-dictionaries            \n17  ¦       °--archive                  \n18  ¦           °--changelog.txt        \n19  ¦--data                             \n20  ¦   °--cohort-1                     \n21  ¦       °--student                  \n22  ¦           °--survey               \n23  ¦               °--archive          \n24  ¦                   °--changelog.txt\n25  °--tracking                         \n26      °--cohort-1                     \n27          ¦--participant-database     \n28          ¦   °--archive              \n29          ¦       °--changelog.txt    \n30          °--parent_consents          "},{"path":"style.html","id":"file-naming","chapter":"8 Style guide","heading":"8.2 File naming","text":"\nFigure 3.2: xkcd comic naming files\nxkcd155 aptly points comic , many us pretty bad naming files consistent usable way. often rush save files maybe don’t consider unclear file names future users (including ).file names alone able answer questions :documents?documents created?document recent version?Let’s walk several conventions consider naming files.Never use spaces words. can often break URL shared.Never use special characters. can meaning within programming languages can cause problems.\nConsider using - _ separate words. helps make name human readable also allows computer read search files easier.\nworth noting _ can difficult read file names included links underlined denote path clickable (example sharing SharePoint link document).\nConsider using - _ separate words. helps make name human readable also allows computer read search files easier.worth noting _ can difficult read file names included links underlined denote path clickable (example sharing SharePoint link document).Choose either use lower case letters, specific use upper case letters (example start every new word)Make names descriptive (user able understand contents file without opening )Consider limiting number characters prevent hitting path limit (mentioned )Keep redundant metadata file name\nreduces confusion ever move file different folder send file collaborator. also makes files searchable.\nexample, always put data collection wave file name, even file currently housed specific wave folder. always put project name file name, even file currently housed project folder.\n\nreduces confusion ever move file different folder send file collaborator. also makes files searchable.\nexample, always put data collection wave file name, even file currently housed specific wave folder. always put project name file name, even file currently housed project folder.\nexample, always put data collection wave file name, even file currently housed specific wave folder. always put project name file name, even file currently housed project folder.use \\ dates. backslash can cause confusion machines often read separator file paths, escape character. Format dates one two ways:\nYYYY-MM-DD YYYYMMDD\nfirst format adds characters variable names, also may clearer users interpret. Either date formats sortable\nYYYY-MM-DD YYYYMMDDWhile first format adds characters variable names, also may clearer users interpret. Either date formats sortableWhen versioning files, pick format add style guide.\nplan version using number, consider left padding 0 single digit numbers keep file name length grows (v01, v02).\nmentioned chapter documentation, possible version programatically using tools like Git GitHub. However, tools always practical education research. practical means versioning may manually version files track changes changelog.\nplan version using number, consider left padding 0 single digit numbers keep file name length grows (v01, v02).mentioned chapter documentation, possible version programatically using tools like Git GitHub. However, tools always practical education research. practical means versioning may manually version files track changes changelog.files need run sequential order, add order number beginning file name, leading zeros ensure proper sorting (01_, 02_)Choose abbreviations use common names/phrases add style guide (student = stu). creates standard metadata also helps reduce file name character lengths.Choose order file name metadataExample file naming style guideExample file names created using style guide","code":"1. Never use spaces between words.\n2. Never use special characters.\n3. Use _ to separate words\n4. Only use lower case letters\n5. Keep names under 35 characters\n6. Use the following metadata file naming order:\n  - Order of use (if relevant–and always add a 0 before single digits)\n  - Project\n  - Cohort/Wave (if relevant)\n  - Participant\n  - Measure\n  - Further description\n  - Date (always add)\n  - Version (if necessary)\n7. Format dates as YYYY-MM-DD\n8. If there are multiple versions of a document on the same date, version using v# with a leading 0.\n9. Use the following abbreviations\n  - student = stu\n  - survey = svy\n  - wave = w\n  - project math efficacy = meme_stu_svy_sop_2022-08-01.docx\nme_w1_stu_svy_data_raw_2022-11-03.csv\nme_w1_stu_svy_cleaning_syntax_2023-01-22v01.R\nme_w1_stu_svy_cleaning_syntax_2023-01-22v02.R"},{"path":"style.html","id":"variable-naming","chapter":"8 Style guide","heading":"8.3 Variable naming","text":"style guide necessary document start create data dictionaries. several considerations review developing variable naming style guide. broken two types rules, non-negotiable requirements really included style guide (follow rules run serious problems interpretation humans machines), best practices suggestions recommended required.Mandatory:Don’t name variable keywords functions used programming language (, , repeat)156Set character limit\nstatistical programs limit variable name characters\nSPSS 64\nStata 32\nSAS 32\nMplus 8\nR 10,000\n\nsaid, limit 8 characters based fact one future user may use program like Mplus. Consider balance character limit interpretation. difficult make good human-readable variable names 8 characters. much easier make 32. majority users using program limit 32 . one potential Mplus user, can always rename variables specific analysis.\nstatistical programs limit variable name characters\nSPSS 64\nStata 32\nSAS 32\nMplus 8\nR 10,000\nSPSS 64Stata 32SAS 32Mplus 8R 10,000With said, limit 8 characters based fact one future user may use program like Mplus. Consider balance character limit interpretation. difficult make good human-readable variable names 8 characters. much easier make 32. majority users using program limit 32 . one potential Mplus user, can always rename variables specific analysis.Use variable name across time project\nitem named anx1 fall, name item anx1 spring\nitem named anx1 fall, name item anx1 springDon’t use spaces special characters (except_), allowed programs.\n- allowed programs R SPSS can mistaken minus sign\n. allowed R SPSS allowed Stata ’s best avoid using \n- allowed programs R SPSS can mistaken minus signWhile . allowed R SPSS allowed Stata ’s best avoid using itDo start variable name number. allowed many statistical programs.variable names unique\nabsolutely applies variables within dataset, also apply variables across datasets within project. reason , point may merge data across forms end identical variable names (programs allow).\n, example collect student gender survey also collect student gender school records, differentiate two (s_gender d_gender)\nabsolutely applies variables within dataset, also apply variables across datasets within project. reason , point may merge data across forms end identical variable names (programs allow)., example collect student gender survey also collect student gender school records, differentiate two (s_gender d_gender)substantively change item (substantive wording response options change) least one round data collected, version variable names order reduce errors interpretation.\nexample revised anx1 becomes anx1_v2\nexample revised anx1 becomes anx1_v2Suggested:Names meaningful\nInstead naming gender q1, name gender\nvariable part scale, consider using abbreviation scale plus scale item number (anx1, anx2, anx3)\nInstead naming gender q1, name genderIf variable part scale, consider using abbreviation scale plus scale item number (anx1, anx2, anx3)used question/scale , consider keeping variable name across projects. can useful ever want combine data across projects.consistent delimiters capitalization. Options include:\nPascal case (ScaleSum)\nSnake case (scale_sum)–preferred method variable names\nCamel case (scaleSum)\nKebab case (scale-sum)–don’t use variable names\nTrain case (Scale-Sum)–don’t use variable names\nPascal case (ScaleSum)Snake case (scale_sum)–preferred method variable namesCamel case (scaleSum)Kebab case (scale-sum)–don’t use variable namesTrain case (Scale-Sum)–don’t use variable namesConsider denoting reverse coding variable name reduce confusion (anx1_r)Choose abbreviations standard phrases use across variables. Using controlled vocabularies improves interpretation also makes data exploration manipulation easier157.\nmean = mean\nscaled score = ss\npercentile rank = pr\nmean = meanscaled score = sspercentile rank = prInclude indication measure variable name (example prefix) always know instrument item came . can also help unique variable name requirement .\ns = student self-report\nt = teach report students\ns_anx1, t_conf2\ns = student self-reportt = teach report studentss_anx1, t_conf2Example variable naming style guideExample variable names created using style guide","code":"1. Use snake case\n2. Keep names under 32 characters\n3. Use meaningful variable names\n4. If part of a scale, use scale abbreviation plus item number from the scale (not order number)\n5. Include an indication of the measure as a prefix in the variable name\n  - student self-report survey = s_\n  - teacher self-report survey = t_\n  - district student level data = d_\n6. Denote reverse coded variables using suffix `_r`s_anx1\ns_anx1_r\ns_gender\nd_gender\nt_stress5"},{"path":"style.html","id":"time","chapter":"8 Style guide","heading":"8.3.1 Time","text":"moving one last consideration variable names. data longitudinal, may need add rules accounting time variable names well.Depending plan merge data, two different ways account time.Concatenate time variables. plan merge data across time wide format. reason need concatenate time variables variable names repeat (anx1 wave 1, anx1 wave 2). remember guidelines , variable names dataset must unique. order create unique variable names correctly interpret items asked, add time variable names. variables assign time linking variables (student unique identifier, teacher unique identifier, ). variables need stay identical linking purposes appear data merging.Create time variables add data. plan append data time long format. Appending data long format requires additional work terms variable naming. discussed data structure chapter, actually want variables identically formatted named across time appending. , order differentiate items asked, add new variable time wave add appropriate value row.Deciding want combine datasets across time need happen early project. ’s typically best store datasets individually either ready internally use data ready publicly share data (archiving phase). times, can make decision best way combine data (need combine ). Waiting combine data prevents either wasting time combining data way ends actually useful, wasting time merging datasets later need re-combined find error individual dataset point.discuss merging appending data cleaning chapter. said, plan potentially merge data wide format point, can helpful go ahead plan rules adding time variable names, add rule style guide.right wrong way assign time variable names necessarily. Just make sure continue follow rules (never starting variable name number). options adding time.prefix suffix generic abbreviation, w1 wave 1, added delimiter _\nw1_s_gender s_gender_w1\nw1_s_gender s_gender_w1As prefix suffix meaningful abbreviation, f21 fall 2021, added delimiter (_)\nf21_s_gender s_gender_f21\nf21_s_gender s_gender_f21One options delimiter\nw1s_gender s_genderw1\nw1s_gender s_genderw1As number embedded variable certain location, instance, existing prefix s student survey\ns1_gender, s2_gender\ns1_gender, s2_genderWhile first second method add additional characters variable name, also benefits adding time ways. First, can easier visually spot interpret time component separated like . Also, adding time standalone component allows easily, programmatically, add, remove, manipulate time component variable. allows flexibility working data, especially restructuring datasets. time embedded variable names, can become inconvenient decide want remove time component restructure data.","code":""},{"path":"style.html","id":"value-coding","chapter":"8 Style guide","heading":"8.4 Value Coding","text":"addition naming variables standardized way, variables values also need added consistently. Value codes apply categorical variable. may numeric categorical values associated labels (ex: “” = 1) may character categorical values associated labels (ex: “” = ‘n’).First, using pre-existing measure, assign values labels manner technical documentation tells assign codes. important derivations need make later based measures. Otherwise, assigning values labels. guidelines assigning codes labels (well examples apply guidelines) .Values must unique\n: Assign “yes” = 1 “” = 0\nDon’t: Assign “yes” = 1 “” = 1\n: Assign “yes” = 1 “” = 0Don’t: Assign “yes” = 1 “” = 1Values must consistent within variable\n: gender assign “male” = ‘m’\nDon’t: gender allow “male” = ‘m’ ‘M’ ‘Male’ ‘male’\n: gender assign “male” = ‘m’Don’t: gender allow “male” = ‘m’ ‘M’ ‘Male’ ‘male’Values must consistent across time\n: Assign anx1 values “yes” = 1 “” = 0 wave 1 wave 2\nDon’t: Assign anx1 values “yes” = 1 “” = 0 wave 1 values “yes” = 1 “” = 2 wave 2\n: Assign anx1 values “yes” = 1 “” = 0 wave 1 wave 2Don’t: Assign anx1 values “yes” = 1 “” = 0 wave 1 values “yes” = 1 “” = 2 wave 2Values consistent across project\n: Assign “yes” = 1 “” = 0 value yes/items\nDon’t: Assign “yes” = 1 “” = 0 variables, “yes” = 1 “” = 2 others (unless pre-existing measure determines variables coded).\n: Assign “yes” = 1 “” = 0 value yes/itemsDon’t: Assign “yes” = 1 “” = 0 variables, “yes” = 1 “” = 2 others (unless pre-existing measure determines variables coded).Order Likert-type scale response options logical way\n: Assign “Strongly Disagree” = 1; “Disagree” = 2; “Agree” = 3; “Strongly Agree” = 4\nDon’t: Assign “Strongly Disagree” = 1; “Disagree” = 3; “Agree” = 4; “Strongly Agree” = 2 (, unless pre-existing measure tells code variables different way)\n: Assign “Strongly Disagree” = 1; “Disagree” = 2; “Agree” = 3; “Strongly Agree” = 4Don’t: Assign “Strongly Disagree” = 1; “Disagree” = 3; “Agree” = 4; “Strongly Agree” = 2 (, unless pre-existing measure tells code variables different way)Define missing values\nmay choose leave missing values blank, NA, NULL okay\nHowever, may care specific reason missing data need consider defining missing values based properties\nkey case use extreme values actually occur data also use values match variable type (ex: numeric missing values numeric variables)158\n\nmay choose leave missing values blank, NA, NULL okayHowever, may care specific reason missing data need consider defining missing values based properties\nkey case use extreme values actually occur data also use values match variable type (ex: numeric missing values numeric variables)158\nkey case use extreme values actually occur data also use values match variable type (ex: numeric missing values numeric variables)158\nFigure 3.3: Missing values assigned ECLS-K:2011 data file\n","code":""},{"path":"style.html","id":"coding","chapter":"8 Style guide","heading":"8.5 Coding","text":"team plans clean data using code, can helpful create coding style guide. style guide can tailored specific language staff use (R Stata), can written generically apply coding language staff use clean data. small sampling good coding practices consider adding guide. looking guides specific language, can helpful google existing style guides language.Consider building implementing coding templates159\nTemplates can standardize format syntax files (using standard headers break code)\nalso standardize summary information provided beginning syntax (code author, project name, date created)\nTemplates can standardize format syntax files (using standard headers break code)also standardize summary information provided beginning syntax (code author, project name, date created)Use comments throughout code clearly explain purpose code chunk\nformat comments dependent coding language\nR uses #\nSPSS Stata uses *\n\nformat comments dependent coding language\nR uses #\nSPSS Stata uses *\nR uses #SPSS Stata uses *Improve code readability using\nspaces\nindentation\nsetting line limit code (ex: 80 characters)\nspacesindentationsetting line limit code (ex: 80 characters)Use relative file paths reproducibility\nSetting absolute file paths syntax reduces reproducibility future users may different file paths. important set file paths relative directory working .160\nSetting absolute file paths syntax reduces reproducibility future users may different file paths. important set file paths relative directory working .160If create objects program (like R Python), consider adding object naming rules similar variable naming rules\nspaces object names\nspecial characters except _ separate words\nnames existing program keywords (, , etc.)\nspaces object namesNo special characters except _ separate wordsNo names existing program keywords (, , etc.)Reduce duplication, improve efficiency, increase ability troubleshoot errors using functions, loops, macros repetitive code chunksRecord session information future users\nRecord version information well operating system information relevant code increase reproducibility code\nRecord version information well operating system information relevant code increase reproducibility code","code":""},{"path":"track.html","id":"track","chapter":"9 Data Tracking","heading":"9 Data Tracking","text":"\nFigure 3.1: Data documentation research project life cycle\n","code":""},{"path":"track.html","id":"why-track-data","chapter":"9 Data Tracking","heading":"9.1 Why track data?","text":"","code":""},{"path":"track.html","id":"build-a-system","chapter":"9 Data Tracking","heading":"9.2 Build a system","text":"","code":""},{"path":"track.html","id":"ids","chapter":"9 Data Tracking","heading":"9.3 Creating participant IDs","text":"","code":""},{"path":"track.html","id":"when-to-build-it-who-builds-it-tools-to-build-it-in","chapter":"9 Data Tracking","heading":"9.4 When to build it, who builds it, tools to build it in","text":"","code":""},{"path":"data-collection.html","id":"data-collection","chapter":"10 Data Collection","heading":"10 Data Collection","text":"","code":""},{"path":"data-collection.html","id":"why-consider-data-management-in-data-collection","chapter":"10 Data Collection","heading":"10.1 Why consider data management in data collection?","text":"","code":""},{"path":"data-collection.html","id":"consents","chapter":"10 Data Collection","heading":"10.2 Consents","text":"","code":""},{"path":"data-collection.html","id":"electronic-data-collection-instruments","chapter":"10 Data Collection","heading":"10.3 Electronic data collection instruments","text":"","code":""},{"path":"data-collection.html","id":"paper-data-collection-instruments","chapter":"10 Data Collection","heading":"10.4 Paper data collection instruments","text":"","code":""},{"path":"data-collection.html","id":"interviewsfocus-groups","chapter":"10 Data Collection","heading":"10.5 Interviews/focus groups","text":"","code":""},{"path":"data-capture.html","id":"data-capture","chapter":"11 Data Capture","heading":"11 Data Capture","text":"","code":""},{"path":"data-capture.html","id":"electronic-data-capture","chapter":"11 Data Capture","heading":"11.1 Electronic data capture","text":"","code":""},{"path":"data-capture.html","id":"paper-data-capture","chapter":"11 Data Capture","heading":"11.2 Paper data capture","text":"","code":""},{"path":"data-capture.html","id":"extant-data","chapter":"11 Data Capture","heading":"11.3 Extant data","text":"","code":""},{"path":"data-storage-and-security.html","id":"data-storage-and-security","chapter":"12 Data Storage and Security","heading":"12 Data Storage and Security","text":"","code":""},{"path":"data-storage-and-security.html","id":"types-of-data-youll-be-storing","chapter":"12 Data Storage and Security","heading":"12.1 Types of data you’ll be storing","text":"","code":""},{"path":"data-storage-and-security.html","id":"general-security-rules","chapter":"12 Data Storage and Security","heading":"12.2 General security rules","text":"","code":""},{"path":"data-storage-and-security.html","id":"participant-tracking-database","chapter":"12 Data Storage and Security","heading":"12.3 Participant tracking database","text":"","code":""},{"path":"data-storage-and-security.html","id":"electronic-data","chapter":"12 Data Storage and Security","heading":"12.4 Electronic data","text":"","code":""},{"path":"data-storage-and-security.html","id":"detachable-media","chapter":"12 Data Storage and Security","heading":"12.5 Detachable media","text":"","code":""},{"path":"data-storage-and-security.html","id":"audiovisual-data","chapter":"12 Data Storage and Security","heading":"12.6 Audio/visual data","text":"","code":""},{"path":"data-storage-and-security.html","id":"paper-data","chapter":"12 Data Storage and Security","heading":"12.7 Paper data","text":"","code":""},{"path":"data-storage-and-security.html","id":"sharing-data","chapter":"12 Data Storage and Security","heading":"12.8 Sharing data","text":"","code":""},{"path":"clean.html","id":"clean","chapter":"13 Data Cleaning","heading":"13 Data Cleaning","text":"","code":""},{"path":"clean.html","id":"foundational-knowledge","chapter":"13 Data Cleaning","heading":"13.1 Foundational knowledge","text":"","code":""},{"path":"clean.html","id":"data-structure-1","chapter":"13 Data Cleaning","heading":"13.2 Data structure","text":"","code":""},{"path":"clean.html","id":"data-cleaning-plan-1","chapter":"13 Data Cleaning","heading":"13.3 Data cleaning plan","text":"","code":""},{"path":"clean.html","id":"data-validation","chapter":"13 Data Cleaning","heading":"13.4 Data validation","text":"","code":""},{"path":"clean.html","id":"why-use-code","chapter":"13 Data Cleaning","heading":"13.5 Why use code?","text":"","code":""},{"path":"share.html","id":"share","chapter":"14 Data Sharing","heading":"14 Data Sharing","text":"","code":""},{"path":"share.html","id":"why-share-your-data","chapter":"14 Data Sharing","heading":"14.1 Why share your data?","text":"","code":""},{"path":"share.html","id":"considering-fair-principles","chapter":"14 Data Sharing","heading":"14.2 Considering FAIR principles","text":"","code":""},{"path":"share.html","id":"best-practices","chapter":"14 Data Sharing","heading":"14.3 Best practices","text":"","code":""},{"path":"share.html","id":"retractions-and-revisions","chapter":"14 Data Sharing","heading":"14.4 Retractions and revisions","text":"","code":""},{"path":"wrapping-it-up-1.html","id":"wrapping-it-up-1","chapter":"15 Wrapping It Up","heading":"15 Wrapping It Up","text":"","code":""},{"path":"wrapping-it-up-1.html","id":"connecting-practices-to-outcomes","chapter":"15 Wrapping It Up","heading":"15.1 Connecting practices to outcomes","text":"","code":""},{"path":"wrapping-it-up-1.html","id":"putting-in-the-work","chapter":"15 Wrapping It Up","heading":"15.2 Putting in the work","text":"","code":""},{"path":"call-to-action.html","id":"call-to-action","chapter":"16 Call to Action","heading":"16 Call to Action","text":"","code":""},{"path":"call-to-action.html","id":"last-thoughts","chapter":"16 Call to Action","heading":"16.1 Last thoughts","text":"","code":""},{"path":"call-to-action.html","id":"training-for-future-researchers","chapter":"16 Call to Action","heading":"16.2 Training for future researchers","text":"","code":""},{"path":"call-to-action.html","id":"investing-in-data-management-and-data-managers","chapter":"16 Call to Action","heading":"16.3 Investing in data management and data managers","text":"","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
