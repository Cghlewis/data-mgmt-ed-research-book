[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":"-progress version Data Management Large-Scale Education Research. completed, book published CRC Press.","code":""},{"path":"index.html","id":"endorsements","chapter":"Welcome","heading":"Endorsements","text":"Imagine seasoned researcher’s best advice fingertips—precisely book offers. ’s well-crafted blend practical know-scholarly wisdom, perfect anyone currently managing research data. clarity touch scholarly flair, Crystal Lewis transforms complex concepts clear, actionable steps. ’s packed real-world examples, straightforward templates, checklists take guesswork data management. Whether ’re seasoned investigator, data manager, student stepping world research, book undoubtedly become staple professional toolkit, enhancing quality impact work. book resource speaks language, understands challenges, respects depth work. summary, book just guide; ’s mentor print form.Joscelin Rocha-Hidalgo, Pennsylvania State UniversityData Management Large-Scale Education Research game changer education researchers wanting improve research practices. book seamlessly blends theory practice, offering pragmatic guide ethically systematically managing sharing data.Crystal Steltenpohl, Center Open ScienceThis book direct answer critical need practical accessible resources education researchers managing primary data collection. Crystal Lewis introduces robust methods collection management data within broader research context. Readers acquire knowledge confidence leading large-scale studies, well skills strategies can implement work immediately. book shelves graduate students, project managers, data managers, PIs conducting research education!Leigh McLean, Center Research Educational Social Policy, University DelawareEducation researchers: skip book! Crystal Lewis gives tools need manage data better order make project run smoothly.Kristin Briney, Biology Librarian, California Institute Technology, author Data Management Researchers: Organize, Maintain Share Data Research SuccessAn outstanding guide learning manage large-scale data social sciences. book embraces tenets open science, highlighting importance reproducible science.Lexi Swanz, Vanderbilt University","code":""},{"path":"index.html","id":"book-key-features","chapter":"Welcome","heading":"Book key features","text":"book includes following key features:Provides holistic approach research life cycle, showing project management data management processes work parallel collaborativelyCan read entirety, well referenced needed throughout life cycleIncludes relatable examples specific education researchIncludes discussion organize document data preparation data sharing requirementsContains links example documents well templates help readers implement practices","code":""},{"path":"index.html","id":"about-the-author","chapter":"Welcome","heading":"About the author","text":"freelance research data management consultant trainer (cghlewis.com). Master’s degree Public Policy University Minnesota, Twin Cities. experience spans research life cycle including collecting, curating, sharing, analyzing data, particularly studies funded federal grants. happiest working intersection education research data management planning, helping researchers build implement organized processes lead secure, reliable, usable data. co-organizer two community groups—R-Ladies St. Louis, organization focused promoting gender diversity R community, well POWER (providing women opportunities education research) data management hub, facilitate peer data management support education research community.","code":""},{"path":"index.html","id":"acknowledgements","chapter":"Welcome","heading":"Acknowledgements","text":"book compilation lessons learned personal experiences data manager, knowledge collected existing books papers (many written librarians involved open science movement), well advice stories collected interviews researchers work data. want clear formally study research data management, unlike research data librarians experts content. Much book based lessons learned firsthand experience, book attempt hopefully save others making mistakes personally made seen others make. emphasize enough work university opportunity consult librarian project, absolutely !said, long list people like acknowledge contributions book supporting process.many people graciously allowed interview current data management practices. Mary McCraken, Ryan Estrellado, Kim Manturuk, Beth Chance, Jessica Logan, Rebecca Schmidt, Sara Hart, Kerry Shea. interviews integral supplementing personal knowledge broader experience others field. also affirmed yes, data management hard, especially context complicated study designs work education research, everyone works field wishes better training, support systems, standards existed. Thank everyone gave hour time share experiences knowledge! also give special thank Jessica Logan first person met appreciates things data management much , since interview, provided invaluable support working book.big thank David Grubbs Curtis Hill CRC Press supporting publishing process. Also, thank everyone took time read provide feedback chapters book. includes Meghan Harris, Alexis Swanz, Allyson Hanson, Rohan Alexander, Peter Higgins, Emily Riederer, Priyanka Gagneja, Jennifer Huck, Danielle Pico, Kristin Briney, Hope Lancaster, Gizem Solmaz-Ratzlaff, Crystal Steltenpohl, Leigh McLean, Jessica Logan, Chris Schatschneider, Tara Reynolds, Kerry Shea, Joscelin Rocha-Hidalgo, John Muschelli, Sara Hart. revisions insight helped make cohesive useful book!special thank Keith Herman well. Many years ago suggested write book titled Data Management Large-Scale Education Research, seemed unimaginable time. Thank Keith believing something didn’t even know possible.Much appreciation Wendy Reinke well. Joining project already created documentation tracking systems first glimpse building tools help manage data, love research data management grew experience.want say thank POWER Issues Data Management Education Research Hub. Regularly meeting group data managers, researchers, students, professors last two years amazing source support learning greatly increased understanding data management.Last, thank Josh fully supporting decision write book Fox reason remember step away computer time time fun.","code":""},{"path":"intro.html","id":"intro","chapter":"1 Introduction","heading":"1 Introduction","text":"results educational research studies accurate data used produce . - Aleata Hubbard (2017)2013, without knowing term research data management existed, accepted position prevention science research center. job coordinate collection management data federally funded randomized controlled trial efficacy studies taking place K-12 schools, along team investigators, research staff, part-time data collectors, graduate students. experience analyzing working education data, .e., ECLS-K, experience running research grants, collecting original data, managing research data, excited learn.time position, learned plan, schedule, track data collection activities, create data collection capture tools, organize document data inputs, produce usable data outputs. Yet didn’t learn things formal training. books, courses, workshops learned . learned colleagues large amount trial error. Since , met investigators, data managers, project coordinators education research, realize common method learning data management—mentoring “winging ”. learning data management informal methods helps us get , ramifications unstandardized system felt project team future data users.","code":""},{"path":"intro.html","id":"why-this-book","chapter":"1 Introduction","heading":"1.1 Why this book","text":"Research data management becoming complicated. collecting data, sometimes novel ways, using complex technologies, increasing visibility work push data sharing open science practices (Briney 2015; Nelson 2022). Ad hoc data management practices may worked us past, now others need understand processes well, requiring researchers thoughtful planning data management routines.","code":""},{"path":"intro.html","id":"lack-of-training-resources-and-standards","chapter":"1 Introduction","heading":"1.1.1 Lack of training, resources, and standards","text":"order implement thoughtful standardized data management practices, researchers need training. Yet clear lack data management training higher education. survey 274 psychology researchers, Borghi Van Gulick (2021) found 33% respondents learned data management college level coursework, 64% learned collaborators, 52% learned self-education. survey 202 education researchers (principal investigators co-principal investigators), Ceviren Logan (2022) found 60% respondents reported formal training data management, yet across eight different data management practices, respondents responsible data management activities anywhere 25-50% time. Similarly, survey 150 graduate students school education, asked needed training research data management, average overall score scale 1 100 80, overall confidence managing data score 40 (Zhou, Xu, Kogut 2023). Furthermore, training exist, usually provided university library systems, material either discipline agnostic STEM focused, leaving gap training apply skills field education unique issues, particularly around working human subjects data (Nichols Hess Thielen 2017).Without training, resources formal support systems next best option learning best practices. Within university systems, addition providing periodic training, research data librarians provide data management planning consultation researchers teams. also wealth existing research data management resources written broad audiences reference book. However, education researchers starting put excellent resources (Neild, Robinson, Agufa 2022; T. Reynolds, Schatschneider, Logan 2022), still find dearth practical guides researchers refer building data management workflow field education, especially working large-scale longitudinal research grants many moving pieces. Researchers often collecting data real-world environments, school systems, keeping data secure reliable deliberate orderly way can overwhelming.Last, unfortunately, fields research, psychology, appear banding together develop standards around structure document data (Kline 2018), field education yet develop shared rules things data documentation data formats. lack standards leads inconsistencies quality usability data products across field (Borghi Van Gulick 2022).","code":""},{"path":"intro.html","id":"consequences","chapter":"1 Introduction","heading":"1.1.2 Consequences","text":"lack training data management practices absence agreed-upon standards field education leads consequences. Implementing subpar inconsistent data management practices, typically resulting frustration time lost, also potential devastating, resulting analyzing erroneous data even unusable lost data. review 1,082 retracted publications journal PubMed 2013-2016, authors found 32% retractions due data management errors (Campos-Varela Ruano-Raviña 2019). 2013 study surveying 360 graduate students data management practices, 14% students indicated recollect data previously collected find file file corrupted, 17% students said lost file unable recollect (Doucette Fyfe 2013). study 488 researchers published psychology journal 2010 2018, Kovacs, et al. (2021) asked respondents data management mistakes found serious data management mistakes reported led range consequences including time loss, frustration, even erroneous conclusions.Poor data management can even prevent researchers implementing good open science practices. waves 1 2 Open Scholarship Survey collected Center Open Science, team found education researchers surveyed currently publicly sharing research data, approximately 15% mentioned “nervous mistakes” reason sharing (Beaudry et al. 2022). Similarly, surveying 780 researchers field psychology, researchers found 38% respondents agreed “fear discovery errors data” posed barrier data sharing (Houtkoop et al. 2018).well-known replication crisis another reason concerned data management. Failure implement practices quality documentation standardization practices (among many reasons), resulted one study finding across 1,500 researchers surveyed, 70% tried failed reproduce another researcher’s study (Baker 2016).","code":""},{"path":"intro.html","id":"about-this-book","chapter":"1 Introduction","heading":"1.2 About this book","text":"field education may agreed-upon guidelines data management, still practices proven result secure, reproducible, reliable data. hope book can foundation help researchers think build quality, standardized data management workflow works team projects. suggested title book, content designed specifically help teams navigate complicated workflows associated large-scale research, randomized controlled trial studies, ultimately practices applicable research project, matter scale.first time opening book, recommend reading book cover cover. Much information later chapters builds content earlier chapters. said, understanding contained chapter, book absolutely meant become handbook referenced needed ready start planning specific phase project.","code":""},{"path":"intro.html","id":"what-this-book-will-cover","chapter":"1 Introduction","heading":"1.2.1 What this book will cover","text":"book begins, like many books subject area, describing research life cycle data management fits within larger picture. remaining chapters organized phase life cycle, examples best practices provided phase. Considerations whether implement, integrate practices workflow discussed.Links templates, checklists, example documents provided throughout book. prefer clickable links, can view online, open access version book https://datamgmtinedresearch.com/.","code":""},{"path":"intro.html","id":"what-this-book-will-not-cover","chapter":"1 Introduction","heading":"1.2.2 What this book will not cover","text":"important also point book cover. book intended tool agnostic provide suggestions anyone can use, matter tools work , especially comes data cleaning. Therefore, might mention options tools can use different tasks, advocate specific tools.also specific coding practices syntax included book. many ways feel actual “data cleaning” phase data management easiest phase implement, long implement good practices point. , book introduces practices phases leading data cleaning prepare data minimal cleaning. said, provide examples expect see data cleaning process, just provide steps specific software system. beyond scope book.book also talk analysis preparing data analysis means data imputation, removal legitimate outliers, calculating analysis specific variables. Written perspective data manager, end goal data management build datasets general data sharing. means cover practices keep data complete true, usable form, future researcher analyze way works best .Last, want acknowledge education research studies, happening similar umbrella study, unique design requirements. impossible provide examples throughout book applicable every type project reader may encounter. Instead done best provide examples think generally relatable wide audience researchers, hopes can extrapolate examples specific work.","code":""},{"path":"intro.html","id":"who-this-book-is-for","chapter":"1 Introduction","heading":"1.3 Who this book is for","text":"book anyone involved research study involving original data collection. particular, book focuses quantitative data, typically collected human participants, although many practices covered apply types data well. book also applies team member, ranging investigators, data managers, project staff, students, contractual data collectors. contents book useful anyone may part planning, collecting, organizing research study data.","code":""},{"path":"intro.html","id":"final-note","chapter":"1 Introduction","heading":"1.4 Final note","text":"Planning implementing new data management practices top planning implementation entire research grant can feel overwhelming. However, idea book find practices work team implement consistently. teams may look like implementing just suggestions mentioned; others may involve implementing . Improving data management workflow process becomes easier time practices become part normal routine. point may even find enjoy working data management processes start see benefits implementation!","code":""},{"path":"rdm.html","id":"rdm","chapter":"2 Research Data Management Overview","heading":"2 Research Data Management Overview","text":"","code":""},{"path":"rdm.html","id":"what-is-research-data-management","chapter":"2 Research Data Management Overview","heading":"2.1 What is research data management?","text":"Research data management (RDM) involves organization, storage, preservation, dissemination research study data (Bordelon 2023). Research study data includes materials generated collected throughout research process (National Endowment Humanities 2018). can imagine, broad definition includes much just management digital datasets. also includes physical files, documentation, artifacts, recordings, . RDM substantial undertaking begins long data ever collected, planning phase, continues well research project ends archiving sharing phase.","code":""},{"path":"rdm.html","id":"data-management-standards","chapter":"2 Research Data Management Overview","heading":"2.2 Data management standards","text":"’s important research data management practices structured around standards—rules data collected, formatted, described, shared (Borghi Van Gulick 2022; Koos 2023). Implementing standards procedures variables collected named, items common measures shared, data formatted documented, leads findable usable data within fields provides added benefit allowing researchers integrate datasets without painstaking work harmonize data.fields adopted standards across research life cycle, CDISC standards used clinical researchers (CDISC 2023), fields adopted standards specifically around metadata, TEI standards used digital humanities (Burnard 2014) ISO 19115 standard used geospatial data (Michener 2015), grassroots efforts, fields psychology developing standards things data formatting documentation (Kline 2018) based FAIR principles inspired BIDS standard (BIDS-Contributors 2022). Yet, common knowledge currently agreed-upon norms field education research (Institute Education Sciences 2023a; Logan Hart 2023). rules collect, format, document data often left individual team, long external compliance requirements met (Tenopir et al. 2016).Without agreed-upon standards field, important research teams develop data management standards apply within across projects. Developing internal standards, implemented reproducible data management workflow, allows practices implemented consistently fidelity.","code":""},{"path":"rdm.html","id":"why-care-about-research-data-management","chapter":"2 Research Data Management Overview","heading":"2.3 Why care about research data management?","text":"external pressures personal reasons care developing research data management standards projects.","code":""},{"path":"rdm.html","id":"external-reasons","chapter":"2 Research Data Management Overview","heading":"2.3.1 External reasons","text":"Funder compliance: researcher applying federal funding required submit data management plan (see Chapter 5) along grant proposal (Holdren 2013; Nelson 2022). contents plans may vary slightly across agencies, shared purpose documents facilitate good data management practices mandate open sharing data maximize scientific outputs benefits society. Along mandatory data sharing policy comes incentive manage data purposes data sharing (Borghi Van Gulick 2022).Funder compliance: researcher applying federal funding required submit data management plan (see Chapter 5) along grant proposal (Holdren 2013; Nelson 2022). contents plans may vary slightly across agencies, shared purpose documents facilitate good data management practices mandate open sharing data maximize scientific outputs benefits society. Along mandatory data sharing policy comes incentive manage data purposes data sharing (Borghi Van Gulick 2022).Journal compliance: Depending journal publish , providing open access data associated publication may requirement (see PLOS ONE (https://journals.plos.org/plosone/) AMPPS (https://www.psychologicalscience.org/publications/ampps) examples). , along data sharing, comes incentive manage data thoughtful, responsible, organized way.Journal compliance: Depending journal publish , providing open access data associated publication may requirement (see PLOS ONE (https://journals.plos.org/plosone/) AMPPS (https://www.psychologicalscience.org/publications/ampps) examples). , along data sharing, comes incentive manage data thoughtful, responsible, organized way.Compliance mandates: Depending research design sensitivity level data collecting (see Section 4.2), variety policies well legal contractual obligations may need consider managing data (see Section 4.3). required submit project Institutional Review Board, board review monitor data management practices. Concerned welfare, rights, privacy research participants, IRB rules data securely collected, managed, shared (Filip 2023). data may also subject laws, HIPAA FERPA, regulate privacy exchange personal information. working research partners, may also need monitor honor conditions laid data sharing legal agreements. Additionally, organization may institutional data policies mandate data must cared secured.Compliance mandates: Depending research design sensitivity level data collecting (see Section 4.2), variety policies well legal contractual obligations may need consider managing data (see Section 4.3). required submit project Institutional Review Board, board review monitor data management practices. Concerned welfare, rights, privacy research participants, IRB rules data securely collected, managed, shared (Filip 2023). data may also subject laws, HIPAA FERPA, regulate privacy exchange personal information. working research partners, may also need monitor honor conditions laid data sharing legal agreements. Additionally, organization may institutional data policies mandate data must cared secured.Open science practices: growing interest open science practices, sharing well-managed documented data helps build trust research process (Renbarger et al. 2022). Sharing data curated reproducible way “strong indicator fellow researchers rigor, trustworthiness, transparency scientific research” (Alston Rick 2021, 2). also allows others replicate learn work, validate results strengthen evidence, well potentially catch errors work, preventing decisions made based incorrect data. Sharing data sufficient documentation standardized metadata can also lead collaboration greater impact collaborators able access understand data ease (Borghi Van Gulick 2022; Eaker 2016).Open science practices: growing interest open science practices, sharing well-managed documented data helps build trust research process (Renbarger et al. 2022). Sharing data curated reproducible way “strong indicator fellow researchers rigor, trustworthiness, transparency scientific research” (Alston Rick 2021, 2). also allows others replicate learn work, validate results strengthen evidence, well potentially catch errors work, preventing decisions made based incorrect data. Sharing data sufficient documentation standardized metadata can also lead collaboration greater impact collaborators able access understand data ease (Borghi Van Gulick 2022; Eaker 2016).Data management matter ethics: education research often collecting data human participants. result, data management ethical issue. responsibility well-designed research studies data collection, management, ownership, sharing practices consider environmental, social, cultural, historical, political context data working (Alexander 2023). Furthermore, collecting data human participants means people giving time energy entrusting us information. Implementing poor data management leads irrelevant, unusable, compromised data huge disservice research participants erodes trust research process (Feeney, Kopper, Sautmann 2022; Gammons 2022).Data management matter ethics: education research often collecting data human participants. result, data management ethical issue. responsibility well-designed research studies data collection, management, ownership, sharing practices consider environmental, social, cultural, historical, political context data working (Alexander 2023). Furthermore, collecting data human participants means people giving time energy entrusting us information. Implementing poor data management leads irrelevant, unusable, compromised data huge disservice research participants erodes trust research process (Feeney, Kopper, Sautmann 2022; Gammons 2022).","code":""},{"path":"rdm.html","id":"personal-reasons","chapter":"2 Research Data Management Overview","heading":"2.3.2 Personal reasons","text":"also many compelling personal reasons manage data reproducible standardized way.Reduces data curation debt: Taking time plan implement quality data management throughout entire research study reduces data curation debt caused suboptimal data management practices (Butters, Wilson, Burton 2020). poorly collected, managed, documented data may make data unusable, either permanently errors corrected. Decreasing removing debt reduces time, energy, resources spent possibly recollecting data scrambling end study get data acceptable standards.Reduces data curation debt: Taking time plan implement quality data management throughout entire research study reduces data curation debt caused suboptimal data management practices (Butters, Wilson, Burton 2020). poorly collected, managed, documented data may make data unusable, either permanently errors corrected. Decreasing removing debt reduces time, energy, resources spent possibly recollecting data scrambling end study get data acceptable standards.Facilitates use data: Every member research team able find understand project data documentation huge benefit. allows easy use reuse data hastens efforts like publication process (Markowetz 2015). search around participant numbers ask version file use allows team spend time analyzing less time playing detective.Facilitates use data: Every member research team able find understand project data documentation huge benefit. allows easy use reuse data hastens efforts like publication process (Markowetz 2015). search around participant numbers ask version file use allows team spend time analyzing less time playing detective.Encourages validation: Implementing reproducible data management practices encourages allows team internally replicate validate processes ensure outputs accurate (Alston Rick 2021).Encourages validation: Implementing reproducible data management practices encourages allows team internally replicate validate processes ensure outputs accurate (Alston Rick 2021).Improves continuity: Data management practices, documentation, ensures implementation fidelity project. includes consistently implementing practices longitudinal project across sites. also improves project continuity staff turnover. thoroughly documented procedures allows new staff pick right former staff member left implement project fidelity (Borghi Van Gulick 2021; Princeton University 2023b). Furthermore, good data management enables continuity handing projects collaborators picking projects long hiatus (Markowetz 2015).Improves continuity: Data management practices, documentation, ensures implementation fidelity project. includes consistently implementing practices longitudinal project across sites. also improves project continuity staff turnover. thoroughly documented procedures allows new staff pick right former staff member left implement project fidelity (Borghi Van Gulick 2021; Princeton University 2023b). Furthermore, good data management enables continuity handing projects collaborators picking projects long hiatus (Markowetz 2015).Increases efficiency: Documenting automating data management tasks reduces duplication efforts repeating tasks, especially longitudinal studies.Increases efficiency: Documenting automating data management tasks reduces duplication efforts repeating tasks, especially longitudinal studies.Upholds research integrity: Errors come many forms, humans technology (Kovacs, Hoekstra, Aczel 2021; Strand 2021). ’ve seen evidence papers cited retracted “unreliable data” blog Retraction Watch (https://retractionwatch.com/). Implementing quality assurance control procedures reduces chances errors occurring allows confidence data. Without implementing practices, research findings include extra noise, missing data, erroneous misleading results.Upholds research integrity: Errors come many forms, humans technology (Kovacs, Hoekstra, Aczel 2021; Strand 2021). ’ve seen evidence papers cited retracted “unreliable data” blog Retraction Watch (https://retractionwatch.com/). Implementing quality assurance control procedures reduces chances errors occurring allows confidence data. Without implementing practices, research findings include extra noise, missing data, erroneous misleading results.Improves data security: Quality data management preservation practices reduce risk lost stolen data, risk data becoming corrupted inaccessible, risk breaking confidentiality agreements.Improves data security: Quality data management preservation practices reduce risk lost stolen data, risk data becoming corrupted inaccessible, risk breaking confidentiality agreements.","code":""},{"path":"rdm.html","id":"existing-frameworks","chapter":"2 Research Data Management Overview","heading":"2.4 Existing frameworks","text":"Data management live space alone. co-exists frameworks impact data managed, important familiar provide foundation build data management structures.","code":""},{"path":"rdm.html","id":"rdm-fair","chapter":"2 Research Data Management Overview","heading":"2.4.1 FAIR","text":"2016, FAIR Principles published Scientific Data (Wilkinson et al. 2016), outlining four guiding principles scientific data management stewardship. principles created improve support reuse scholarly data, specifically ability machines access read data. foundation digital data publicly shared. principles :F: FindableAll data findable persistent identifier thorough, searchable metadata. practices aid long-term discovery information provide registered citations.: AccessibleUsers able access data. can mean data available repository request system. minimum, user able access metadata, even actual data openly available.: InteroperableYour data metadata use standardized vocabularies well formats. humans machines able read interpret data. Licenses pose barrier usage. Data available open formats can accessed software (e.g., CSV, TXT, DAT).R: ReusableTo provide context reuse data, metadata give insight data provenance, providing project description, overview data workflow, well authors cite appropriate attribution. also clear licensing data use.","code":""},{"path":"rdm.html","id":"seer","chapter":"2 Research Data Management Overview","heading":"2.4.2 SEER","text":"SEER principles, developed 2018 Institute Education Sciences (IES), provide Standards Excellence Education Research (Institute Education Sciences 2022). principles broadly cover entire life cycle research study, provide context good data management within education research study. SEER principles include:Pre-register studiesMake findings, methods, data openIdentify interventions’ core componentsDocument treatment implementation contrastAnalyze interventions’ costsFocus meaningful outcomesFacilitate generalization study findingsSupport scaling promising results","code":""},{"path":"rdm.html","id":"open-science","chapter":"2 Research Data Management Overview","heading":"2.4.3 Open science","text":"concept open science pushed quality data management forefront, bringing visibility cause, well advances practices urgency implement . Open science aims make scientific research dissemination accessible , making need good data management practices absolutely necessary. Open science advocates transparent reproducible practices means open data, open analysis, open materials, preregistration, open access (Van Dijk, Schatschneider, Hart 2021). Organizations, Center Open Science (https://www.cos.io), become well-known proponent open science, offering open science framework (OSF) (Foster Deardorff 2017) tool promote open science entire research life cycle. Furthermore, many education funders aligned requirements open science practices, openly sharing study data preregistration study methods.NoteWhen working specific populations, may principles consider complement FAIR principles open science practices provide guidance working protecting data collected specific communities. example, conducting research Indigenous populations, important consider Indigenous data sovereignty recognizes rights Indigenous peoples , control, access, use data collected communities lands, engage Indigenous communities planning data management study (Carroll et al. 2020; National Institutes Health 2022).","code":""},{"path":"rdm.html","id":"terminology","chapter":"2 Research Data Management Overview","heading":"2.5 Terminology","text":"moving forward book, important shared understanding terminology used. Many concepts education research synonymous terms can used interchangeably. Across different institutions, researchers may use terms. Please review Glossary gain better understanding terms used throughout book.","code":""},{"path":"rdm.html","id":"the-research-life-cycle","chapter":"2 Research Data Management Overview","heading":"2.6 The research life cycle","text":"remainder book organized chapters provide best practices phase research project life cycle. imperative understand life cycle order see flow data project, well understand everything project connected. phases skipped, whole project suffer.Figure 2.1, can see throughout project, data management roles project coordination roles work parallel collaboratively. teams may made people different members, either way, workflows must happen, must work together.\nFigure 2.1: research project life cycle\nLet’s walk chart.typical study, team first begins generating ideas, deciding want study., likely, look grant funding implement study. two paths begin diverge. team applying federal funding, proposal budget created project management track, supplemental required data management plan (DMP) created data track. , may people working pieces.Next, grant awarded, project team begin planning things hiring, recruitment, data collection, implement intervention. time, working data team begin plan specifically implement 2–5 page data management plan submitted funder start putting necessary structures place.planning complete, team moves cycle data collection. called cycle study longitudinal, every step occur cyclically. one phase data collection wraps , team re-enters cycle next phase data collection, data collection complete entire project.\ndata management project management teams begin cycle starting documentation. can see phase occurs collaboratively denoted double outline. teams begin developing documentation data dictionaries standard operating procedures.\ndocumentation started, teams collaboratively begin create data collection instruments. instruments created input documentation development involve several quality assurance procedures. phase teams may also develop participant tracking database.\nNext, project management team moves data collection phase. addition data collection, phase may also involve preliminary activities recruitment consenting participants, well hiring training data collectors. data management team may directly involved physical collection data, continue support project management team quality control needed.\ndata collected, project team track incoming data participant tracking database. data management team collaborate project management team help troubleshoot anything related tracking database issues discovered data tracking.\nNext, data collected, teams move data capture phase. teams actively retrieving electronically collected data converting paper data digital format. Oftentimes, collaborative effort project management team data team.\ndata captured, file needs stored. data team may charge setting monitoring storage efforts, project team may ones actively retrieving storing data.\nNext teams move cleaning validation phase. time data team reviewing data cleaning plans, writing data cleaning scripts, actively cleaning data recent data collection round.\nLast, data team create save new versions data updated, errors found.\ndata management project management teams begin cycle starting documentation. can see phase occurs collaboratively denoted double outline. teams begin developing documentation data dictionaries standard operating procedures.documentation started, teams collaboratively begin create data collection instruments. instruments created input documentation development involve several quality assurance procedures. phase teams may also develop participant tracking database.Next, project management team moves data collection phase. addition data collection, phase may also involve preliminary activities recruitment consenting participants, well hiring training data collectors. data management team may directly involved physical collection data, continue support project management team quality control needed.data collected, project team track incoming data participant tracking database. data management team collaborate project management team help troubleshoot anything related tracking database issues discovered data tracking.Next, data collected, teams move data capture phase. teams actively retrieving electronically collected data converting paper data digital format. Oftentimes, collaborative effort project management team data team.data captured, file needs stored. data team may charge setting monitoring storage efforts, project team may ones actively retrieving storing data.Next teams move cleaning validation phase. time data team reviewing data cleaning plans, writing data cleaning scripts, actively cleaning data recent data collection round.Last, data team create save new versions data updated, errors found.teams move active data collection phase data collection project complete. time project team begins analyzing study data working publications well final grant reports. able organized processes implemented data collection cycle. Since data managed cleaned throughout, data ready analysis soon data collection complete. , project team analyzing data, data team additional preparation archive data long-term storage public sharing.Last, grant closing , team submits data public sharing.work remaining chapters book, Figure 2.1 guide navigating phase practices fits larger picture. point feel overwhelmed information book, Appendix provides summary common activities occur phase. digestible list can helpful reminder information can boiled achievable tasks implemented extended period time.","code":""},{"path":"structure.html","id":"structure","chapter":"3 Data Organization","heading":"3 Data Organization","text":"jumping project life cycle, need basic understanding data looks like. Understanding basics data organization helps us make informed decisions throughout research life cycle result clear, analyzable information.","code":""},{"path":"structure.html","id":"basics-of-a-dataset","chapter":"3 Data Organization","heading":"3.1 Basics of a dataset","text":"education research, data often collected internally team using instrument questionnaire, observation form, interview guide, assessment. However, data may also collected external entities, districts, states, agencies.data come many forms (e.g., video, transcripts, documents, data files), represented text, numbers, multimedia (USGS 2023). world quantitative education research, often working digital data form dataset, structured collection data. dataset organized rectangular format allows information machine-readable. Rectangular, also called tabular, datasets made columns rows (see Figure 3.1).\nFigure 3.1: Basic format dataset\n","code":""},{"path":"structure.html","id":"structure-columns","chapter":"3 Data Organization","heading":"3.1.1 Columns","text":"columns dataset consist following types variables:Variables collect\nvariables collected instrument external source.\nvariables collected instrument external source.Variables create\nmay indicators create (e.g., cohort, treatment, time).\nvariables derived summary purposes (e.g., means, sum scores).\nmay indicators create (e.g., cohort, treatment, time).variables derived summary purposes (e.g., means, sum scores).Identifier variables\nUnless data collected anonymously, must also include values uniquely identify subjects data (e.g., student unique identifier).\nSee Section 10.4 information creating unique identifier variables.\nUnless data collected anonymously, must also include values uniquely identify subjects data (e.g., student unique identifier).See Section 10.4 information creating unique identifier variables.","code":""},{"path":"structure.html","id":"column-attributes","chapter":"3 Data Organization","heading":"3.1.1.1 Column attributes","text":"columns, variables, dataset also following attributes:Variable names\nvariable name short representation information contained column.\nVariable names must unique. variable name dataset can repeat. talk variable naming discuss style guides Chapter 9.\nvariable name short representation information contained column.Variable names must unique. variable name dataset can repeat. talk variable naming discuss style guides Chapter 9.Variable types\nvariable’s type determines allowable values variable, operations can performed variable, values stored.\nExample types include numeric, character (also called text string), date. Types can also narrowly defined needed (e.g., continuous, categorical).\nvariable’s type determines allowable values variable, operations can performed variable, values stored.Example types include numeric, character (also called text string), date. Types can also narrowly defined needed (e.g., continuous, categorical).Variable values\nVariable values refer information contained column. Every variable pre-determined allowable values.\nExamples setting allowable values different types variables include:\nCategorical character variable: “yes” | “”\nNumeric variable: 1–25\nDate variable: 2023-08-01 2023-12-15\nFree text character variable: value allowed\n\nAnything outside expected values ranges considered error.\nVariable values refer information contained column. Every variable pre-determined allowable values.Examples setting allowable values different types variables include:\nCategorical character variable: “yes” | “”\nNumeric variable: 1–25\nDate variable: 2023-08-01 2023-12-15\nFree text character variable: value allowed\nCategorical character variable: “yes” | “”Numeric variable: 1–25Date variable: 2023-08-01 2023-12-15Free text character variable: value allowedAnything outside expected values ranges considered error.Variable labels\nvariable label human readable description variable represents.\nmay label , variable creator, assigns (e.g., “Treatment condition”) may actual wording item (e.g., “enjoy pizza?”).\nvariable label human readable description variable represents.may label , variable creator, assigns (e.g., “Treatment condition”) may actual wording item (e.g., “enjoy pizza?”).","code":""},{"path":"structure.html","id":"rows","chapter":"3 Data Organization","heading":"3.1.2 Rows","text":"rows dataset aligned subjects (also called records cases) data. Subjects dataset may students, teachers, schools, locations, forth. unique subject identifier variable mentioned Section 3.1.1, denote row belongs subject.","code":""},{"path":"structure.html","id":"cells","chapter":"3 Data Organization","heading":"3.1.3 Cells","text":"cells observations associated case data. Cells made key/value pairs, created intersection column row (see Figure 3.2). Consider example collect survey (also called questionnaire) students. dataset, row made unique student study, column item survey, cell contains value corresponds row/column pair (.e., participant question).\nFigure 3.2: Representation cell value\n","code":""},{"path":"structure.html","id":"structure-rules","chapter":"3 Data Organization","heading":"3.2 Dataset organization rules","text":"order dataset machine-readable analyzable, adhere set organizational rules (Broman Woo 2018; Wickham 2014).first rule data make rectangle (Figure 3.3). first row data variable names (use one row ). remaining data made values cells.\nFigure 3.3: comparison non-rectangular rectangular data\nColumn values consistent (Figure 3.4). humans machines difficulty categorizing information measured, coded, formatted consistently.\ntext categorical values, use controlled vocabularies keep consistent spelling, case, spacing.\ndate values, keep format consistent.\nnumeric values, measure consistent units keep consistent decimal places.\ntext categorical values, use controlled vocabularies keep consistent spelling, case, spacing.date values, keep format consistent.numeric values, measure consistent units keep consistent decimal places.\nFigure 3.4: comparison inconsistent uniform variable values\nColumns adhere expected variable type (Figure 3.5).\nexample, numeric variable, age, add cell value text, variable longer adheres variable type. Machines now read variable type character.\nexample, numeric variable, age, add cell value text, variable longer adheres variable type. Machines now read variable type character.\nFigure 3.5: comparison variables adhering adhering data type\nvariable collect one piece information (Figure 3.6). allows easily work variables.\nexample, rather combining number incidents number enrolled students variable, separate information two variables. allows aggregate information needed (e.g., calculate incident rate).\nexample, rather combining number incidents number enrolled students variable, separate information two variables. allows aggregate information needed (e.g., calculate incident rate).\nFigure 3.6: comparison two things measured one variable two things measured across two variables\ncell values explicit (Figure 3.7). means cells missing values filled value.\nConsider cell value empty\nvalue actually missing, can either leave cells blank fill pre-determined missing values (e.g., -99). See Section 9.5.1 ideas coding missing values.\ncell left empty implied value , cells filled actual data.\nempty cell implied 0, fill cells actual 0.\n\nConsider cell value empty\nvalue actually missing, can either leave cells blank fill pre-determined missing values (e.g., -99). See Section 9.5.1 ideas coding missing values.\ncell left empty implied value , cells filled actual data.\nempty cell implied 0, fill cells actual 0.\nvalue actually missing, can either leave cells blank fill pre-determined missing values (e.g., -99). See Section 9.5.1 ideas coding missing values.cell left empty implied value , cells filled actual data.empty cell implied 0, fill cells actual 0.\nFigure 3.7: comparison variables empty cells variables empty cells\nvariables explicit (Figure 3.8). variables implied using color coding.\nwant indicate information, add indicator variable rather cell coloring.\nwant indicate information, add indicator variable rather cell coloring.\nFigure 3.8: comparison information indicated cell color information provided indicator variable\n","code":""},{"path":"structure.html","id":"structure-link","chapter":"3 Data Organization","heading":"3.3 Linking data","text":"now talking one, standalone dataset. However, likely research project made multiple datasets, collected different participants, using variety instruments, possibly across different time points. point likely need link datasets together.order think link data, need discuss two things, database design data structure.","code":""},{"path":"structure.html","id":"structure-database","chapter":"3 Data Organization","heading":"3.3.1 Database design","text":"database “organized collection data stored multiple datasets” (USGS 2023). Sometimes database actually housed database software system (SQLite FileMaker), times loosely using term database simply define linking datasets together stored individually (.e., flat files). matter storage system, general concepts applicable.database terminology, dataset considered “table”. table includes one variables uniquely define rows data (.e., primary key). Tables may also contain variables associated unique values another table (.e., foreign keys) (Wickham, Çetinkaya-Rundel, Grolemund 2023). See Figure 3.9 example three tables contain primary keys (denoted rectangles) foreign keys (denoted ovals). Furthermore, tables can joined either horizontally vertically.\nFigure 3.9: Three tables primary foreign keys\n","code":""},{"path":"structure.html","id":"horizontal-joins","chapter":"3 Data Organization","heading":"3.3.1.1 Horizontal joins","text":"Joining tables horizontally, also called merging, involves matching rows one (e.g., stu_id) (e.g., first_name last_name) keys, resulting table combined information. exception primary foreign keys often identically named across tables, important variables uniquely named across tables joining horizontally.several different types horizontal joins (e.g., left, right, inner, full). diving different types joins outside scope book, resources learning provided end section. now, just assume joins discuss left joins (.e., records first table matched available records second table).better understand horizontal joins, let’s take simple example Figure 3.10, primary key (stu_id) table, foreign keys. collected data students using two different instruments (survey assessment). join tables primary key, one--one merge student appears table.\nFigure 3.10: Linking data primary keys\nHowever, often collecting data using variety instruments, also collecting nested data across different entities (e.g., students, nested classrooms, nested schools). Let’s look another example collected data students (assessment) teachers (survey). Figure 3.11 shows can now link foreign key student assessment (tch_id) primary key teacher survey (tch_id). scenario, many one join (.e., multiple students associated teacher), meaning upon merging, teacher data repeated students classroom.\nFigure 3.11: Linking data foreign keys\ncan imagine, add tables, database structure begins become even complex. Figure 3.12 example collected data students (survey assessment), teachers (survey observation), schools (intake form). linking structure begins look complex, see can still link data primary foreign keys. Tables within participant types can linked primary keys, tables across participant types can linked foreign keys.\nFigure 3.12: Linking data primary foreign keys\nNoteIt important note , unique identifiers tables, case anonymous data, unable join data horizontally.","code":""},{"path":"structure.html","id":"vertical-joins","chapter":"3 Data Organization","heading":"3.3.1.2 Vertical joins","text":"Joining tables vertically, also called appending, involves stacking tables top . , rather joining primary foreign keys, matching columns variable names. case, variable names variable types identical across tables matching work.Let’s take simple example collected survey two different sites. surveys entered two separate tables want combine data. Figure 3.13 shows vertically join tables.\nFigure 3.13: Appending data across sites\nResources","code":""},{"path":"structure.html","id":"structure-datastructure","chapter":"3 Data Organization","heading":"3.3.2 Data structure","text":"working longitudinal data, ’s important consider data structure linking data. Collecting longitudinal, repeated measures data, typically results multiple, identically formatted tables, representing different wave data collection. common researchers join waves data storage analysis purposes. However, two different ways structure combined longitudinal data—wide format long format—important choose structure joining data.","code":""},{"path":"structure.html","id":"wide-format","chapter":"3 Data Organization","heading":"3.3.2.1 Wide format","text":"structure data wide format, data collected unique subject one row. Subjects duplicated data format.structure data wide format, join tables horizontally. joining though, wave data collection appended variable name create unique names. Figure 3.14 shows example structure two waves data collection wide format.\nFigure 3.14: Example linking tables across time wide format\n","code":""},{"path":"structure.html","id":"long-format","chapter":"3 Data Organization","heading":"3.3.2.2 Long format","text":"Another way structure longitudinal data long format. participant can, often , repeat dataset, unique rows now identified combination variables (e.g., stu_id wave together primary key).structure data long format, join tables vertically. scenario, longer add data collection wave variable names. However, time period variable added denote wave associated row data. Figure 3.15 shows example structure two waves data collection long format.\nFigure 3.15: Example linking tables across time long format\n","code":""},{"path":"structure.html","id":"structure-reshape","chapter":"3 Data Organization","heading":"3.3.2.3 Choosing wide vs long","text":"different reasons structuring longitudinal data one way another. Storing data long format usually considered efficient storing wide format, potentially requiring less memory. However, comes time analysis, specific data structures may required. example, repeated measure procedures typically require data wide format, unit analysis subject. mixed model procedures typically require data long format, unit analysis measurement subject (Grace-Martin 2013). may structure data one format one reason (e.g., storing sharing), restructure data another format different reason (e.g., analysis). Luckily, type restructuring can done fairly quickly many statistical programs 4. review decision making around data structure Chapters 14 16.","code":""},{"path":"hsd.html","id":"hsd","chapter":"4 Human Subjects Data","heading":"4 Human Subjects Data","text":"addition understanding organize data, also need foundational understanding types data may collect. field education research, often working data collected human subjects. Along collecting data people, comes responsibility secure data. Data humans may contain identifiable information increasing risk participants can revealed dataset. Human subjects data sometimes also contains information sensitive topics mental health, drug use, criminal behavior, increasing risks participants identified. beginning project, important assess type data collecting understand protections need place secure data. chapter briefly review types human subjects data may work well regulations, organizations, policies, agreements may impact need secure data.","code":""},{"path":"hsd.html","id":"identifiability-of-a-dataset","chapter":"4 Human Subjects Data","heading":"4.1 Identifiability of a dataset","text":"working human subjects two types identifiers may collect study, direct indirect (see Table 4.1). Direct identifiers unique individual can used identify participant. Indirect identifiers necessarily unique particular individual, combined information used identify participant (Kopper, Sautmann, Turitto 2023a).Table 4.1: Examples direct indirect identifiersA term often used discussing identifiable information personally identifiable information (PII). term broadly refers information can used identify participant. agreed-upon list fields included list PII generally includes direct indirect types information shown Table 4.1.collecting data creating datasets, working one four types data files (UNC Office Human Research Ethics 2020).Identifiable: Data includes personally identifiable information. common raw research study data identifiable.Coded: type data file, PII removed distorted names replaced code (.e., unique participant identifier). way link data back individual code. identifying code file (linking key) stored separate research data (see Chapter 10). Coded data typically type file create cleaning raw study data.De-identified: type file, identifying information removed distorted data can longer reassociated underlying individual (linking key longer exists). typically create publicly sharing research study data.Anonymous: anonymous dataset, identifying information ever collected little risk identifying specific participant.","code":""},{"path":"hsd.html","id":"hsd-dcl","chapter":"4 Human Subjects Data","heading":"4.2 Data classification","text":"Data often classified based level sensitivity (Filip 2023). levels sensitivity dictate data can collected, stored, shared, well response data breach. Depending institution, names levels, number levels, included levels, rules applied levels, vary. variation, general summary information may categorized.Low sensitivity: data considered low risk disclosed. includes de-identified anonymous data.Low sensitivity: data considered low risk disclosed. includes de-identified anonymous data.Moderate sensitivity: data considered moderate risk disclosed, meaning adversely affect people. data either includes identifiable information information allow participants re-identified within data using external source. data typically required kept confidential law agreements. data protected unauthorized access.Moderate sensitivity: data considered moderate risk disclosed, meaning adversely affect people. data either includes identifiable information information allow participants re-identified within data using external source. data typically required kept confidential law agreements. data protected unauthorized access.High sensitivity: data stringent security cause great harm disclosed. data includes PII information allow participants re-identified, well private highly sensitive information (e.g., illegal behaviors, medical records) typically required kept confidential law agreements. data protected unauthorized access.High sensitivity: data stringent security cause great harm disclosed. data includes PII information allow participants re-identified, well private highly sensitive information (e.g., illegal behaviors, medical records) typically required kept confidential law agreements. data protected unauthorized access.important review institution’s data classification levels, data sensitivity levels, determine specific institution classifies data. rules may come information technology department, institutional review board (IRB), combination . Note different data collection efforts project can classified different ways.","code":""},{"path":"hsd.html","id":"hsd-oversight","chapter":"4 Human Subjects Data","heading":"4.3 Human subjects data oversight","text":"collecting identifiable data, laws, policies, departments, agreements may impact collect manage data. review commonly encountered oversight education research.","code":""},{"path":"hsd.html","id":"hsd-laws","chapter":"4 Human Subjects Data","heading":"4.3.1 Regulations and laws","text":"FERPA: Family Educational Rights Privacy Act (FERPA) federal law protecting privacy student education records. law applies elementary secondary schools, well post-secondary institutions receive federal funds Department Education. FERPA provides list personally identifiable information often contained education records 5.FERPA: Family Educational Rights Privacy Act (FERPA) federal law protecting privacy student education records. law applies elementary secondary schools, well post-secondary institutions receive federal funds Department Education. FERPA provides list personally identifiable information often contained education records 5.HIPAA: Health Insurance Portability Accountability Act (HIPAA) provides federal protection privacy protected health information (PHI) collected covered entities serving patients. HIPAA Privacy Rule provides list 18 identifiers protected 6.HIPAA: Health Insurance Portability Accountability Act (HIPAA) provides federal protection privacy protected health information (PHI) collected covered entities serving patients. HIPAA Privacy Rule provides list 18 identifiers protected 6.Common Rule: 1991 Federal Policy Protection Human Subjects published, establishing core procedures human subjects protections. policy, 45 CFR part 46 (Office Human Research Protections 2016), included four subparts. Subpart , known “Common Rule”, provided set protections human subjects research including informed consent, review IRB, compliance monitoring (National Institute Justice 2007; Office Human Research Protections 2009). 2018 Common Rule revised order better protect research participants reduce administrative burden (Office Human Research Protections 2018; U.S. Department Health Human Services 2018).Common Rule: 1991 Federal Policy Protection Human Subjects published, establishing core procedures human subjects protections. policy, 45 CFR part 46 (Office Human Research Protections 2016), included four subparts. Subpart , known “Common Rule”, provided set protections human subjects research including informed consent, review IRB, compliance monitoring (National Institute Justice 2007; Office Human Research Protections 2009). 2018 Common Rule revised order better protect research participants reduce administrative burden (Office Human Research Protections 2018; U.S. Department Health Human Services 2018).","code":""},{"path":"hsd.html","id":"hsd-institution","chapter":"4 Human Subjects Data","heading":"4.3.2 Institutions and departments","text":"IRB: Institutional Review Board (IRB) formal organization designated review monitor human participant research ensure welfare, rights, privacy research participants maintained throughout project (Oregon State University 2012). particular IRB concerned three ethical principles established Belmont Report (National Commission Protection Human Subjects Biomedical Behavioral Research 1979); respect persons (.e., protecting autonomy participants), beneficence (.e., minimizing harm maximizing good), justice (.e., fair distribution burdens benefits)(Duru Sautmann 2023; Gaddy Scott 2020). conducting human subjects research, important review local IRB’s policies procedures determine study requires IRB approval.IRB: Institutional Review Board (IRB) formal organization designated review monitor human participant research ensure welfare, rights, privacy research participants maintained throughout project (Oregon State University 2012). particular IRB concerned three ethical principles established Belmont Report (National Commission Protection Human Subjects Biomedical Behavioral Research 1979); respect persons (.e., protecting autonomy participants), beneficence (.e., minimizing harm maximizing good), justice (.e., fair distribution burdens benefits)(Duru Sautmann 2023; Gaddy Scott 2020). conducting human subjects research, important review local IRB’s policies procedures determine study requires IRB approval.department: Institutional information technology () departments often vet data collection, transfer, storage tools authority tools approved research use. may also source determining classification levels data security.department: Institutional information technology () departments often vet data collection, transfer, storage tools authority tools approved research use. may also source determining classification levels data security.Office research sponsored programs: Institutions often administrative body serves signatory authority can help negotiate terms conditions certain types agreements (Washington University St. Louis 2023).Office research sponsored programs: Institutions often administrative body serves signatory authority can help negotiate terms conditions certain types agreements (Washington University St. Louis 2023).","code":""},{"path":"hsd.html","id":"agreements","chapter":"4 Human Subjects Data","heading":"4.3.3 Agreements","text":"Informed consent/assent: Consent involves informing participant data collected research study handled used, well obtaining participant’s voluntary agreement participate study. study involves participants age 18, may also required obtain participant assent form, addition parent/guardian consent form.Informed consent/assent: Consent involves informing participant data collected research study handled used, well obtaining participant’s voluntary agreement participate study. study involves participants age 18, may also required obtain participant assent form, addition parent/guardian consent form.DUA: data use agreement (DUA), also sometimes referred data sharing agreement (DSA), contractual agreement provides terms conditions sharing data. DUAs commonly written data sharing partnering school districts state agencies. example, DUA may include terms sharing, working , storing education records data. However, DUAs can used provide guidance outgoing data well (.e., researcher sharing original data agency). DUAs can standalone documents may incorporated documents memorandum understanding (MOU).DUA: data use agreement (DUA), also sometimes referred data sharing agreement (DSA), contractual agreement provides terms conditions sharing data. DUAs commonly written data sharing partnering school districts state agencies. example, DUA may include terms sharing, working , storing education records data. However, DUAs can used provide guidance outgoing data well (.e., researcher sharing original data agency). DUAs can standalone documents may incorporated documents memorandum understanding (MOU).NDA: Non-disclosure agreements (NDAs), also may synonymous confidentiality agreements, restrict use proprietary confidential information (University Washington 2023) legally enforceable agreements.NDA: Non-disclosure agreements (NDAs), also may synonymous confidentiality agreements, restrict use proprietary confidential information (University Washington 2023) legally enforceable agreements.","code":""},{"path":"hsd.html","id":"funders","chapter":"4 Human Subjects Data","heading":"4.3.4 Funders","text":"Funding agencies: Along requiring data management plans, funding agencies may data protection procedures may require applicants submit additional documents agreeing specific guidelines outlining security plans human subjects data.","code":""},{"path":"hsd.html","id":"protecting-human-subjects-data","chapter":"4 Human Subjects Data","heading":"4.4 Protecting human subjects data","text":"Throughout remaining chapters book, review ways keep identifiable human subjects data secure phase research life cycle. said, quick review important things remember collecting data contain PII.situations important get consent collect identifiers. Consult local IRB determine required. See Section 11.2.5 information.Collect identifiers possible. collect necessary. See Section 11.2.1 information.Follow rules laid applicable laws, policies, agreements collecting, storing, sharing data. includes, limited , using approved tools data collection, capture, storage, assigning appropriate data access levels, transmitting data using approved methods. See Chapters 11, 12, 13, 15 information.Remove names data replace codes (.e., unique study identifiers). See Section 10.4 Section 14.3.1 information.Fully de-identify data publicly sharing . See Section 16.2.3.4.1 information.Use data sharing agreements controlled access needed publicly sharing data. See Section 16.2.1 information.","code":""},{"path":"dmp.html","id":"dmp","chapter":"5 Data Management Plan","heading":"5 Data Management Plan","text":"\nFigure 5.1: Data management plan research project life cycle\n","code":""},{"path":"dmp.html","id":"history-and-purpose","chapter":"5 Data Management Plan","heading":"5.1 History and purpose","text":"Since 2013, even earlier National Science Foundation (NSF), federal agencies education researchers work required data management plan (DMP) part funding application (Holdren 2013). focus plans mostly future outcome data sharing, data management plan means ensuring researchers thoughtfully plan research study result data can shared confidence, free errors, uncertainty, violations confidentiality. President Obama’s May 2013 Executive Order declared “default state new modernized government information resources shall open machine readable” (White House 2013). August 2022, Office Science Technology Policy (OSTP) doubled data sharing policy issued memorandum stating federal agencies must update public access policies later December 31, 2025, make federally funded publications supporting data accessible public embargo release (Nelson 2022). Even sooner , organizations like National Institutes Health (NIH) mandated grant applicants, beginning January 2023, must submit plan managing sharing project data (National Institutes Health 2023c). National Science Foundation also released version 2.0 public access plan February 2023, describing agency plans ensure scientific data, funded NSF associated peer-reviewed publications, publicly shared (National Science Foundation 2023).NoteIn last year, agencies begun revising phrase “data management plan” include word “sharing” better represent shifting emphasis sharing publicly funded data. example, NIH now uses term Data Management Sharing (DMS) Plan7, Institute Education Sciences (IES) chosen use term Data Sharing Management Plan (DSMP)8. sake simplicity, term DMP used throughout book generally represent plans, matter precise name, across federal agencies.","code":""},{"path":"dmp.html","id":"why-are-dmps-important","chapter":"5 Data Management Plan","heading":"5.1.1 Why are DMPs important?","text":"Funding agencies see DMPs important maximizing scientific outputs investments increasing transparency. Mandating data sharing federally funded projects leads many benefits including accelerating discovery, greater collaboration, building trust among data creators users. addition benefits viewed funders, intrinsic benefits come write data management plan. thoughtfully plan, transparency plan, leads better data management. Knowing eventually sharing data documentation others outside team can motivate researchers think hard organize data management practices way produce data trust share outside world (Center Open Science 2023). Even DMP required funder, always first step planning process. Although brief, document serves foundation future planning provides team shared understanding data management expectations.","code":""},{"path":"dmp.html","id":"what-is-it","chapter":"5 Data Management Plan","heading":"5.2 What is it?","text":"Typically, data management plan supplemental 2–5 page document, submitted grant application, contains high-level decisions plan collect, store, manage, share research data products. funders DMPs part scoring process, reviewed panel program officer. funders may provide feedback ask revisions believe plan /budget associated costs adequate. Although document usually submitted funder, considered living document updated plans change throughout study.","code":""},{"path":"dmp.html","id":"what-to-include","chapter":"5 Data Management Plan","heading":"5.2.1 What to include?","text":"include DMP varies across funding agencies landscape requirements currently evolving. check funding agency’s site specific DMP requirements submitting proposal. said generally 10 common categories covered data management plan (Center Open Science 2023; Gonzales, Carson, Holmes 2022; ICPSR 2020; Michener 2015) review .Description data shared (See Chapters 11, 12, 14, 16)\nsource data? (e.g., surveys, assessments, observations, extant data)\ndata cleaned curated prior data sharing?\nlevel aggregation ? (e.g., item-level, summary data, metadata )\nDatasets project may need shared different ways due legal, ethical, technical reasons.\n\nraw clean data shared?\nexpected number files? Expected number rows/cases file?\nsource data? (e.g., surveys, assessments, observations, extant data)data cleaned curated prior data sharing?level aggregation ? (e.g., item-level, summary data, metadata )\nDatasets project may need shared different ways due legal, ethical, technical reasons.\nDatasets project may need shared different ways due legal, ethical, technical reasons.raw clean data shared?expected number files? Expected number rows/cases file?Format data shared (See Chapters 14 16)\ndata electronic format?\nprovided non-proprietary format? (e.g., CSV)\none format provided? (e.g., SPSS CSV)\ntools needed manipulate reproduce shared data? (e.g., software, code)\nProvide details tools. (e.g., can accessed, version number, required operating system)\n\ndata electronic format?provided non-proprietary format? (e.g., CSV)one format provided? (e.g., SPSS CSV)tools needed manipulate reproduce shared data? (e.g., software, code)\nProvide details tools. (e.g., can accessed, version number, required operating system)\nProvide details tools. (e.g., can accessed, version number, required operating system)Documentation shared (See Chapters 8 16)\ndocumentation share?\nConsider project-level, dataset-level, variable-level documentation.\n\nformat documentation ? (e.g., XML, CSV, PDF)\ndocumentation share?\nConsider project-level, dataset-level, variable-level documentation.\nConsider project-level, dataset-level, variable-level documentation.format documentation ? (e.g., XML, CSV, PDF)Standards (See Chapters 8 11)\nplan use standards things metadata, data collection (e.g., common data elements), data formatting?\nplan use standards things metadata, data collection (e.g., common data elements), data formatting?Data preservation (See Chapter 16)\ndata archived public sharing?\nMany agencies now requiring applicants name specific data repository section.\n\ndesirable characteristics repository? 9 (e.g., unique persistent identifiers assigned data, metadata collected, records provenance, licensing options)\ndeposit study data repository long data remain accessible?\nenable discoverability reuse data?\ndata archived public sharing?\nMany agencies now requiring applicants name specific data repository section.\nMany agencies now requiring applicants name specific data repository section.desirable characteristics repository? 9 (e.g., unique persistent identifiers assigned data, metadata collected, records provenance, licensing options)deposit study data repository long data remain accessible?enable discoverability reuse data?Access, distribution, reuse considerations (See Chapters 4 16)\nlegal, technical, ethical factors affecting reuse, access, distribution data?\ndata restricted?\naccess controls required (e.g., data use agreement, data enclave)?\nlegal, technical, ethical factors affecting reuse, access, distribution data?data restricted?access controls required (e.g., data use agreement, data enclave)?Protection privacy confidentiality (See Chapters 4, 14, 16)\nparticipants sign informed consent agreements? consent communicate participant data expected used shared?\nprevent disclosure personally identifiable information share data?\nparticipants sign informed consent agreements? consent communicate participant data expected used shared?prevent disclosure personally identifiable information share data?Data security (See Chapter 13)\nsecurity integrity data maintained project? (e.g., consider data storage, access, backup, transfer)\nsecurity integrity data maintained project? (e.g., consider data storage, access, backup, transfer)Roles responsibilities (See Chapter 7)\nstaff roles management preservation data?\nensures accessibility, reliability, quality data?\nplan core team member leaves project institution?\nstaff roles management preservation data?ensures accessibility, reliability, quality data?plan core team member leaves project institution?Pre-registration\npre-register study?\npre-register study?, specifics included category vary funder. sites visit learn DMP requirements four common federal education research funding agencies.Institute Education Sciences 10 11National Institutes Health 12National Institute Justice 13National Science Foundation 14","code":""},{"path":"dmp.html","id":"dmp-catalog","chapter":"5 Data Management Plan","heading":"5.3 Creating a data sources catalog","text":"preparation writing DMP, can helpful create data sources catalog allows visually see data collecting, sensitivity level source , data collected, managed, stored, shared (Filip 2023). type catalog help write DMP can also serve excellent planning discussion tool throughout entire project.setting rectangular formatted document, row represents unique data collection effort, column (field) represents information effort. fields can add catalog include:Source information\nInstrument (e.g., survey, assessment)\nRecord level (.e., instrument collected )\ncompletes instrument (e.g., rater, participant)\nMeasures included instrument\nInstrument (e.g., survey, assessment)Record level (.e., instrument collected )completes instrument (e.g., rater, participant)Measures included instrumentCollection capture methodData collection waves (.e., often collect data source)Planned number size data files source (e.g., two student assessment files (T1, T2), ~500 rows per file)PII includedSensitivity level based institution’s policiesData storage access planData ownershipHow confidentiality securedData sharing methodFigure 5.2 simplified example building catalog hypothetical study. Ultimately, data source catalog, multiplied number cohorts /waves collected, give estimate final number distinct data files end study. Figure 5.2, collected data one year, end six datasets end study, three teacher-level files three student-level files. Chapter 16, discuss whether share separate datasets, larger files combined unit analysis (e.g., combined student-level file, combined teacher-level file).\nFigure 5.2: Example data sources catalog\n","code":""},{"path":"dmp.html","id":"getting-help","chapter":"5 Data Management Plan","heading":"5.4 Getting help","text":"Since DMPs written project funded, therefore additional staff members may hired, oftentimes investigators developing grant proposal ones write DMP. However, constructing DMP well worth time enlist help. existing data manager data team, certainly want consult writing plan ensure decisions feasible. work university system, research data librarians also excellent resources wealth knowledge writing comprehensive data management plans. Also, plan share final data repository institutional archive want contact team writing plan well. repository may requirements data must shared, helpful outline guidelines data management plan time submission. Last, may want obtain help colleagues. colleagues likely written DMPs many people willing share plans way help others better understand include.mentioned , DMP living document, can always update plan project completion. may helpful keep contact program officer regarding potential changes throughout project.looking guidance writing DMP, variety generic DMP templates different federal agencies available, well actual copies submitted DMPs researchers graciously make publicly available example purposes. Furthermore, DMPTool (https://dmptool.org), free, open-source, online application, allows users create share data management plans using pre-defined funding agency templates.Templates resources","code":""},{"path":"dmp.html","id":"dmp-budget","chapter":"5 Data Management Plan","heading":"5.5 Budgeting","text":"Effective data management requires significant investment. Funding agencies acknowledge costs associated implementing data management plan allow explain costs budget narrative. Costs associated entire data life cycle considered (Cruse 2011), include things personnel expenses, well fees tools services. Make sure review funder’s documentation information allowable costs time frame incurring costs. Allowable costs might include things (National Institutes Health 2023a; UK Data Service 2023):Infrastructure tools required organize, document, store dataCurating de-identifying dataDeveloping data documentationDepositing data long-term sharing repositoryIt can difficult estimate costs everything associated vast landscape managing data. necessary dollar amount vary depending size project, expertise needed, specific data management plan. Recommendations suggest budgeting anywhere 5-30% budget data stewardship (Mons 2020; J. H. Reynolds et al. 2014). Luckily organizations developed resources aid estimating costs. Exercise caution using tools though; may always account every cost result underestimation costs (Michigan State University 2023).Resources","code":""},{"path":"plan.html","id":"plan","chapter":"6 Planning Data Management","heading":"6 Planning Data Management","text":"\nFigure 6.1: Planning research project life cycle\nPlanning data management distinct 2-5 page data management plan (DMP) discussed Chapter 5. spending weeks, maybe months, meeting regularly team gathering information develop detailed instructions plan manage data according DMP. data management planning happens time project team planning project implementation (e.g., collect data, hire staff, supplies needed, recruit participants, communicate sites). Team members investigators, project coordinators, data managers, may assisting planning processes.","code":""},{"path":"plan.html","id":"why-spend-time-on-planning","chapter":"6 Planning Data Management","heading":"6.1 Why spend time on planning?","text":"Funder required data management plans hopeful outlines future practices. However, broad theory behind DMPs actually prepare us complex implementation plans practice (Borycz 2021). Therefore, important spend time, project begins, planning preparing data management. upfront time investment sort slow science leads better data outcomes. Reproducibility begins planning phase. Taking time create, document, train staff data management standards project begins helps ensure processes implemented fidelity can replicated consistently throughout entire study.Planning day--day management project data many benefits well. allows anticipate overcome barriers managing data, communication issues, training needs, potential tool issues. type planning also saves time long run, removing last-minute scrambling can occur trying organize data end project. Last, type planning can mitigate errors. Viewing errors problems created poorly planned workflows, rather individual failures, helps us see data management planning can lead better data (Strand 2021). data management planning remove chances errors creeping data (Eaker 2016), can certainly reduce errors prevent “compounding time” (Alston Rick 2021, 4).","code":""},{"path":"plan.html","id":"goals-of-planning","chapter":"6 Planning Data Management","heading":"6.2 Goals of planning","text":"planning phase include series regular meetings core decision makers. purpose, can helpful form data management working group (DMWG), consisting investigators, key project staff, decision makers (e.g., methodologists), can attend planning meetings provide feedback needed throughout project (Van Bochove, Alper, Gu 2023). several goals accomplish planning meetings.flesh project goals laid grant proposal (e.g., confirm measures collected study).Finalize timeline goals (e.g., confirm data collection timeline).Lay specific tasks required accomplish data management plans.Assign roles responsibilities specific tasks.Make decisions around manage tasks communication.Make sure come every meeting agenda stay track take detailed notes. notes basis creating documentation (see Chapter 8).end planning period, team clear plan project goals , goals accomplished, goals accomplished, charge completing tasks associated goals, additional resources needed accomplish goals.","code":""},{"path":"plan.html","id":"plan-checklist","chapter":"6 Planning Data Management","heading":"6.3 Planning checklists","text":"Along existing data management plan grant application materials, checklists great tools help inform meeting agendas work planning process team. sample checklists, one phase research cycle. checklists can added amended brought planning meetings help team think various data management decisions need made phase research project.Planning checklistsRoles Responsibilities (https://osf.io/ghtc6)Task Management (https://osf.io/8x3s4Documentation (https://osf.io/bckh8)Data Collection (https://osf.io/ckwtr)Data Tracking (https://osf.io/ahz4f)Data Capture (https://osf.io/pc8nt)Data Storage Security (https://osf.io/y3z9s)Data Cleaning (https://osf.io/7t4rg)Data Archiving (https://osf.io/u4exh)Data Sharing (https://osf.io/jkgwz)Note \nfirst time working book, checklists great way summarize content chapter. learn best practices phase, pull checklist specific chapter begin thinking practices feasible specific project.","code":""},{"path":"plan.html","id":"decision-making-process","chapter":"6 Planning Data Management","heading":"6.3.1 Decision-making process","text":"decision-making process personalized. Borghi Van Gulick (2022) view process series steps research team chooses, many possibilities chosen. Maybe won’t always able implement “best practices” can decide good enough team based motivations, incentives, needs, resources, skill set, rules regulations.example, one team may collect survey data paper participants young children, hand enter Microsoft Excel tool access , double enter 20% don’t capacity enter . Another team may collect paper data collecting data field, hand enter data FileMaker tool team familiar , double enter 100% budget capacity .Figure 6.2 simplified example decision-making process, based Borghi Van Gulick (2022) flow chart. course, real life often choosing many just two options!\nFigure 6.2: simplified decision-making process\n","code":""},{"path":"plan.html","id":"checklist-considerations","chapter":"6 Planning Data Management","heading":"6.3.2 Checklist considerations","text":"’s important consider team project unique work planning checklists. technique might work well one team, may work well another. Make sure consider following:external requirements\npractices align plan laid DMP? , may need revise DMP match new decisions (remember DMP living document).\npractices meet compliance requirements (e.g., IRB requirements, department requirements, consent agreements, data sharing agreements)?\npractices align plan laid DMP? , may need revise DMP match new decisions (remember DMP living document).practices meet compliance requirements (e.g., IRB requirements, department requirements, consent agreements, data sharing agreements)?skill set team\nskill set team align practices plan implement? additional training required?\nskill set team align practices plan implement? additional training required?available tools\ntools available team?\ntools appropriate sensitivity level files?\ncomplexity tools? additional training needed?\ntools available team?tools appropriate sensitivity level files?complexity tools? additional training needed?budget\nbudget implement practices want implement, need plan something feasible?\nbudget implement practices want implement, need plan something feasible?Complexity project\nsize project, amount types data collecting, number participants populations collecting data , sensitivity level data collecting, number sites collecting data , number partners decision makers working , factor data management planning\nsize project, amount types data collecting, number participants populations collecting data , sensitivity level data collecting, number sites collecting data , number partners decision makers working , factor data management planningShared investment\nentire team invested quality data management?\nentire team motivated adhere standards instructions laid data management planning? , safeguards can implement help prevent errors creeping data?\nentire team invested quality data management?entire team motivated adhere standards instructions laid data management planning? , safeguards can implement help prevent errors creeping data?","code":""},{"path":"plan.html","id":"data-management-workflow","chapter":"6 Planning Data Management","heading":"6.4 Data management workflow","text":"last step planning phase build workflows. Workflows allow data management seamlessly integrated data collection process. Often illustrated flow diagram, workflow repeatable series sequential tasks (Lucidchart 2019) help move stages research life cycle organized efficient manner. walk checklists, can begin enter decisions workflow diagram shows actionable steps data management process. order steps follow general order data management life cycle (specifically data collection cycle). team want workflow diagram every source data sources catalog (see Section 5.3). example, collect following three items, three workflow diagrams.Student online surveyStudent paper assessmentStudent school recordsYour diagrams include , , , task process. Adding details make process actionable (Borycz 2021). diagram can displayed format works can simple detailed want . template like one Figure 6.3 works well thinking high-level workflows. Remember, repeatable process. , diagram linear (steps laid chronological order expect happen), process repeated every time collect piece data.\nFigure 6.3: simple workflow template\nFigure 6.4 might complete simplified diagram student survey.\nFigure 6.4: Example simplified student survey workflow\nformat truly matter. Figure 6.5 diagram student survey workflow Figure 6.4, detail added, time using swimlane diagram lane displays tasks associated individual iterative processes occur within across lanes.\nFigure 6.5: Example student survey workflow using swimlane diagram\nworking data collection timeline (see Section 8.2.6) already created, can even build time workflow. Figure 6.6 another example survey workflow , time displayed using Gantt chart (Duru, Kopper, Turitto 2021) order better capture expected timeline.\nFigure 6.6: Example student survey workflow using Gantt chart\nworkflow diagrams excellent high-level views process , can see unable put fine details visual. , last step creating workflow put tasks (final decisions associated tasks) standard operating procedure (SOP). SOP add necessary details process. can also attach diagram addendum link SOPs diagrams ways reference. talk creating SOPs Section 8.2.7.","code":""},{"path":"plan.html","id":"benefits-to-visualizing-a-workflow","chapter":"6 Planning Data Management","heading":"6.4.1 Benefits to visualizing a workflow","text":"Visualizing decisions diagram format many benefits. First, allows team conceptualize specific tasks process, timing tasks occur, dependencies associated tasks. also allows team see roles responsibilities fit larger research process (Briney, Coates, Goben 2020). Showing data management integrated larger research workflow can help team members view data management part daily routine, rather “extra work” (Borghi Van Gulick 2022). last, reviewing workflows team allowing members provide feedback may help create buy-data management processes, potentially leading better adherence practices.","code":""},{"path":"plan.html","id":"workflow-considerations","chapter":"6 Planning Data Management","heading":"6.4.2 Workflow considerations","text":"Similar questions need consider reviewing planning checklists, also need evaluate following things developing personalized workflows (Hansen 2017).flow preserve integrity data? point might lose comprise data?point flow data handled securely? Can someone gain access identifiable information access ?flow accordance compliance requirements?flow feasible team (based size, skill level, motivation, etc.)?flow feasible budget available resources?flow feasible amount types data collecting?bottlenecks workflow? areas resources training needed? areas tasks re-directed?","code":""},{"path":"plan.html","id":"task-management-systems","chapter":"6 Planning Data Management","heading":"6.5 Task management systems","text":"tools checklists, workflow diagrams, SOPs allow us document share processes, can tricky manage day--day implementation processes. planning phase great time choose task management system (Gentzkow Shapiro 2014). Keeping track various deadlines communications across scattered sources can overwhelming using task management system may help remove ambiguity status task progress. Rather regularly check via email status updates reading various meeting notes learn decisions made, task management system allows assign tasks responsible parties, set deadlines based timelines, track progress, capture communication decisions one location.many existing tools allow teams assign track tasks, schedule meetings, track project timelines, document communication. Without endorsing particular product, project/task management tools know education research teams used include:TrelloSmartsheetTodoistMicrosoft PlannerNotionBasecampConfluenceAsanaOf course, processes ’ve discussed far, task management system useful team trained use , invested using , actually uses part daily routine. , make sure consider choose tool, , right .","code":""},{"path":"roles.html","id":"roles","chapter":"7 Project Roles and Responsibilities","heading":"7 Project Roles and Responsibilities","text":"\nFigure 7.1: Planning research project life cycle\nPart DMP planning data management phase, noted previous chapters, include assigning roles responsibilities. terms data management, important assign document roles, just presume roles, many reasons including following (UK Data Service 2023):allows team members begin standardizing workflows.team members know exactly expected , keeps data secure.Creating contingency plans staff can longer fulfill roles allows continuity practices.","code":""},{"path":"roles.html","id":"research-project-roles","chapter":"7 Project Roles and Responsibilities","heading":"7.1 Research project roles","text":"diving assign document roles project, important get understanding typical roles education research project team. team may lucky enough , several roles. times, just one person, principal investigator, may take multiple roles. said, budget allows , highly recommend hiring individuals fill roles mentioned allow team members specialize excel area expertise. learning aspects project highly recommended create cohesive team works collaboratively, team members take many project roles can spread thin project goals may suffer.","code":""},{"path":"roles.html","id":"investigators","chapter":"7 Project Roles and Responsibilities","heading":"7.1.1 Investigators","text":"investigators, also know PIs (principal investigators) co-PIs, individuals prepare submit grant proposal responsible administration grant. often one investigator project including someone content area knowledge, well methodologist. PIs Co-PIs varying levels involvement research projects typically, always, hands day--day administration. Even tasks delegated research staff, PIs Co-PIs ultimately responsible meeting grant requirements, well requirements oversight departments partners (e.g., Institutional Review Board (IRB) submissions, agreement compliance, effort reporting, progress reporting) (Washington University St. Louis 2023).","code":""},{"path":"roles.html","id":"project-coordinator","chapter":"7 Project Roles and Responsibilities","heading":"7.1.2 Project coordinator","text":"project coordinator (project manager) essential member research team. name implies, person typically coordinates research activities ensures compliance agencies IRB. Tasks may oversee include recruitment consenting participants, creation data collection materials, creation protocols standard operating procedures (SOPs), training data collectors, data collection scheduling, . project coordinator may also supervise many research team roles, research assistants.","code":""},{"path":"roles.html","id":"data-manager","chapter":"7 Project Roles and Responsibilities","heading":"7.1.3 Data manager","text":"data manager also essential member team. person responsible organizing, cleaning, documenting, storing, dissemination research project data. team member works closely project coordinator, well investigators, ensure data management considered throughout project life cycle. Tasks data manager may oversee include data storage, security access, building data collection tracking tools, data cleaning validation, data documentation, organizing data sharing purposes.role vital maintaining standardization data practices. budget hire data manager, make sure assign someone team oversee flow data, ensuring throughout project, data documented, collected, entered, cleaned, stored consistently securely.","code":""},{"path":"roles.html","id":"project-team-members","chapter":"7 Project Roles and Responsibilities","heading":"7.1.4 Project team members","text":"role refers staff hired help implement research project may include full-time staff members, titles research project assistants instance, may include part-time team members, graduate students. Project team members often field, collecting data, may also assist areas preparing data collection materials, entering data, assisting data management. Senior project team members may also assist implementing training acting data collection leads field.","code":""},{"path":"roles.html","id":"other-roles","chapter":"7 Project Roles and Responsibilities","heading":"7.1.5 Other roles","text":"size research team roles exist dependent factors funding, type research study, intervention studied, organization specific research center. teams may include additional roles, mentioned previously, research director, lab manager, software engineer, database manager, postdoc, analyst, statistician, administrative professional, hourly data collector, outreach coordinator, coach/interventionist, may assist research cycle ways. roles assist research data life cycle seen Figure 7.1. may path hidden diagram still happening, behind scenes, alongside process. Take instance, role coach implementing intervention studied (see Figure 7.2). tasks aren’t shown original diagram work happening alongside data collection cycle.\nFigure 7.2: Life cycle diagram updated show hidden processes\n","code":""},{"path":"roles.html","id":"assigning-roles-and-responsibilities","chapter":"7 Project Roles and Responsibilities","heading":"7.2 Assigning roles and responsibilities","text":"Early project may start generally assign roles data management plan (DMP). Remember submitted DMP, often required state responsible activities data integrity security. , project funded start better idea goals budget, can flesh details roles. planning phase, using tools planning checklists help think specific responsibilities associated role. assigning roles responsibilities, several factors consider (Valentine 2011).Required skill set\nassigning roles responsibilities, consider skills needed successful position. example, considering role data manager responsibilities associated role, may look skills following buckets:\nInterpersonal skills (Detail-oriented, organized, good communicator)\nDomain skills (Experience working education data, understands data privacy - FERPA, HIPAA)\nTechnical skills (Understanding data organization, experience building data pipelines, coding experience, specific software/tool experience)\n\nspecific skills needed role depend project needs well skill sets team members.\nassigning roles responsibilities, consider skills needed successful position. example, considering role data manager responsibilities associated role, may look skills following buckets:\nInterpersonal skills (Detail-oriented, organized, good communicator)\nDomain skills (Experience working education data, understands data privacy - FERPA, HIPAA)\nTechnical skills (Understanding data organization, experience building data pipelines, coding experience, specific software/tool experience)\nInterpersonal skills (Detail-oriented, organized, good communicator)Domain skills (Experience working education data, understands data privacy - FERPA, HIPAA)Technical skills (Understanding data organization, experience building data pipelines, coding experience, specific software/tool experience)specific skills needed role depend project needs well skill sets team members.Training needs\naddition considering skills needed certain roles, also consider training needed fulfill assigned responsibilities. roles work data, training may include mandated courses program like Collaborative Institutional Training Initiative (CITI) may signing training use specific device software. Make sure team members well-equipped perform responsibilities project begins.\naddition considering skills needed certain roles, also consider training needed fulfill assigned responsibilities. roles work data, training may include mandated courses program like Collaborative Institutional Training Initiative (CITI) may signing training use specific device software. Make sure team members well-equipped perform responsibilities project begins.Estimated costs\nworking roles responsibilities grant funded, grant budget already submitted. However, can still helpful think costs associated roles (based experience/skill set person filling role) even broken associated responsibilities (based things like percent effort time complete task). discrepancies original budget updated costs found, funders often allow investigators amend budgets.\nworking roles responsibilities grant funded, grant budget already submitted. However, can still helpful think costs associated roles (based experience/skill set person filling role) even broken associated responsibilities (based things like percent effort time complete task). discrepancies original budget updated costs found, funders often allow investigators amend budgets.Assess equity responsibilities\nReview responsibilities allocated. Consider time needed complete tasks number responsibilities assigned team member. Make sure overloading one team member. quality work declines staff overloaded, reassign tasks needed.\nReview responsibilities allocated. Consider time needed complete tasks number responsibilities assigned team member. Make sure overloading one team member. quality work declines staff overloaded, reassign tasks needed.Contingency plans\nalso begin thinking backup plans staff member leave project absent extended period time. may include cross training staff plan training replacement staff.\nalso begin thinking backup plans staff member leave project absent extended period time. may include cross training staff plan training replacement staff.","code":""},{"path":"roles.html","id":"roledoc","chapter":"7 Project Roles and Responsibilities","heading":"7.3 Documenting roles and responsibilities","text":"assigning roles responsibilities, decisions documented avoid ambiguity . roles may briefly documented data management plan, important thoroughly document information well.many reasons document staff roles responsibilities store information central, accessible location.allows team easily reference document see project team, roles play, contact questions regarding various project aspects (e.g., contact data storage access).new tasks arise, team members can refer document see best fit assignment.Last, reviewing roles responsibilities document also helps clearly see responsibilities assigned assigned. reviewing document, can make revisions responsibilities need added redistributed way.Figure 7.3 one example roles responsibilities document organizes information roles. Note document lists overarching responsibilities, detailed steps associated tasks. Specific actionable steps laid process documentation standard operating procedures (see Section 8.2.7), names attached task.\nFigure 7.3: Roles responsibilities document organized role\nHowever, document can laid format conveys information clearly team. Figure 7.4 example organizing information phases research life cycle.\nFigure 7.4: Roles responsibilities organized phase\nLast, additional information can added documents help clarify responsibilities, :Links related standard operating procedures (e.g., building participant tracking database may link specific SOP lays steps building tool).Names staff members () assist also contribute responsibility.Timing responsibility (e.g., weekly, ongoing, month February).Name team members take responsibilities case team member’s absence.","code":""},{"path":"document.html","id":"document","chapter":"8 Documentation","heading":"8 Documentation","text":"\nFigure 8.1: Data documentation research project life cycle\nDocumentation collection files containing procedural descriptive information team, project, workflows, data. Creating thorough documentation study equally important collecting data. Documentation serves many purposes including:Standardizing proceduresStrategic planningSecuring data protecting confidentialityTracking data provenanceDiscovering errorsEnabling reproducibilityEnsuring others use interpret data accuratelyProviding searchability metadataThis chapter cover four levels documentation: team-level, project-level, dataset-level, variable-level. Even though currently discussing documentation phase, documents created earlier later phase, timing discussed section. project, actively using documents, format documents matter. Choose human-readable format works well team (e.g., Word, PDF, TXT, Google Doc, XLSX, HTML, OneNote, etc.). said, want long-term plan converting documents, needed, formats interoperable sustainable archiving sharing (see Chapter 15 information).documents recommended help successfully run project. can create many documents wish. documents choose produce based best project team, well required funder governing bodies. matter documents choose implement, important create templates documents implement consistently within, even across projects. Creating documentation using templates, consistent formats fields, reduces duplication efforts (need reinvent wheel) allows team interpret documents easily. documents best created team member directly oversees process, sometimes may include collaborative effort (example, project coordinator data manager may build documents together). Ultimately though, documents reviewed data management working group (DMWG) order gather feedback reach consensus (see Chapter 6).type documentation discussed living document updated procedures change, new information received. seen cyclical section Figure 8.1, team members revisit documentation time new data collected, often needed, ensure documentation still aligns actual practices. changes made added documentation long periods time, find longer remember happened information lost. also important version documents (.e., track major changes) along way staff know working recent version can see documents updated.Note \nCreating maintaining documents investment. However, return investment well worth effort. Make sure account time expertise proposal budget (see Section 5.5).","code":""},{"path":"document.html","id":"team-level","chapter":"8 Documentation","heading":"8.1 Team-level","text":"Team-level data management documentation typically contains data governance rules apply entire team, across projects. documents can amended time, started long apply grant, lab, center, institution formed (see Figure 8.2).\nFigure 8.2: Team-level documentation research project life cycle\n","code":""},{"path":"document.html","id":"lab-manual","chapter":"8 Documentation","heading":"8.1.1 Lab manual","text":"create: Team document phaseA lab manual, team handbook, creates common knowledge across team (Mehr 2020). provides staff consistent information lab culture—team works things . also sets expectations, provides guidelines, can even place passing along career advice (Aczel 2023; Turing Way Community 2022). lab manual primarily consist administrative, procedural, interpersonal types information, can helpful include data management content, including general rules accessing, storing, sharing, working data securely ethically.Templates resources","code":""},{"path":"document.html","id":"wiki","chapter":"8 Documentation","heading":"8.1.2 Wiki","text":"create: Team document phase, planning data management phaseA wiki webpage allows users collaboratively edit manage content (Figure 8.3). can either created alongside lab manual alternative lab manual. Wikis can built housed many tools (e.g., SharePoint, Teams, Notion, GitHub). lab wikis public, can restricted invited users . Wikis great way keep disparate documents pieces information, administrative data related purposes, organized central, accessible location. wiki can include links important documents policies, can also add text directly wiki describe certain procedures. Rather sending team members multiple different folders frequently requested information, can refer one wiki page.\nFigure 8.3: Example team wiki links frequently requested information\nNote \nProject-level wikis can also created useful centralizing frequently referenced information pertaining specific projects.Templates resources","code":""},{"path":"document.html","id":"onboarding-and-offboarding","chapter":"8 Documentation","heading":"8.1.3 Onboarding and offboarding","text":"create: Team document phaseWhile onboarding checklist mainly consist non-data related, administrative information sign email get set laptop, also contain several data-specific pieces information get staff generally acclimated working data new role.Similarly, offboarding checklist contain lot procedural information returning equipment handing tasks, also contain information specific data management documentation help maintain data integrity security.Data-related topics consider adding onboarding offboarding checklists included Figure 8.4.\nFigure 8.4: Sample data topics add onboarding offboarding checklists\nTemplate resources","code":""},{"path":"document.html","id":"document-inventory","chapter":"8 Documentation","heading":"8.1.4 Data inventory","text":"create: Team document phase, prepare archiving phaseA data inventory maps datasets collected research team across projects (Salfen 2018; Van den Eynden et al. 2011) (Figure 8.5). team grows, number datasets typically expands well. can helpful keep inventory datasets available team members use, well details datasets. Types information share data inventory include:Project associated datasetDates dataset collectedDetails dataset (dataset contains, organized, questions can answered data)datasets relatedStorage location dataset contact access\nFigure 8.5: Example data inventory document\n","code":""},{"path":"document.html","id":"document-security","chapter":"8 Documentation","heading":"8.1.5 Team data security policy","text":"create: Team document phaseA team-level data security policy set formal guidelines working data within organization. policy may draw information broader institutional data security policies, team-level policy written specifically group broadly cover team members allowed work data way protects research participant privacy, ensures quality control, adheres legal, ethical, technical guidelines. Documenting information ensures cohesive understanding among team members regarding terms conditions project data use (CESSDA Training Team 2017). data security policy can added lab manual, created separate document team members can even sign (Filip 2023) check box acknowledging read understand policy.Ideas content include team-level data security policy included Figure 8.6.\nFigure 8.6: Example content include team data security policy\nTemplates resources","code":""},{"path":"document.html","id":"style-guide","chapter":"8 Documentation","heading":"8.1.6 Style guide","text":"create: Team document phase, planning data management phaseA style guide set standards formatting information. improves consistency creates shared understanding within across files projects. document includes conventions procedures variable naming, variable value coding, file naming, file structure, even coding practices. can created one large document separate files type procedure. highly recommend applying style guide consistently across projects, hence included team documentation. Since style guides important, many recommended practices cover, given document chapter. See Chapter 9 information.Templates resources","code":""},{"path":"document.html","id":"project-level","chapter":"8 Documentation","heading":"8.2 Project-level","text":"Project-level documentation descriptive information project contained, well planning decisions process documentation specifically related project.","code":""},{"path":"document.html","id":"data-management-plan","chapter":"8 Documentation","heading":"8.2.1 Data management plan","text":"create: DMP phaseAs discussed Chapter 5, project federally funded likely data management plan required. project-level summary document created DMP phase, long project begins. However, DMP can continue modified throughout entire study. major changes made, may helpful reach program officer keep loop well.","code":""},{"path":"document.html","id":"document-catalog","chapter":"8 Documentation","heading":"8.2.2 Data sources catalog","text":"create: DMP phaseAlso, reviewed Section 5.3, data sources catalog excellent project planning tool developed early DMP phase. spreadsheet helps succinctly summarize data sources collect project, well plan details data collected, managed, shared. document serves referral source remaining planning phases project updated needed.","code":""},{"path":"document.html","id":"checklists-and-meeting-notes","chapter":"8 Documentation","heading":"8.2.3 Checklists and meeting notes","text":"create: DMP phase, planning data management phaseChecklists, discussed Section 6.3, documents created, copied existing templates, reviewed planning phase. Using checklists facilitates discussion allows team build cohesive understanding data managed throughout entire project. work checklists, decisions made documented meeting notes. Consider creating using template standardize flow meeting notes across various team members may take notes.Example meeting notes template.meeting notes stored central location team members can reference needed (e.g., planning folder notes ordered date, running document linked project wiki page). planning phase complete, decisions formally documented applicable team, project, data, variable-level documents (e.g., research protocol, SOPs, style guide, roles responsibilities documents). Even beyond planning phase though, meeting decisions discussions continue documented meeting notes used update formal documentation needed.","code":"Date: YYYY-MM-DD\n\nAttendees: Name1, Name2, Name3\n\nAgenda Items:\n\n  1. Topic 1\n  2. Topic 2\n  3. Topic 3\n\nAction Items:\n\n  Name1: \n    - Tasks\n  Name2: \n    - Tasks\n  Name3: \n    - Tasks\n"},{"path":"document.html","id":"roles-and-responsibilities-document","chapter":"8 Documentation","heading":"8.2.4 Roles and responsibilities document","text":"create: DMP phase, planning data management phaseUsing checklists reviewed DMP planning phase, team begin assigning roles responsibilities project. designations formally documented shared team. Chapter 7 reviewed ways structure document. document created, make sure store central location easy referral update document needed.Templates resources","code":""},{"path":"document.html","id":"document-protocol","chapter":"8 Documentation","heading":"8.2.5 Research protocol","text":"create: Documentation phaseThe research protocol comprehensive project plan describes , , , , study. Many decisions made writing data management plan reviewing planning checklists summarized document. submitting study Institutional Review Board, likely required submit document part application. research protocol assists board determining methods provide adequate protection human subjects. addition serving required purpose, research protocol also excellent document share along data time data sharing, excellent resource writing technical reports manuscripts. document provides context needed others effectively interpret use data. Make sure follow institution’s specific template provided, items commonly included protocol shown Figure 8.7.\nFigure 8.7: Common research protocol elements\ncomes time deposit data repository, protocol can revised contain information helpful data end user, known limitations data. Content risks benefits participants might removed, numbers study sample count updated show final numbers. Additional supplemental information can also added needed (see Section 8.2.6).Templates resources","code":""},{"path":"document.html","id":"document-supplement","chapter":"8 Documentation","heading":"8.2.6 Supplemental documents","text":"documents can absolutely stand alone, calling supplemental documents can also added research protocol, point, addendum clarify specifics project.TimelineWhen create: Planning data management phaseThe first supplemental document highly recommend creating visual representation data collection timeline. first create timeline, based best estimate time take complete milestones, like documents ’ve discussed, can updated learn reality workload. document can helpful planning tool (project data teams) preparing times heavier lighter workloads, well excellent document share future data users better understand waves data collection. one format create document. Figure 8.8 example one way visualize data collection timeline.\nFigure 8.8: Example data collection timeline\nParticipant flow diagramWhen create: data collectionA participant flow diagram displays movement participants study, assisting researchers better understanding milestones eligibility, enrollment, final sample counts. seen Figure 8.9, diagrams helpful assessing study attrition reasons missing data can described diagram (Nahmias et al. 2022). randomized controlled trial studies, visualizations formally referred CONSORT (Consolidated Standards Reporting Trials) diagrams (Schulz et al. 2010). provide means understand participants randomized assigned treatment groups. can imagine though, diagram started participants recruited enrolled, must updated wave data collected. participant tracking database, discuss Chapter 10, inform creation diagram.\nFigure 8.9: Example participant flow diagram\nInstrumentsWhen create: Create instruments phaseUnless form proprietary, actual copies instruments can included supplemental documentation. includes copies surveys, assessments, forms, forth. can also include technical documents associated instruments measures (.e., technical document assessment publication associated measure used). Sometimes researchers annotate instruments show items named coded.Flowchart data collection instrumentsWhen create: Create instruments phaseYou can also include flowcharts participants provided assigned different instruments screeners help users better understand issues missing data (see Figure 8.10).\nFigure 8.10: Example instrument decision making flowchart\nConsent formsWhen create: Create instruments phaseInformed consent forms (see Section 11.2.5) can also added addendum research protocols give insight information provided study participants.","code":""},{"path":"document.html","id":"document-sop","chapter":"8 Documentation","heading":"8.2.7 Standard operating procedures","text":"create: Documentation phaseWhile research protocol provides summary information decisions procedures associated project, still need documents inform procedures actually implemented daily basis (NUCATS 2023). Standard operating procedures (SOPs) provide set detailed instructions routine tasks decision-making processes. recall Chapter 6, every step added data collection workflow added SOP, details fleshed . SOP source data collecting (.e., teacher survey, student assessments, teacher observation), also SOPs decisions processes need repeated reproducible manner followed specific way maintain compliance (Hollmann et al. 2020). Many decisions laid protocol detailed SOP. Examples data management procedures include SOP provided Figure 8.11. Additional project management tasks recruitment procedures, personnel training, data collection scheduling, -field data collection routines, also documented SOPs, ensuring fidelity implementation project procedures.\nFigure 8.11: Examples data management SOPs create\naddition giving staff instruction perform tasks, SOPs also create transparency practices, allow continuity staff turnover go leave, create standardization procedures, last, SOP include versioning information, allow accurately report changes procedures throughout project. want create template used consistently across procedures, staff build SOPs (see Figure 8.12 example).\nFigure 8.12: Standard operating procedure minimal template\ndeveloping SOP template, begin general information scope purpose procedure, well relevant tools, terminology, documentation. provides context user gives background use interpret SOP. next section SOP template, procedures, lists steps order. step provides name staff member/s associated activity ensure ambiguity. step detailed possible hand SOP new staff member, background process, confident can implement procedure little trouble. Specifics names files links locations, names contacts, methods communication (e.g., email vs instant message), included. Additions screenshots, links SOPs workflow diagrams, even links online tutorials staff-created -videos can also embedded. Last, time revisions made SOP, clarifying information update added revision section new version SOP saved (see Section 9.3 ideas version file name). allows keep track changes made time, including made made .Templates resources","code":""},{"path":"document.html","id":"document-dataset","chapter":"8 Documentation","heading":"8.3 Dataset-level","text":"Dataset-level documentation applies solely datasets includes information contain related. also captures things planned transformations, potential issues aware , alterations made data. addition helpful descriptive information, huge reason creating dataset documentation authenticity. Datasets go many iterations processing can result multiple versions dataset (CESSDA Training Team 2017; UK Data Service 2023). Preserving data lineage tracking transformations errors found key ensuring know data come , processing already completed, using correct version data.","code":""},{"path":"document.html","id":"document-read","chapter":"8 Documentation","heading":"8.3.1 Readme","text":"create: time usefulA README plain text document contains information files. stem field computer science now prevalent research world. documents way convey pertinent information collaborators simple, frills manner. READMEs can used many different ways, cover three ways often used data management.conveying information colleagues\nImagine scenario study participant reaches project coordinator let know entered incorrect ID survey. project coordinator downloads raw data file cleaned data manager, also create file named “readme.txt” contains information saved alongside data file raw data folder. Now, data manager goes retrieve data file, see README included know review document first.\nImagine scenario study participant reaches project coordinator let know entered incorrect ID survey. project coordinator downloads raw data file cleaned data manager, also create file named “readme.txt” contains information saved alongside data file raw data folder. Now, data manager goes retrieve data file, see README included know review document first.Example README used convey information fileFor conveying steps process (sometimes also called setup file)\nmay times specific data pipeline reporting process requires multiple steps, opening different files running different scripts. information go SOP, programmatic-type process, completed using series scripts, might easiest put simple file named “readme_setup.txt” folder scripts someone can easily open file see need run.\nmay times specific data pipeline reporting process requires multiple steps, opening different files running different scripts. information go SOP, programmatic-type process, completed using series scripts, might easiest put simple file named “readme_setup.txt” folder scripts someone can easily open file see need run.Example README used convey information steps processFor providing information set files directory\ncan helpful add README top directories sharing data internally colleagues, sharing files external repository. can provide information datasets available directory pertinent information datasets. README can include things like description files, datasets related can linked, information associated different versions, definitions common prefixes, suffixes, acronyms used datasets, instrument response rates. Figure 8.13 example README can used describe data sources shared project repository.\ncan helpful add README top directories sharing data internally colleagues, sharing files external repository. can provide information datasets available directory pertinent information datasets. README can include things like description files, datasets related can linked, information associated different versions, definitions common prefixes, suffixes, acronyms used datasets, instrument response rates. Figure 8.13 example README can used describe data sources shared project repository.\nFigure 8.13: Example README conveying information files directory\nTemplates resources","code":"  - ID 5051 entered incorrectly. Should be 5015.\n  - ID 5089 completed the survey twice\n    - First survey is only partially completed  Step 1: Run the file 01_clean_data.R to clean the data  \n  Step 2: Run the file 02_check_errors.R to check for errors  \n  Step 3: Run the file 03_run_report.R to create report "},{"path":"document.html","id":"document-change","chapter":"8 Documentation","heading":"8.3.2 Changelog","text":"create: Version phaseAfter dataset collected, cleaned, finalized, uncommon revise file later point due errors found, addition new data. However, rather saving previous files, important use version control. Version control method recording changes file way allows track revision history revert back previous versions file needed (Briney 2015; Turing Way Community 2022). automatic ways track updates files version control programs Git, may always fit education research workflow. Institution-approved storage locations, Box SharePoint, also often versioning capabilities. programs save copies files different points time, allowing go back previous versions. However, unless users able add contextual messages changes made saving versions (e.g., commit message Git), users want manually version files.Manual version control involves two-step process. First, add version indicator file names (see Section 9.3 ideas version file name). file revised, copy saved indicator updated. Second, description change recorded changelog—historical record major file changes (UK Data Service 2023; Wilson et al. 2017) (see Figure 8.14).Manually versioning file names keeping date changelog serves many purposes. First, supports reproducibility. file used analysis file saved new version, original findings analysis can longer reproduced (Turing Way Community 2022). Version control also reduces data rot (Henry 2021) providing data lineage, allowing user understand data originated well transformations made data. Last, supports data confidence, allowing user understand version data currently using, decide using recently created version file.simplest form changelog contain following (Schmitt Burchinal 2011):file nameThe date file createdA description dataset (including changes made compared previous version)can also helpful record additional information made change link code used transform data (CESSDA Training Team 2017).\nFigure 8.14: Example changelog clean student survey data file\nTemplates resources","code":""},{"path":"document.html","id":"document-plan","chapter":"8 Documentation","heading":"8.3.3 Data cleaning plan","text":"create: Documentation phaseA data cleaning plan written proposal outlining plan transform raw data clean, usable data. document contains code technical skills dependent. data cleaning plan created dataset listed data sources catalog (see Section 8.2.2). Since document lays intended transformations raw dataset, allows team member provide feedback data cleaning process.document can started documentation phase, likely continue updated throughout study. Typically, person responsible cleaning data write data cleaning plans, documents can brought planning meeting allowing DMWG provide input plan. ensures everyone agrees transformations performed. finalized, data cleaning plan serves guide cleaning process. addition changelog, data cleaning plan (well syntax used changelog) provides documentation necessary assess data provenance, historical record data file’s journey.data cleaning plan based agreed-upon norms constitutes clean dataset help ensure datasets cleaned formatted consistently (see Section 14.2). norms can operationalized checklist transformations can inform data cleaning plan, along data dictionary relevant documentation. review types transformations consider adding data cleaning plan Section 14.3.example simplified data cleaning plan student survey file.","code":"1. Import raw data\n2. Review data (rows and columns)\n3. Remove duplicate cases if they exist (using rules from applicable SOP and README)\n4. De-identify data (bring in study IDs and remove names)\n5. Rename variables based on data dictionary\n6. Fix variable types as needed\n7. Reverse code anx1, anx2, anx3\n8. Calculate anx_mean\n9. Merge in treatment and tch_id variables from roster file\n10. Add missing value codes\n11. Add variable and value labels based on data dictionary\n12. Run final data validation checks\n13. Export data as an SPSS file\n"},{"path":"document.html","id":"variable-level","chapter":"8 Documentation","heading":"8.4 Variable-level","text":"think data management, think likely first type documentation pops people’s minds. Variable-level documentation tells us pertinent information variables datasets: variable names, descriptions, types, allowable values. documentation often used interpret existing datasets, can also serve many vital purposes including guiding construction data collection instruments, assisting data cleaning, validating accuracy data. discuss throughout chapters book.","code":""},{"path":"document.html","id":"document-dictionary","chapter":"8 Documentation","heading":"8.4.1 Data dictionary","text":"create: Documentation phase, sometimes data capture phase external datasetsA data dictionary rectangular formatted collection names, definitions, attributes variables dataset (Bordelon 2023; Gonzales, Carson, Holmes 2022; UC Merced Library 2023). document useful created documentation phase used throughout study planning interpretation purposes (see Figure 8.15) (Lewis 2022a; Van Bochove, Alper, Gu 2023).\nFigure 8.15: many uses data dictionary\ndata dictionary typically structured row represents variable dataset, column represents field information variable (Broman Woo 2018; Grynoch 2023). several necessary fields include data dictionary, well several optional fields (see Table 8.1).Table 8.1: Fields include data dictionaryYou build one data dictionary instrument plan collect, including original data collection instruments well external data sources (e.g., student education records). five data sources data sources catalog, end five data dictionaries.","code":""},{"path":"document.html","id":"document-original","chapter":"8 Documentation","heading":"8.4.1.1 Creating a data dictionary for an original data source","text":"collecting original data, things helpful creating data dictionaries:data sources catalog\ndocument (see Section 8.2.2) provide overview data sources plan collect project, including measures make instrument.\ndocument (see Section 8.2.2) provide overview data sources plan collect project, including measures make instrument.style guide\ntalk style guides Chapter 9, document provide team project standards naming variables coding response values.\ntalk style guides Chapter 9, document provide team project standards naming variables coding response values.Documentation measures\ncollecting data using existing measures (.e., existing scales, existing standardized assessments), want collect documentation measures, technical documents copies instruments. want documentation provide information :\nitems included measure? exact wording items?\nitems divided subscales?\nitems coded? allowable values?\ncalculations/scoring/reverse coding needed?\nitems entered scoring program exported, variables exported?\n\nSee Figure 8.16 example information pulled publication using Math Anxiety Scale Teachers (MAST) (Ganley et al. 2019).\ncollecting data using existing measures (.e., existing scales, existing standardized assessments), want collect documentation measures, technical documents copies instruments. want documentation provide information :\nitems included measure? exact wording items?\nitems divided subscales?\nitems coded? allowable values?\ncalculations/scoring/reverse coding needed?\nitems entered scoring program exported, variables exported?\nitems included measure? exact wording items?items divided subscales?items coded? allowable values?calculations/scoring/reverse coding needed?items entered scoring program exported, variables exported?See Figure 8.16 example information pulled publication using Math Anxiety Scale Teachers (MAST) (Ganley et al. 2019).data element standards plan use\nSee Section 11.2.1 overview existing data element standards\nSee Section 11.2.1 overview existing data element standards\nFigure 8.16: Pulling relevant information Math Anxiety Scale Teachers (MAST)\nmeasures/items instrument included data dictionary. build data dictionaries, consider following:Item names\nvariable names meeting requirements laid style guide?\nfield standards dictate item named?\nvariable names meeting requirements laid style guide?field standards dictate item named?Item wording\nitems come existing scale, item wording match wording scale documentation? plan reword item?\nfield standards dictate item worded?\nitems come existing scale, item wording match wording scale documentation? plan reword item?field standards dictate item worded?Item value codes categorical items\nitems come existing scale, value coding (numeric values assigned categorical response options) align coding laid scale documentation?\nitems come existing scale, value coding align requirements style guide?\nfield standards dictate item’s values coded?\nitems come existing scale, value coding (numeric values assigned categorical response options) align coding laid scale documentation?items come existing scale, value coding align requirements style guide?field standards dictate item’s values coded?additional items make final dataset? Consider items derived, collected metadata, added . included data dictionary.\nUnique study identifiers (see Section 3.3.1)\nPrimary keys (e.g., stu_id, rater_id)\nForeign keys needed (e.g., tch_id student file)\n\nGrouping variables (e.g., treatment, cohort, cluster, block)\nTime component (e.g., wave, time, year, session)\nDerived variables\nincludes variables team derives (e.g., mean scores, reverse coded variables, variable checks) well variables derived scoring programs (e.g., percentile ranks, standard scores)\ndescribing variables calculated, make sure account anomalies calculating scores missing data\n\n\nMetadata (Variables tool collects IP Address, completion, language)\nUnique study identifiers (see Section 3.3.1)\nPrimary keys (e.g., stu_id, rater_id)\nForeign keys needed (e.g., tch_id student file)\nPrimary keys (e.g., stu_id, rater_id)Foreign keys needed (e.g., tch_id student file)Grouping variables (e.g., treatment, cohort, cluster, block)Time component (e.g., wave, time, year, session)Derived variables\nincludes variables team derives (e.g., mean scores, reverse coded variables, variable checks) well variables derived scoring programs (e.g., percentile ranks, standard scores)\ndescribing variables calculated, make sure account anomalies calculating scores missing data\n\nincludes variables team derives (e.g., mean scores, reverse coded variables, variable checks) well variables derived scoring programs (e.g., percentile ranks, standard scores)\ndescribing variables calculated, make sure account anomalies calculating scores missing data\ndescribing variables calculated, make sure account anomalies calculating scores missing dataMetadata (Variables tool collects IP Address, completion, language)items removed public data sharing (.e., personally identifiable information)?Figure 8.17 provides example simplified teacher survey data dictionary, including items MAST scale (Ganley et al. 2019).\nFigure 8.17: Example teacher survey data dictionary\nlast step creating data dictionary, review document team. Gather DMWG review following types questions:everyone agreement variables named, acceptable variable ranges, values coded, variable types formats?everyone agreement participants receive item (e.g., everyone specific group)?team want adjust item wording?data dictionary include everything team plans collect? items missing?\nadditional items added instruments later points longitudinal collection, adding fields data dictionary, time periods available, can really helpful future users understanding items may missing data certain time points.\nadditional items added instruments later points longitudinal collection, adding fields data dictionary, time periods available, can really helpful future users understanding items may missing data certain time points.dictionary include variables plan derive? (.e., either derived team, external scoring system)?","code":""},{"path":"document.html","id":"document-extant","chapter":"8 Documentation","heading":"8.4.1.2 Creating a data dictionary from an existing data source","text":"research study data gathered original data collection methods. may capturing supplemental external data sources organizations like school districts state departments education. possible, start gathering information external data sources early , planning documentation phases, begin adding information data dictionary. Starting process early help prepare future data capture cleaning processes.data source public, may able easily find codebooks data dictionaries data source. , download sample data learn variables exist source formatted.data source non-public, request documentation ahead time partner (see Section 12.3).However, possible may able access information acquire actual data data capture phase. documentation provided along data, begin reviewing data ensure documentation matches see data. Integrate information project data dictionary.documentation provided important review data begin collecting questions allow build data dictionary.variables represent?\nwording items?\nwording items?items collected (e.g., students specific grade level)?values represent?\nseeing full range values/categorical options item? range larger seeing?\nvalues data don’t make sense item (e.g., 999 0 age variable)?\nseeing full range values/categorical options item? range larger seeing?values data don’t make sense item (e.g., 999 0 age variable)?data types items currently? types ?situations questions easily answered without documentation may require detective work.Contact person originally collected data learn instrument data collection process.Contact person cleaned data (cleaned) see transformations completed raw data.applicable, request access original instruments review exact question wording, item response options, skip patterns, etc.Ultimately end data dictionary structured similarly Figure 8.17. may add additional fields help keep track changes (e.g., column old variable name column new variable name), transformations section may become verbose values assigned previously may align values prefer based style guide original measures. Otherwise, data dictionary still constructed manner mentioned Section 8.4.1.1.","code":""},{"path":"document.html","id":"time-well-spent","chapter":"8 Documentation","heading":"8.4.1.3 Time well spent","text":"process described section manual, time consuming process. intentional. Building data dictionary information seeking journey take time understand dataset, standardize items, plan data transformations. Spending time manually creating document collecting data prevents many potential errors time lost fixing data future. absolutely ways can automate creation data dictionary using existing dataset, time can imagine useful clean dataset confidently already verified accurate ready shared. However, mentioned , data dictionary much document shared alongside public dataset. tool guiding many processes research life cycle.Templates Resources","code":""},{"path":"document.html","id":"document-codebook","chapter":"8 Documentation","heading":"8.4.2 Codebook","text":"create: Data cleaning validation phase, prepare archive phaseCodebooks provide descriptive, variable-level information well univariate summary statistics allow users understand contents dataset without ever opening . Unlike data dictionary, codebook created data collected cleaned, value lies data interpretation data validation.codebook contains information overlaps data dictionary, summary document actually exists dataset (ICPSR 2011) (see Table 8.2).Table 8.2: Codebook content overlaps unique data dictionaryIn addition excellent resource users review data without ever opening file, document may also help catch errors data range unexpected values appear.can create separate codebooks per dataset contained one document, linked table contents. Unlike data dictionary, recommend creating manually, codebook created automated process. Automating codebooks save tons time, also reduce errors made manual entry. can use many tools create codebooks, including point click statistical programs SPSS, little programming knowledge can flexibly design codebooks using programs like R SAS. R programming language particular many packages create export codebooks variety formats existing dataset 53. Figure 8.18 example codebook created R using memisc package (Elff 2023).\nFigure 8.18: Example teacher survey codebook content\nLast, may notice review codebooks created researchers, many start several pages text, usually containing information project. comes time share data, ’s common people combine information research protocol README files, codebooks, rather sharing separate documents.Templates resources","code":""},{"path":"document.html","id":"document-metadata","chapter":"8 Documentation","heading":"8.5 Repository metadata","text":"create: Share archive phaseWhen comes time deposit project resource repository, submit two types documentation, human-readable documentation, includes documents ’ve previously discussed, metadata. Metadata, data data, documentation meant processed machines serves purpose making files searchable (CESSDA Training Team 2017; Danish National Forum Research Data Management 2023). Metadata aids cataloging, citing, discovering, retrieving data creation critical step creating FAIR data (see Section 2.4.1) (Logan, Hart, Schatschneider 2021; UK Data Service 2023 ; Wilkinson et al. 2016).part, additional work needed create metadata depositing data repository. simply created part depositing process (CESSDA Training Team 2017; University Iowa Libraries 2023). deposit data, repository may fill form. information collected intake form become metadata. Figure 8.19 example metadata form OSF (https://osf.io).\nFigure 8.19: Example metadata intake form OSF\nmetadata forms typically contain descriptive (description project files), administrative (licensing ownership well technical information), structural (relationships objects) metadata (Cofield 2023; Danish National Forum Research Data Management 2023). Commonly collected metadata elements (Dahdul 2023; Hayslett 2022) shown Table 8.3.Table 8.3: Common metadata elementsDepending repository, minimum, enter basic project-level metadata similar shown Table 8.3. However, may required, option, enter comprehensive information, project-level information covered research protocol (e.g., setting sample, study procedures). may also option enter additional levels metadata help make level searchable, file-level variable-level metadata (Gilmore, Kennedy, Adolph 2018; ICPSR 2023a; LDbase 2023). information needed metadata can gathered documents ’ve discussed earlier chapter.ways metadata can gathered well. instance, variable-level metadata, rather users input metadata, repositories may create metadata deposited statistical data files contain embedded metadata (variable types labels) deposited documentation data dictionaries codebooks (ICPSR 2023a).repository provides limited forms metadata entry, can also choose increase searchability files creating machine-readable documents. several tools help users create machine-readable codebooks data dictionaries findable search engines Google Dataset Search (Arslan 2019; Buchanan et al. 2021; USGS 2021).","code":""},{"path":"document.html","id":"metastandards","chapter":"8 Documentation","heading":"8.5.1 Metadata standards","text":"Metadata standards, typically field specific, establish common way describe data improves data interoperability well ability users find, understand, use data. Metadata standards can applied several ways (Bolam 2022; Cofield 2023).Formats: machine-readable format metadata ?Schema: elements recommended verses mandatory project, dataset, variable-level metadata?Controlled vocabularies: controlled list terms used index retrieve data.Many fields chosen metadata standards adhere (Berry 2022; Bolam 2022) (see Figure 8.20). fields, like psychology (Kline 2018), developing metadata standards, including formats, schemas, vocabularies grounded FAIR principles Schema.org schema (Schema.org 2023). Yet, Institute Education Sciences recognizes currently agreed-upon metadata standards field education (Institute Education Sciences 2023a).\nFigure 8.20: sampling field metadata standards\nplan archive data, first check repository see follow standards. example, OSF (Gueguen 2023) Figshare (Figshare 2023) repositories currently use DataCite schema, ICPSR uses DDI standard (ICPSR 2023a). repository use certain standards, work ensure metadata adheres standards. repositories may even provide curation support free fee. mentioned earlier, depending repository, adding metadata project may require additional work part. repository may simply enter information form convert information .standards provided repository plan create metadata, can choose standard works . Oftentimes researchers may choose pick general standard DataCite Dublin Core (University Iowa Libraries 2023), field education, researchers least familiar DDI standard another good option. Remember, choose adhere standard, decision documented data management plan.Resources","code":""},{"path":"document.html","id":"wrapping-it-up","chapter":"8 Documentation","heading":"8.6 Wrapping it up","text":"point head might spinning number documents ’ve covered. ’s important understand document discussed provides unique meaningful purpose, don’t create every document listed. data management walk fine line creating sufficient documentation spending working hours perfecting documenting every detail project. Choose documents help record structure processes best way project also giving grace stop documents “good enough”. document create well organized well maintained improve data management workflow, decrease errors, enhance understanding data.","code":""},{"path":"style.html","id":"style","chapter":"9 Style Guide","heading":"9 Style Guide","text":"\nFigure 9.1: Style guide research project life cycle\nstyle guide provides general rules formatting information. mentioned Chapter 8, style guides can created standardize procedures variable naming, variable value coding, file naming, file structure, even coding practices.Style guides create standardization within across projects. benefits using consistently include:Creating interoperability: allows data easily combined compared across forms time.Improving interpretation: Consistent clear structure, naming, coding allows files variables findable understandable humans computers.Increasing reproducibility: organization file paths, file naming, variable naming constantly change, undermines reproducibility data management analysis code written.Style guides can created individual projects, can also created team level, applied across projects. importantly, created project kicks can implement soon project begins. team-wide style guide already created, likely want create project-level style guide planning phase can begin setting directory structures file naming standards start creating saving project-related files.Style guides can housed one large document, table contents used reference section, can created separate documents. Either way, style guides stored central location easily accessible team members (team project wiki), team members trained, periodically retrained, style guide ensure adherence rules. team members consistently implementing style guide, benefits guide lost.remainder chapter, spend time reviewing best practices consider creating style guides following purposes:Structuring directoriesNaming filesNaming variablesAssigning variable valuesWriting code","code":""},{"path":"style.html","id":"style-practices","chapter":"9 Style Guide","heading":"9.1 General good practices","text":"dive particular types style guides, things know computers read names order understand “” behind practices.Avoid spaces.\nCommand line operations operating systems support , best avoid together. Furthermore, can often break URL shared.\nunderscore (_) hyphen (-) good delimiters use place spaces.\nworth noting (_) can difficult read file paths shared links underlined denote path clickable (example sharing SharePoint link document).\n\nCommand line operations operating systems support , best avoid together. Furthermore, can often break URL shared.underscore (_) hyphen (-) good delimiters use place spaces.\nworth noting (_) can difficult read file paths shared links underlined denote path clickable (example sharing SharePoint link document).\nworth noting (_) can difficult read file paths shared links underlined denote path clickable (example sharing SharePoint link document).exception (_) (-), avoid special characters.\nExamples include limited ?, ., *, \\, /, +, ', &, \".\nComputers assign specific meaning many special characters.\nExamples include limited ?, ., *, \\, /, +, ', &, \".Computers assign specific meaning many special characters.several existing naming conventions can choose add style guide. Different naming conventions may work better different purposes. Using conventions help consistent delimiters capitalization, makes names human-readable also allows computer read search names easier.\nPascal case (ScaleSum)\nSnake case (scale_sum)\nCamel case (scaleSum)\nKebab case (scale-sum)\nTrain case (Scale-Sum)\nPascal case (ScaleSum)Snake case (scale_sum)Camel case (scaleSum)Kebab case (scale-sum)Train case (Scale-Sum)Character length matters. Computers unable read names surpass certain character length. applies file paths, file names, variable names. Considerations type limit reviewed .","code":""},{"path":"style.html","id":"directory-structure","chapter":"9 Style Guide","heading":"9.2 Directory structure","text":"deciding structure project directories (organization folders files within operating system), several things want consider.structuring folders:First, consider organizing directory hierarchical folder structure clearly delineate segments projects improve searchability.\nalternative using folder structure using metadata tagging organize search files (Cakici 2017; Fuchs Kuusniemi 2018; Krishna 2018).\nalternative using folder structure using metadata tagging organize search files (Cakici 2017; Fuchs Kuusniemi 2018; Krishna 2018).creating folder structure, strike balance deep shallow structure.\nshallow leads many files one folder difficult sort .\ndeep leads many clicks get one file, plus file paths can max many. characters. file path includes full length folders file name.\nexample file path 73 characters W:\\team\\project_new\\data\\wave1\\student\\survey\\pn_w1_stu_svy_clean_v02.csv\n\nExamples file path limits:\nSharePoint/OneDrive path limit 400 characters (Microsoft 2023)\nWindows path limit 260 characters (Ashcraft 2022)\n\nshallow leads many files one folder difficult sort .deep leads many clicks get one file, plus file paths can max many. characters. file path includes full length folders file name.\nexample file path 73 characters W:\\team\\project_new\\data\\wave1\\student\\survey\\pn_w1_stu_svy_clean_v02.csv\nexample file path 73 characters W:\\team\\project_new\\data\\wave1\\student\\survey\\pn_w1_stu_svy_clean_v02.csvExamples file path limits:\nSharePoint/OneDrive path limit 400 characters (Microsoft 2023)\nWindows path limit 260 characters (Ashcraft 2022)\nSharePoint/OneDrive path limit 400 characters (Microsoft 2023)Windows path limit 260 characters (Ashcraft 2022)Create folders specific enough can limit access.\nexample, want limit user access folders hold personally identifiable information (PII).\nprotect files don’t want others accidentally edit (example clean datasets), also consider making files “read ”.\nexample, want limit user access folders hold personally identifiable information (PII).protect files don’t want others accidentally edit (example clean datasets), also consider making files “read ”.Decide want “archive” folder move old files want leave previous versions folder.Ultimately, create structure consistently applied.\nexample, project includes three phases intervention, consider creating “phase” folders top directory content folders creating content folders top directory phase folders . mix match methods. leads confusion searching files.\nexample, project includes three phases intervention, consider creating “phase” folders top directory content folders creating content folders top directory phase folders . mix match methods. leads confusion searching files.Top level phase foldersTop level content foldersWhen naming folders:Consider setting character limit folder names (reduce problems hitting path character limits).Make folder names meaningful easy interpret.Don’t use spaces folder names.\nUse _ - separate words.\nUse _ - separate words.exception - _, don’t use special characters folder names.consistent delimiters capitalization. Follow existing naming convention (mentioned Section 9.1).Example directory structure style guideExample directory structure created using style guide","code":"project_new/\n├── phase1\n|   ├── planning\n|   |   └── ...\n|   ├── documentation\n|   |   └── ...\n|   └── ...\n├── phase2\n|   ├── planning\n|   |   └── ...\n|   ├── documentation\n|   |   └── ...\n|   └── ...\n└── ...\nproject_new/\n├── planning\n|   ├── phase1\n|   |   └── ...\n|   ├── phase2\n|   |   └── ...\n|   └── ...\n├── documentation\n|   ├── phase1\n|   |   └── ...\n|   ├── phase2\n|   |   └── ...\n|   └── ...\n└── ...\n1. All project directories follow this hierarchical metadata structure  \n    - Level 1: Name of project  \n    - Level 2: Life cycle folders  \n    - Level 3: Data collection wave folders (if relevant)  \n    - Level 4: Participant group folder (if relevant)\n    - Level 5: Specific content folder/s  \n    - Level 6: Archive folder  \n2. All folders should be named according to these rules  \n    - Meaningful name but no longer than 20 characters  \n    - No spaces or special characters except (_)\n    - Only use lower case letters  \n    - Use (_) to separate words  \n    - Consistently named across waves of data collection\n3. All previous versions of files must be placed into their respective \"archive\" folder\n        - A changelog should be placed in all data \"archive\" folders to document changes between file versions\nproject_new/\n├── planning\n|   ├── grant_mgmt\n|   |   ├── proposal_docs\n|   |   |   └── ...\n|   ├── meetings\n|   |   ├── agendas\n|   |   |   └── ...\n|   └── ...\n├── documentation\n|   ├── consent_forms\n|   |   └── ...\n|   ├── data_dictionaries\n|   |   └── ...\n|   ├── data_sources_catalog.xlsx\n|   ├── instrument_copies\n|   |   └── ...\n|   ├── research_protocol.docx\n|   ├── sops\n|   |   └── ...\n|   └── ...\n├── data_collection\n|   ├── hiring_materials\n|   |   └── ...\n|   ├── scheduling_materials\n|   |   └── ...\n|   └── ...\n├── tracking\n│   ├── parent_consents\n|   |   └── ...\n│   └── participant_tracking_database.accdb\n├── data\n│   ├── cohort1\n│   |   ├── student\n|   |   |   ├── survey\n|   |   |   |   └── clean\n|   |   |   |   |   ├── archive\n|   |   |   |   |   |   └── changelog.txt\n|   |   |   |   └── raw\n|   |   |   |   |   ├── archive\n|   |   |   |   |   |   └── changelog.txt\n|   |   |   └── ... \n|   |   └── ...\n|   └── ...   \n└── ...\n"},{"path":"style.html","id":"style-file","chapter":"9 Style Guide","heading":"9.3 File naming","text":"\nFigure 9.2: “Documents”, xkcd.com\nseen Figure 9.2, naming files consistent usable way hard. often rush save files maybe don’t consider unclear file names future users (including ).file names alone able answer questions :documents?documents created?document recent version?file naming style guide helps us name files way allows us answer questions. can one overarching file naming guide, may file naming guides different purposes need different organizational strategies (e.g., one naming guide project meeting notes, another naming guide project data files). Let’s walk several conventions consider naming files.Make names descriptive (user able understand contents file without opening ).PII used file name (e.g., participant name).Never use spaces words.\nUse (-) (_) separate words.\nUse (-) (_) separate words.exception (_) (-), never use special characters.consistent delimiters capitalization. Follow existing naming convention (see Section 9.1).Consider limiting number allowable characters prevent hitting path limit.\ninstance, Harvard Longwood Research Data Management (2023) recommends keeping file names 40-50 characters.\ninstance, Harvard Longwood Research Data Management (2023) recommends keeping file names 40-50 characters.Format dates consistently use forward slashes (/) separate parts date. beneficial format dates using ISO 8601 standard one two ways:\nYYYY-MM-DD YYYYMMDD\nUsing ISO 8601 standard ensures dates consistently formatted correctly interpreted (e.g., “06-01-2023” interpreted DD-MM-YYYY Europe, often interpreted MM-DD-YYYY U.S.).\n\nusing delimiters parts date adds characters variable names, also may clearer users interpret. Either date formats sortable.\nYYYY-MM-DD YYYYMMDD\nUsing ISO 8601 standard ensures dates consistently formatted correctly interpreted (e.g., “06-01-2023” interpreted DD-MM-YYYY Europe, often interpreted MM-DD-YYYY U.S.).\nUsing ISO 8601 standard ensures dates consistently formatted correctly interpreted (e.g., “06-01-2023” interpreted DD-MM-YYYY Europe, often interpreted MM-DD-YYYY U.S.).using delimiters parts date adds characters variable names, also may clearer users interpret. Either date formats sortable.manually versioning file names (see Section 8.3.2), pick consistent indicator use.\nOne method add number file name. Using method, consider left padding single numbers 0 keep file name length grows (v01, v02).\nAnother method add date file name, using ISO 8601 standard.\nOne method add number file name. Using method, consider left padding single numbers 0 keep file name length grows (v01, v02).Another method add date file name, using ISO 8601 standard.files need run sequential order, add order number beginning file name, leading zeros ensure proper sorting (01_, 02_).Choose abbreviations use common phrases (student = stu).\nhelps reduce file name character lengths also creates standardized, searchable metadata, can allow easily, programmatically retrieve files (example, retrieve files containing phrase “stu_obs_raw”).\nhelps reduce file name character lengths also creates standardized, searchable metadata, can allow easily, programmatically retrieve files (example, retrieve files containing phrase “stu_obs_raw”).Keep redundant metadata file name.\nreduces confusion ever move file different folder send file collaborator. also makes files searchable.\nexample, always put data collection wave file name, even file currently housed specific wave folder, always put project name file name, even file currently housed project folder, always put word “raw” “clean” file name, even file housed “raw” “clean” folder.\nreduces confusion ever move file different folder send file collaborator. also makes files searchable.example, always put data collection wave file name, even file currently housed specific wave folder, always put project name file name, even file currently housed project folder, always put word “raw” “clean” file name, even file housed “raw” “clean” folder.Choose order file name metadata (e.g., project -> time -> participant -> instrument).Example file naming style guideExample file names created using style guide","code":"1. Never use spaces between words\n2. Never use special characters except (_) or (-)\n3. Use (_) to separate words\n4. Only use lower case letters\n5. Keep names under 50 characters\n6. Format dates as YYYY-MM-DD\n7. Use the following metadata file naming order\n  - Order of use (if relevant – add a 0 before single digits)\n  - Project\n  - Cohort/Wave (if relevant)\n  - Participant group\n  - Instrument\n  - Further description\n  - Version\n    - For raw data files, use date\n    - For clean data files, code files, or SOPs use version number (add a 0 before single digits)\n8. Use the following abbreviations\n  - student = stu\n  - teacher = tch\n  - survey = svy\n  - observation = obs\n  - wave = w\n  - project new = pn\npn_stu_svy_sop_v03.docx\npn_w1_tch_obs_raw_2023-11-03.csv\npn_w1_stu_svy_raw_entry1_2023-11-15.csv\npn_w1_stu_svy_raw_entry2_2023-11-15.csv\npn_w1_stu_svy_clean_syntax_v01.R\npn_w1_stu_svy_clean_syntax_v02.R\n"},{"path":"style.html","id":"style-varname","chapter":"9 Style Guide","heading":"9.4 Variable naming","text":"style guide necessary document start create data dictionaries. several considerations review developing variable naming style guide. broken two types rules, non-negotiable requirements really included style guide (follow rules run serious problems interpretation humans machines), best practice suggestions recommended required.Mandatory:Don’t name variable keywords functions used programming language (, , repeat) (R Core Team 2023; Stangroom 2019).Set character limit.\nstatistical programs limit variable name characters.\nSPSS 64\nStata 32\nSAS 32\nMplus 8\nR 10,000\n\nsaid, limit 8 characters based fact one future user may use program like Mplus. Consider balance character limit interpretation. difficult make good human-readable variable names 8 characters. much easier make 32. Also, users using program limit 32 . one potential Mplus user, can always rename variables specific analysis.\nstatistical programs limit variable name characters.\nSPSS 64\nStata 32\nSAS 32\nMplus 8\nR 10,000\nSPSS 64Stata 32SAS 32Mplus 8R 10,000With said, limit 8 characters based fact one future user may use program like Mplus. Consider balance character limit interpretation. difficult make good human-readable variable names 8 characters. much easier make 32. Also, users using program limit 32 . one potential Mplus user, can always rename variables specific analysis.Use variable name across time project.\nitem named anx1 fall, name item anx1 spring (see Section 9.4.1 discussion accounting time).\nitem named anx1 fall, name item anx1 spring (see Section 9.4.1 discussion accounting time).Don’t use spaces special characters, except (_). allowed programs.\nEven (-) allowed programs R SPSS can mistaken minus sign.\n(.) allowed R SPSS allowed Stata ’s best avoid using .\nEven (-) allowed programs R SPSS can mistaken minus sign.(.) allowed R SPSS allowed Stata ’s best avoid using .start variable name number. allowed many statistical programs.variable names unique.\nabsolutely applies variables within dataset, also apply variables across datasets within project. reason , point may merge data across forms end identical variable names (programs allow).\n, example, collect student gender survey also collect student gender district student records, differentiate two (s_gender d_gender).\nexception variables collected across time. Identical variables named consistently across waves data collection. See Section 9.4.1 information accounting time.\nabsolutely applies variables within dataset, also apply variables across datasets within project. reason , point may merge data across forms end identical variable names (programs allow)., example, collect student gender survey also collect student gender district student records, differentiate two (s_gender d_gender).exception variables collected across time. Identical variables named consistently across waves data collection. See Section 9.4.1 information accounting time.substantively change item (substantive wording response options change) least one round data collected, version variable names reduce errors interpretation.\nexample, revised anx1 becomes anx1_v2.\nexample, revised anx1 becomes anx1_v2.Suggested:Names meaningful.\nInstead naming gender q1, name gender.\nvariable part scale, consider using abbreviation scale plus scale item number (anx1, anx2, anx3).\nallow easily associate item scale, also allows programmatically select manipulate scale items (example, sum items start “anx”).\n\nInstead naming gender q1, name gender.variable part scale, consider using abbreviation scale plus scale item number (anx1, anx2, anx3).\nallow easily associate item scale, also allows programmatically select manipulate scale items (example, sum items start “anx”).\nallow easily associate item scale, also allows programmatically select manipulate scale items (example, sum items start “anx”).used item , consider keeping variable name across projects. can useful ever want combine data across projects. also allows easily reuse code snippets across projects (e.g., scoring measure).Choose standard abbreviations denote types variable working (standard score = ss). Using controlled vocabularies improves interpretation makes data exploration manipulation easier (Riederer 2020).consistent delimiters capitalization. Follow existing naming convention. programming languages case sensitive consider choosing convention feasible workflow.\nSnake case (scale_sum) – preferred method variable names\npascal case camel case also options, use underscores helps clearly delineate relevant pieces metadata variable names.\n\nKebab case (scale-sum) – don’t use variable names\nTrain case (Scale-Sum) – don’t use variable names\nSnake case (scale_sum) – preferred method variable names\npascal case camel case also options, use underscores helps clearly delineate relevant pieces metadata variable names.\npascal case camel case also options, use underscores helps clearly delineate relevant pieces metadata variable names.Kebab case (scale-sum) – don’t use variable namesTrain case (Scale-Sum) – don’t use variable namesIf variable includes “select ” option, start associated variables prefix (cert_elem, cert_secondary, cert_leader, cert_other). , allows easily see grouped items, well easily programmatically manipulate items needed.Consider denoting reverse coding variable name reduce confusion (anx1_r).Include indication reporter variable name (student self-report = s). can also help unique variable name requirement .Choose order variable name metadata (e.g., reporter -> variable name -> item number/type).Example variable naming style guideExample variable names created using style guide","code":"1. Use snake case\n2. Keep names under 32 characters\n3. Use meaningful variable names\n4. Use unique variable names within and across data sources\n5. Use consistent variable names across waves of data collection\n6. If part of a scale, use scale/subscale abbreviation plus item number from the scale. \n  - If the scale has been used in another project, keep the same name from previous projects.\n7. Include an indication of the reporter as a prefix in the variable name\n  - student self-report = s_\n  - teacher self-report = t_\n  - district student records = d_\n8. Denote reverse coded variables using suffix _r\n9. Follow this metadata order for variable names\n  - Reporter\n  - Item name (or scale abbreviation)\n  - Subscale abbreviation (if relevant)\n  - Item number (if relevant)\n  - Variable type (if relevant)\n  - Recode (if relevant)\n9. Use the following abbreviations\n  - mean = m\n  - standard score = ss\n  - percentile rank = pr\n  - other, open text = text\n  - date = dt\ns_wj_lwi_dt\ns_wj_lwi1\ns_wj_lwi2\ns_wj_lwi_ss\ns_wj_lwi_pr\ns_gender\nd_gender\nt_profdev\nt_profdev_text\nt_stress5\nt_stress5_r\nt_stress_m\n"},{"path":"style.html","id":"style-time","chapter":"9 Style Guide","heading":"9.4.1 Time","text":"moving one last consideration variable names. data longitudinal (.e., collecting repeated measures), may need add rules accounting time variable names well. Recall Section 3.3.2, two ways can link structure longitudinal data, wide format long format.combining data time long format, changes need made variable names. Variable names identically named time. account time component, simply include new variable (e.g., time, year, wave) add appropriate value row.combining data time long format, changes need made variable names. Variable names identically named time. account time component, simply include new variable (e.g., time, year, wave) add appropriate value row.combining data wide format, need concatenate time time-varying variable names (.e., subject unique identifier). removes problem non-unique variable names (e.g., anx1 wave 1 anx1 wave 2) allows interpret variable collected. concatenate time variable names . Just make sure continue adding time consistently variable names (.e., location, format) remember follow variable naming best practices (e.g., never start variable name number).combining data wide format, need concatenate time time-varying variable names (.e., subject unique identifier). removes problem non-unique variable names (e.g., anx1 wave 1 anx1 wave 2) allows interpret variable collected. concatenate time variable names . Just make sure continue adding time consistently variable names (.e., location, format) remember follow variable naming best practices (e.g., never start variable name number).adding time component, either new variable part variable name, ’s important decide values want assign time. depend entirely study design intend use time analyses. working cohorts, can helpful choose generic time values allow combine samples collected relative time periods. example:wave 1 = fall study yearwave 2 = spring study yearwave 3 = fall follow yearHowever, working cohorts dataset fall within pre-defined data collection periods, can choose values work . Figure 9.3 provides just examples might account time data based different scenarios.\nFigure 9.3: Examples adding data based variety scenarios\nsaid, active project, actually best add time component data, store dataset distinct file, clear file name denotes appropriate time period (e.g., pn_w1_stu_svy_clean_v01.csv). benefits method.Naming variables consistently time (time component added) allows easily reuse data collection data capture tools, well cleaning code, wave (T. Reynolds, Schatschneider, Logan 2022).Storing files separately prevents potentially wasting time combining data way ends actually useful wasting time merging datasets later need re-combined find error individual dataset point.Therefore, add rules variable naming style guide around concatenate time variable names, make asterisk saying time component added necessary (e.g., need combine files, publicly sharing data). ready, fairly easy add time variable concatenate time variable names using statistical program, R 57, even program like Microsoft Excel.","code":""},{"path":"style.html","id":"style-codes","chapter":"9 Style Guide","heading":"9.5 Value coding","text":"Oftentimes education research codify categorical values. coding values helps data entry, data scoring, data analysis. example, rather referring lengthier values “yes” “” variable, may code values code/label pair. code can numeric (e.g., “yes” = 1 | “” = 0) character (e.g., “yes” = ‘y’ | “” = ‘n’), depending needs. Ultimately, code appears data, code/label pair represented data dictionary, allowing users interpret meaning code.planning code categorical variable values study, can helpful include general guidelines style guide assigning codes. general good practices outlined .First, using pre-existing measure, assign codes labels manner technical documentation tells assign codes. important derivations need make later based measures.Otherwise, assigning codes, following guidelines:Codes must unique.\n: Assign “yes” = 1 | “” = 0\nDon’t: Assign “yes” = 1 | “” = 1\n: Assign “yes” = 1 | “” = 0Don’t: Assign “yes” = 1 | “” = 1Codes must consistent within variable.\n: gender assign “male” = ‘m’\nDon’t: gender allow “male” = ‘m’ ‘M’ ‘Male’ ‘male’\n: gender assign “male” = ‘m’Don’t: gender allow “male” = ‘m’ ‘M’ ‘Male’ ‘male’Codes must consistent across time.\n: anx1 assign “yes” = 1 | “” = 0 wave 1 wave 2\nDon’t: anx1 assign “yes” = 1 | “” = 0 wave 1 “yes” = 1 | “” = 2 wave 2\n: anx1 assign “yes” = 1 | “” = 0 wave 1 wave 2Don’t: anx1 assign “yes” = 1 | “” = 0 wave 1 “yes” = 1 | “” = 2 wave 2Codes consistent across project.\n: Assign “yes” = 1 | “” = 0 value yes/items\nDon’t: Assign “yes” = 1 | “” = 0 variables, “yes” = 1 | “” = 2 others\nexception pre-existing measure determines values coded. case, may inconsistency across items.\n\n: Assign “yes” = 1 | “” = 0 value yes/itemsDon’t: Assign “yes” = 1 | “” = 0 variables, “yes” = 1 | “” = 2 others\nexception pre-existing measure determines values coded. case, may inconsistency across items.\nexception pre-existing measure determines values coded. case, may inconsistency across items.Likert-type scale response options ordered logical way.\n: Assign “strongly disagree” = 1 | “disagree” = 2 | “agree” = 3 | “strongly agree” = 4\nDon’t: Assign “strongly disagree” = 1 | “disagree” = 3 | “agree” = 4 | “strongly agree” = 2\nexception pre-existing measure tells code variables different way.\n\n: Assign “strongly disagree” = 1 | “disagree” = 2 | “agree” = 3 | “strongly agree” = 4Don’t: Assign “strongly disagree” = 1 | “disagree” = 3 | “agree” = 4 | “strongly agree” = 2\nexception pre-existing measure tells code variables different way.\nexception pre-existing measure tells code variables different way.","code":""},{"path":"style.html","id":"style-missing","chapter":"9 Style Guide","heading":"9.5.1 Missing value coding","text":"little agreement missing data assigned (White et al. 2013). essentially two options.can choose leave missing values blank.\nBenefits option chance assigned missing value codes (e.g., -999) mistaken actual values.\nconcern method way discern value truly missing, potentially erased accident skipped data entry (Broman Woo 2018).\nAlso, statistical programs allow blank values (e.g., Mplus), therefore missing values need assigned point. Yet, mentioned earlier chapter, best make decisions based one potential use case. better make decisions based reasonable way assign missing values general audience.\nBenefits option chance assigned missing value codes (e.g., -999) mistaken actual values.concern method way discern value truly missing, potentially erased accident skipped data entry (Broman Woo 2018).Also, statistical programs allow blank values (e.g., Mplus), therefore missing values need assigned point. Yet, mentioned earlier chapter, best make decisions based one potential use case. better make decisions based reasonable way assign missing values general audience.option define missing codes add data. code can numeric (e.g., “missing” = -999) character (e.g., “missing” = ‘NA’) may one consistent code applied missing data, may multiple codes assigned different types missing data.\nOne benefit method removes uncertainty blank cells. value filled, now certain value deleted skipped data entry.\nAnother benefit allows specify distinct reasons missing data (e.g., “Applicable” = -97, “Skipped” = -98) important study.\nbiggest problem can occur method either codes mistaken actual values (someone misses documentation missing values), use value match variable type, introduce new variable type issues (e.g., ‘NULL’ used numeric variable, variable longer numeric)\nOne benefit method removes uncertainty blank cells. value filled, now certain value deleted skipped data entry.Another benefit allows specify distinct reasons missing data (e.g., “Applicable” = -97, “Skipped” = -98) important study.biggest problem can occur method either codes mistaken actual values (someone misses documentation missing values), use value match variable type, introduce new variable type issues (e.g., ‘NULL’ used numeric variable, variable longer numeric)Ultimately, whichever method choose, several guidelines follow.decide fill defined missing codes, use values match variable type (e.g., numeric codes numeric variables) (ICPSR 2020; White et al. 2013)\n, however, merit using text define missing values numeric variables prevent incorrect use missing values. try run mean variable, immediately notified possible variable stored character column. care different types missingness, easily choose change missing codes blank. However, care types missingness want keep included variable, need match variable type.\n, however, merit using text define missing values numeric variables prevent incorrect use missing values. try run mean variable, immediately notified possible variable stored character column. care different types missingness, easily choose change missing codes blank. However, care types missingness want keep included variable, need match variable type.use numeric values, use extreme values actually occur data.Use values consistently within across variables.value coding style guide, can add general rules follow, may appropriate place actually designate missing value coding schema project (see Table 9.1).Table 9.1: Example missing value code schema used numeric variablesNoteIt important note difference string value “NA” “NULL” inserted, versus NA NULL value assigned blank values specific platform. instance, blank numeric values R represented symbol NA. Yet value treated missing, string “NA”.","code":""},{"path":"style.html","id":"style-code","chapter":"9 Style Guide","heading":"9.6 Coding","text":"team plans clean data using code can helpful create coding style guide. style guide can tailored specific language staff use (e.g., R Stata), can written generically apply coding language staff use clean data. small sampling good coding practices consider adding guide. looking guides specific language, can helpful search online existing style guides language.Consider building implementing coding templates (Castañeda 2019; Farewell 2018).\nTemplates can standardize format syntax files (using standard headers break code).\nalso standardize summary information provided beginning syntax (e.g., code author, project name, date created) (Alexander 2023).\nTemplates can standardize format syntax files (using standard headers break code).also standardize summary information provided beginning syntax (e.g., code author, project name, date created) (Alexander 2023).One example template might look like R.Use comments throughout code clearly explain purpose code chunk.\nsyntax may seem intuitive , necessarily clear others. write code, comment every step syntax, explaining specific line code . format comments depend coding language.\nR uses # start comment\nSPSS Stata use * start comment\n\nsyntax may seem intuitive , necessarily clear others. write code, comment every step syntax, explaining specific line code . format comments depend coding language.\nR uses # start comment\nSPSS Stata use * start comment\nR uses # start commentSPSS Stata use * start commentImprove code readability using (Wickham 2021; San Martin, Rodriguez-Ramirez, Suzuki 2023)\nspaces\nindentation\nsetting line limit code (e.g., 80 characters)\nspacesindentationsetting line limit code (e.g., 80 characters)Use relative file paths reproducibility.\npoint click environment (e.g., Microsoft Excel), typically open read file going file -> open navigating file’s location. However, writing code, import file writing file path, location file lives, syntax. Rather writing full, absolute file path, good practice write path relative directory working (Wickham, Çetinkaya-Rundel, Grolemund 2023). Setting absolute file paths syntax reduces reproducibility future users may different file paths.\npoint click environment (e.g., Microsoft Excel), typically open read file going file -> open navigating file’s location. However, writing code, import file writing file path, location file lives, syntax. Rather writing full, absolute file path, good practice write path relative directory working (Wickham, Çetinkaya-Rundel, Grolemund 2023). Setting absolute file paths syntax reduces reproducibility future users may different file paths.create objects program (like R Python), consider adding object naming rules similar variable naming rules.\nspaces object names\nspecial characters except (_) separate words\nnames existing program keywords (, , etc.)\nspaces object namesNo special characters except (_) separate wordsNo names existing program keywords (, , etc.)Don’t repeat .\nReduce duplication, improve efficiency, increase ability troubleshoot errors following DRY (don’t repeat ) principle. Consider using functions, loops, macros repetitive code chunks.\nReduce duplication, improve efficiency, increase ability troubleshoot errors following DRY (don’t repeat ) principle. Consider using functions, loops, macros repetitive code chunks.Record session information future users.\nInformation software/package versions operating systems used recorded text log file increase reproducibility code. users run errors running code, information may help troubleshoot.\nInformation software/package versions operating systems used recorded text log file increase reproducibility code. users run errors running code, information may help troubleshoot.","code":"#### Overview ####\n# Associated project: \n# Script purpose:\n# Data cleaning plan followed:\n# Created by: \n# Date created:\n# Code checked by:\n# Code checked date:\n\n\n#### Workspace setup ####\n\n# Settings, packages, root paths\n\n\n#### Data import ####\n\n\n#### Cleaning code section 1 ####\n\n\n#### Cleaning code section 1 ####\n...\n# Example absolute file path\n\"/Users/crystal/project_new/data/raw/pn_stu_svy_clean_v01.csv\"  \n\n# Example relative file path\n\"raw/pn_stu_svy_clean_v01.csv\"\n"},{"path":"track.html","id":"track","chapter":"10 Data Tracking","heading":"10 Data Tracking","text":"\nFigure 10.1: Tracking research project life cycle\nproject want able answer progress summary questions recruitment data collection activities.many participants consented study? many lost study ?much progress made cycle data collection? much data left collect?many forms collect cycle missing data forms?Questions like arise many times throughout study internal project coordination purposes, well external progress reporting publication purposes. Yet, answer questions? dig papers, search emails, download -progress data, time need answer question status project activities? better solution track project activities participant tracking database.participant tracking database essential component project management data management. database contains study participants, relevant study information, well tracking information completion project milestones. database two underlying purposes.serve roster study participants “master key” (Pacific University Oregon 2014) houses identifying participant information well assigned unique study identifiers.aid project coordination reporting, tracking movement participants well completion milestones, throughout study.database considered single source truth concerning everything happened throughout duration project. time participant consents participate, drops study, changes name, completes data collection instrument, provided payment, moves locations, project coordinator, designated team member, updates information one location. Tracking administrative information one database, rather across disparate spreadsheets, emails, papers, ensures always one definitive source refer seeking answers sample project activities.NoteI want reiterate single source truth concept. Information often coming multiple sources (e.g., data collectors field, emails project coordinators teachers, conversations administrators). important train team relevant contact information gleaned (e.g., name change, new email, moved district) must updated participant tracking database alone. people track information sources, personal spreadsheets, longer single source truth, multiple sources truth. makes difficult keep track going project. Whether single person designated update information database, multiple, make sure team members know either update information contact update information.","code":""},{"path":"track.html","id":"benefits","chapter":"10 Data Tracking","heading":"10.1 Benefits","text":"thorough complete participant database updated regularly beneficial following reasons:Protecting participant confidentiality\nAssigning unique study identifiers (.e., codes) linked participant’s true identity within one database necessary maintaining participant confidentiality. database stored restricted secure location (see Chapter 13), separate identifiable coded study datasets stored, typically destroyed period time project’s completion.\nAssigning unique study identifiers (.e., codes) linked participant’s true identity within one database necessary maintaining participant confidentiality. database stored restricted secure location (see Chapter 13), separate identifiable coded study datasets stored, typically destroyed period time project’s completion.Project coordination record keeping\ndatabase can used customer relation management (CRM) tool, storing participant contact information, well tracking correspondence. can also used project coordination tool, storing scheduling information useful planning activities data collection.\nIntegrating database daily workflow allows team easily report status data collection activities (e.g., today completed 124 150 assessments). Furthermore, checking tracking incoming data daily, compared data collection complete, reduces likelihood missing data.\nLast, thorough tracking allows explain missing data reports publications (e.g., teacher 1234 went maternity leave).\ndatabase can used customer relation management (CRM) tool, storing participant contact information, well tracking correspondence. can also used project coordination tool, storing scheduling information useful planning activities data collection.Integrating database daily workflow allows team easily report status data collection activities (e.g., today completed 124 150 assessments). Furthermore, checking tracking incoming data daily, compared data collection complete, reduces likelihood missing data.Last, thorough tracking allows explain missing data reports publications (e.g., teacher 1234 went maternity leave).Sample rostering\ntime, can pull study roster database accurately reflects participant’s current status. tracking information contained tool also aids creation documentation including flow participants CONSORT diagram.\ntime, can pull study roster database accurately reflects participant’s current status. tracking information contained tool also aids creation documentation including flow participants CONSORT diagram.Data cleaning\npart data cleaning process, raw dataset sample sizes compared reported complete tracking database ensure participants missing final datasets\nFurthermore, database can used de-identifying data. data collected identifiers name, roster tracking database can used merge unique study identifiers name can removed. similar process can used merge assigned variables contained database treatment cohort.\npart data cleaning process, raw dataset sample sizes compared reported complete tracking database ensure participants missing final datasetsFurthermore, database can used de-identifying data. data collected identifiers name, roster tracking database can used merge unique study identifiers name can removed. similar process can used merge assigned variables contained database treatment cohort.","code":""},{"path":"track.html","id":"building-your-database","chapter":"10 Data Tracking","heading":"10.2 Building your database","text":"tracking phase appears collection Figure 10.1, beneficial build database begin recruiting participants, typically time building data collection tools, create instruments phase. way, team recruits participants, can record information name, consent status, necessary identifying contact information participant database begin assigning participants study IDs.project coordinator can build database, can helpful consult data manager, someone database expertise, creating system. ensures system set efficiently comprehensively.database may standalone structure, used tracking anonymization purposes, may integrated part larger study system, study data collected /entered well.","code":""},{"path":"track.html","id":"comparing-database-types","chapter":"10 Data Tracking","heading":"10.2.1 Comparing database types","text":"discuss build database, helpful basic understanding benefits using different types databases. essentially two types databases commonly used tracking—relational non-relational.Relational database\nRelational databases typically built database software system (e.g., FileMaker, Microsoft Access). database, information organized tables made records (rows) fields (columns), tables can related keys (Bourgeois 2014; Chen 2022).\nRelational databases typically built database software system (e.g., FileMaker, Microsoft Access). database, information organized tables made records (rows) fields (columns), tables can related keys (Bourgeois 2014; Chen 2022).Non-relational database\nloosely using term non-relational database describe tables information linked (think tabs spreadsheet). type database usually built spreadsheet program (e.g., Microsoft Excel). technically considered database, continue use term “database”, even system built using spreadsheet program.\nloosely using term non-relational database describe tables information linked (think tabs spreadsheet). type database usually built spreadsheet program (e.g., Microsoft Excel). technically considered database, continue use term “database”, even system built using spreadsheet program.study design can inform type database choose build. relational databases may involved build, also efficient use study includes variety related entities (e.g., students teachers), tracked waves time. However, tracking one group participants (e.g., just students) one wave data collection, fairly small study (e.g., participant numbers < 30), relational database might overkill simple spreadsheet system work just fine. Figure 10.2 flow chart showing kinds decisions consider choosing type database build. decision tree used help guide discussion; contain hard--fast rules. Rules N > 30, replaced criteria make sense project team.\nFigure 10.2: decision tree choosing whether build participant tracking database using relational database spreadsheet\nfollowing sections review benefits relational databases compared non-relational databases, especially working complex studies.","code":""},{"path":"track.html","id":"relational-database","chapter":"10 Data Tracking","heading":"10.2.1.1 Relational database","text":"Using relational database track participant information, compared disconnected tabs spreadsheet, many benefits including reducing data entry errors improving efficiency (Borer et al. 2009).three general steps building relational database.Create tables made fields (.e., variables)Choose one primary key fields uniquely identify rows tables. keys change point. Typically keys assigned unique study IDs.Create relationships tables primary foreign keys (see Section 3.3.1 refresher primary foreign keys)Understanding ways optimize relational database outside scope book also always necessary purposes. , important thing consider building relational database duplicate information across tables. one field need updated one location, never one. want learn building databases, many freely available resources.ResourcesLet’s compare simple example building tracking database using relational model non-relational model. Figure 10.3 three entities need track database—schools, teachers, students. built simple database one table entity. Within table added fields need collect subjects. also set tables include primary keys (denoted ovals) foreign keys (denoted rectangles). keys unique study identifiers assigned study participants (see Section 10.4 information assigning IDs).\nFigure 10.3: Participant database built using relational model\ncan see across table duplicated information. Student Table contains student-level information, Teacher Table contains teacher-level information, School Table contains school-level information. huge time saver. Imagine teacher’s last name changes. Rather updating name multiple places, now update , teacher table make note previous name notes field.want see table student teacher information, can simply query database (.e., make request) create new table. programs, type querying may simple point click option, programs may require someone write simple code can used time user.Say example, needed pull roster students teacher. easily create run query, one written SQL (structured query language), joins student teacher tables Figure 10.3 tch_id pulls relevant teacher student information tables.SELECT Teacher.t_l_name, Teacher.t_f_name, Student.s_l_name, Student.s_f_name,  Student.s_grade_levelFROM Student LEFT JOIN Teacher Student.tch_id = Teacher.tch_idORDER t_l_name, t_f_name, s_l_name, s_f_nameThe resulting output Table 10.1.Table 10.1: Example roster created querying relational database tablesDepending design study structure database model, writing queries can become complicated. ’s important strike balance creating structure reduces inefficiencies data entry also creating something isn’t complicated work based expertise team.","code":""},{"path":"track.html","id":"non-relational-database","chapter":"10 Data Tracking","heading":"10.2.1.2 Non-relational database","text":"Now imagine built non-relational model, three tabs Excel spreadsheet, track participant information (see Figure 10.4). Since unable link tables together, need enter redundant information table (denoted rectangles) order see information within table without flip back forth across tables find information need. example, now enter repeating teacher school names Student Table, teacher names change, need update Teacher Table Student Table every student associated teacher. model may work fine smaller studies, can imagine duplicating information increase data entry time create opportunity data entry errors larger, complicated study several tables information (Borer et al. 2009).\nFigure 10.4: Participant database built using non-relational model duplicated variables denoted rectangles\n","code":""},{"path":"track.html","id":"designing-the-database","chapter":"10 Data Tracking","heading":"10.2.2 Designing the database","text":"can begin design database, need think following pieces information.want use relational non-relational database?many tables want construct?\nConsider entities (e.g., student, teacher, school)\nConsider purpose (e.g., enrollment info, wave 1 data collection tracking, wave 2 data collection tracking)\nConsider entities (e.g., student, teacher, school)Consider purpose (e.g., enrollment info, wave 1 data collection tracking, wave 2 data collection tracking)fields want include table?using relational database, fields use relate tables?make decisions regarding questions, can begin design database. can helpful visualize database schema process. Figure 10.5 designing relational database schema scenario collecting information teachers schools, two waves data collection.\nFigure 10.5: Example participant database relational model using two separate tables tracking across waves\ndesigned database model way:four tables total.\nTwo tables (Teacher Info School Info tables) information fairly constant based project assumptions (name, email, consent, one-time documents received).\ntime information changes (e.g., withdrawn status, new last name, new contact person), update information appropriate table make note change occurred notes field.\n\nTwo tables longitudinal information.\ntrack data collection activities wave, well information may change wave, based assumptions project. example, may put grade level longitudinal tables collect data across years assume ’s possible teachers may switch grade levels.\n\nTwo tables (Teacher Info School Info tables) information fairly constant based project assumptions (name, email, consent, one-time documents received).\ntime information changes (e.g., withdrawn status, new last name, new contact person), update information appropriate table make note change occurred notes field.\ntime information changes (e.g., withdrawn status, new last name, new contact person), update information appropriate table make note change occurred notes field.Two tables longitudinal information.\ntrack data collection activities wave, well information may change wave, based assumptions project. example, may put grade level longitudinal tables collect data across years assume ’s possible teachers may switch grade levels.\ntrack data collection activities wave, well information may change wave, based assumptions project. example, may put grade level longitudinal tables collect data across years assume ’s possible teachers may switch grade levels.connected tables primary foreign keys (tch_id sch_id).information separated four tables, can also now limit access needed (e.g., allow data entry staff access de-identified tables, restricting entry current wave data preventing accidental overwriting existing data).model Figure 10.5 absolutely way can design tables. may efficient appropriate ways design database, long duplicating information, build works . example potentially efficient way structure database, combine waves data collection one table create concatenated (compound) primary key uses tch_id wave uniquely identify rows since tch_id now duplicated wave data collection (see Figure 10.6).\nFigure 10.6: Example participant database relational model using one table track data across waves\nentered data Teacher Wave Data table Figure 10.6, might look something like Figure 10.7. can see tch_id repeats rows unique combined wave.\nFigure 10.7: example data contains concatenated primary key\nexamples fairly simple scenario, can hopefully see might extrapolate model entities waves data collection, well might modify better meet needs specific project.NoteIf study involves anonymous data collection, longer able track data associated specific individual. However, still helpful create form tracking system. Creating simplified database, tables based sites instance (school table, district table) allows still track project management data collection efforts (e.g., number student surveys received per school per wave, payment sent school).","code":""},{"path":"track.html","id":"choosing-fields","chapter":"10 Data Tracking","heading":"10.2.3 Choosing fields","text":"design participant tracking database model, also need choose fields include table. fields choose include dependent particular study design. participant tracking database may database enter study data, purposes chapter considering fields relevant project coordination participant de-identification. concerned fields collected part data collection measures (e.g., survey items). can consider participant tracking database internal database used coordination, summary, linking purposes. database export data external data sharing.ideas fields may consider adding database. Depending design assumptions study, may collected , others may collected , longitudinally.Ideas fields collect:Primary keys (Study IDs)Foreign keysNames (participants sites)Contact informationOther necessary linking identifiers (double IDs, district/school IDs)Consent/assent statusInclusion/exclusion criteria statusEnrollment statusWithdrawn statusRelevant datesRandomization (treatment/control)Grouping information (cohort)Information relevant project coordination (grade level, class periods, block schedules)Summary information may helpful participant flow diagrams (# consents sent , # students class, # teachers school)Administrative data status (W-9 received, MOUs received)Data collection status (unique fields instrument)Data collection administrator names IDsIncentive status (gift cards sent )Notes\nReasons changes (example changes name, email)\nReasons movement/withdraw\nCommunication participants\nReasons missing data\nErrors data\nReasons changes (example changes name, email)Reasons movement/withdrawCommunication participantsReasons missing dataErrors data","code":""},{"path":"track.html","id":"structuring-fields","chapter":"10 Data Tracking","heading":"10.2.3.1 Structuring fields","text":"choose fields also need make decisions structure fields.Set data types fields (e.g., character, integer, date)\nRestrict entry values allowable data types reduce errors\nRestrict entry values allowable data types reduce errorsSet allowable values ranges\nexample, categorical status field may allow “complete”, “partially complete” “incomplete”\nexample, categorical status field may allow “complete”, “partially complete” “incomplete”lump separate pieces information together field\nexample, separate first name last name two fields\nexample, separate first name last name two fieldsName fields according variable naming rules discussed Chapter 9","code":""},{"path":"track.html","id":"choosing-a-tool","chapter":"10 Data Tracking","heading":"10.2.4 Choosing a tool","text":"many criteria consider choosing tool build database .Choose tool customizable needs.\nCan build relational table structure?\nCan export files? Can connect database via application programming interfaces (APIs)?\nCan query data?\nCan build relational table structure?Can export files? Can connect database via application programming interfaces (APIs)?Can query data?Choose tool user-friendly.\ndon’t want tool steep learning curve users.\ndon’t want tool steep learning curve users.running project across multiple sites, consider accessibility tool.\nexample, may want tool cloud-based site coordinators can access .\nmay also want make sure multiple users can access time.\nexample, may want tool cloud-based site coordinators can access .may also want make sure multiple users can access time.Choose tool interoperable.\ninstance, tools may difficulties running certain operating systems.\ninstance, tools may difficulties running certain operating systems.Consider cost licensing.\nmany free tools, may provide functionality want.\nproducts already access (.e., institution license )?\nmany free tools, may provide functionality want.products already access (.e., institution license )?Consider security.\ntools approved institution protect sensitivity level data (See Chapter 4)?\nCan limit access entire database? specific tables?\nmultiple people entering data, may want restrict access/editing capabilities . tables\n\nProtect data loss.\nCan backup system?\nCan protect overwriting data?\nCan keep versions database case mistake ever made need go back older version?\n\ntools approved institution protect sensitivity level data (See Chapter 4)?Can limit access entire database? specific tables?\nmultiple people entering data, may want restrict access/editing capabilities . tables\nmultiple people entering data, may want restrict access/editing capabilities . tablesProtect data loss.\nCan backup system?\nCan protect overwriting data?\nCan keep versions database case mistake ever made need go back older version?\nCan backup system?Can protect overwriting data?Can keep versions database case mistake ever made need go back older version?Data quality protection.\nCan set data quality constraints (e.g., restrict input values/types)?\nCan set data quality constraints (e.g., restrict input values/types)?many tool options can choose . sampling options . tools represent wide range criteria section. Take time review options see one best meets needs.Microsoft AccessMicrosoft ExcelQuickbaseAirtableREDCapClaris FileMakerGoogle Sheets Google FormsForms feed relational database, maintained using SQL database engine SQLite, MySQL, PostgreSQL","code":""},{"path":"track.html","id":"track-enter","chapter":"10 Data Tracking","heading":"10.3 Entering data","text":"last consideration building database , want team enter data database? many ways enter data including manually entering data, importing data, integrating data collection platform tracking database, even scanning forms using QR codes. options may work great project, going talk two simplest common options—manually entering data tabular view, manually entering data form.","code":""},{"path":"track.html","id":"entering-data-in-a-tabular-view","chapter":"10 Data Tracking","heading":"10.3.1 Entering data in a tabular view","text":"first option manually enter data tabular view participant row (see Figure 10.8). common, possibly option, using spreadsheet tools Microsoft Excel. However, can also use option entering database tools Microsoft Access FileMaker. Depending tool, might name datasheet table view. pros cons method.Pros: quickest easiest method. also allows view data holistically.Cons: method can lead errors someone enters data wrong row/record. can also easily lead accidental deletion overwriting data.\nFigure 10.8: Example tabular view data entry\n","code":""},{"path":"track.html","id":"entering-data-in-a-form","chapter":"10 Data Tracking","heading":"10.3.2 Entering data in a form","text":"second option create form (also called data entry screen) linked tables (see Figure 10.9). enter data forms, automatically populates tables information. option possible many systems including Microsoft Access, FileMaker, REDCap, even Google Forms populates Google Sheets.Pros: method reduces data entry errors working one participant form time.Cons: Takes time, possibly expertise, set data entry forms.\nFigure 10.9: Example form view data entry\nNoteIf participant tracking database separate data collection tools, information need entered team using one ways mentioned section. However, participant tracking tool also data collection tool (collect electronic data using REDCap), fields data collection status (e.g., svy_complete) may need manually entered. Rather may automated populate “complete” participant submits responses data collection tool.","code":""},{"path":"track.html","id":"track-ids","chapter":"10 Data Tracking","heading":"10.4 Creating unique identifiers","text":"One important parts keeping participant tracking database assigning unique participant identifiers. soon participants entered database, unique study ID assigned. confidentiality promised schools districts, also want assign identifiers sites well. Assigning identifiers important part protecting privacy human participants. publicly sharing study data, personally identifying information removed identifiers (.e., codes), allow uniquely identify link participants data.Participant unique identifiers numeric alphanumeric values typically range 2-10 digits. several ways participant identifiers can assigned (e.g., created participants , assigned data collection software), commonly, research team assigns identifiers participants.assigning identifiers, can helpful develop ID schema planning phase (see Table 10.2), document schema SOP (see Section 8.2.7).Table 10.2: Example study ID schemaThis schema sets parameters participant identifiers assigned entered tracking database (.e., format, range). several best practices consider developing participant ID schema.Participants must keep identifier entire project.\nstatic participant ID allows track flow participant study can also provide added benefit helping measure dosage intervention studies.\nKeeping unique identifier even applies circumstances participant opportunity re-recruited study (seen Figure 10.10). situation, participant still keeps ID use combination variables identify unique instances participant (e.g., stu_id cohort).\nmultiple rounds recruitment, important procedure place check participants may already database (e.g., search participant names adding database). Without system place, possible bring participant back database new ID.\nstatic participant ID allows track flow participant study can also provide added benefit helping measure dosage intervention studies.Keeping unique identifier even applies circumstances participant opportunity re-recruited study (seen Figure 10.10). situation, participant still keeps ID use combination variables identify unique instances participant (e.g., stu_id cohort).multiple rounds recruitment, important procedure place check participants may already database (e.g., search participant names adding database). Without system place, possible bring participant back database new ID.\nFigure 10.10: Example keeping participant IDs entire study\nParticipant identifiers must unique within across entities.\nexample, duplicating IDs within students across teachers schools.\nduplicating within entities imperative maintain uniqueness records, duplicating across reduces confusion form belongs reduces potential errors.\nexample, duplicating IDs within students across teachers schools.duplicating within entities imperative maintain uniqueness records, duplicating across reduces confusion form belongs reduces potential errors.identifier randomly assigned completely distinct personal information protect confidentiality.\nsort identifying information (e.g., names, date birth) assign IDs sequential order.\ngroup identifying information (e.g., grade level, teacher) assign IDs sequential order.\ninclude identifying information (e.g., initials) part identifier.\nsort identifying information (e.g., names, date birth) assign IDs sequential order.group identifying information (e.g., grade level, teacher) assign IDs sequential order.include identifying information (e.g., initials) part identifier.embed project information ID information potential change.\nresearchers prefer embed project-level ID acronym participant ID help tracking information, especially running multiple studies using identical forms across studies. absolutely okay assumed information never changes.\nHowever, embedding time indicator, wave session, identifier variable guarantees identifiers remain constant. information added dataset ways (.e., either variable concatenated variable names).\nEmbedding information teacher IDs, school IDs, treatment, cohort also potential cause problems. longitudinal studies, depending study design, possible students move study teachers, teachers move study schools, participants get re-recruited cohorts. issues cause problems information embedded ID ID longer reflect accurate information require IDs changed, breaking best practice #1. , information can tracked separate variables (e.g., tch_id, sch_id, cohort, treatment) added forms datasets needed. Figure 10.11 example dataset stu_id = 12428 moved another teacher’s classroom wave 2 caused issues teacher ID embedded stu_id variable.\nresearchers prefer embed project-level ID acronym participant ID help tracking information, especially running multiple studies using identical forms across studies. absolutely okay assumed information never changes.However, embedding time indicator, wave session, identifier variable guarantees identifiers remain constant. information added dataset ways (.e., either variable concatenated variable names).Embedding information teacher IDs, school IDs, treatment, cohort also potential cause problems. longitudinal studies, depending study design, possible students move study teachers, teachers move study schools, participants get re-recruited cohorts. issues cause problems information embedded ID ID longer reflect accurate information require IDs changed, breaking best practice #1. , information can tracked separate variables (e.g., tch_id, sch_id, cohort, treatment) added forms datasets needed. Figure 10.11 example dataset stu_id = 12428 moved another teacher’s classroom wave 2 caused issues teacher ID embedded stu_id variable.\nFigure 10.11: Example student changing teachers research study\nLast, less important data tracking phase, study datasets identifiers stored character variables. Even ID variable numbers, stored character type. helps prevent people inappropriately working values (.e., taking mean ID variable).NoteThe time assign unique identifiers collect anonymous data. situation able assign identifiers since know participants . However, still possible assign identifiers known entities school sites anonymity required.","code":""},{"path":"track.html","id":"summary","chapter":"10 Data Tracking","heading":"10.5 Summary","text":"tracking phase one important data management practices education research project life cycle. Anecdotally, seen several teams, without participant tracking system project, end lost unusable data struggle recall details data collection efforts. optimizing design database entry system helpful reducing inefficiencies errors, don’t let get lost details. Build system works team project. key takeaways focus phase following:Build system tracking intake information, well storing participant key, keep date.Keep one single source truth. Don’t information stored multiple locations.Keep tracking system secure. Don’t allow unauthorized access participant information (see Chapter 13 information).Assign participant unique IDs using best practices covered Section 10.4.","code":""},{"path":"collect.html","id":"collect","chapter":"11 Data Collection","heading":"11 Data Collection","text":"\nFigure 11.1: Data collection research project life cycle\ncollecting original data part study (.e., administering survey assessment opposed using externally collected data source), data management best practices interwoven throughout data collection process. Unfortunately, quality data doesn’t just happen instrument created data collected. takes careful consideration, structure, care part entire team. number one way improve integrity data spend time planning data collection efforts. planning minimize errors, also keeps data secure, valid, relieves future data cleaning headaches.","code":""},{"path":"collect.html","id":"quality-assurance-and-control","chapter":"11 Data Collection","heading":"11.1 Quality assurance and control","text":"planning data collection efforts, ’ll want data sources catalog available (see Section 8.2.2). document guide data collection planning period. Recall every row document original instrument collected study. data sources may also include external datasets, discuss Chapter 12.addition planning data collection logistics original data sources (.e., data collected, collect , ), teams spend time prior data collection anticipating potential data integrity problems may arise data collection putting procedures place reduce errors (DIME Analytics 2021a; Northern Illinois University 2023). shown Figure 11.1, creating data collection instruments typically collaborative effort project management data management team members. Even project management team builds data collection tools, data management team overseeing data collected tools aligns expectations set data dictionaries. chapter review two types practices project management data management team members can implement improve integrity data.Quality assurance practices happen data collected.\nBest practices associated designing building data collection instruments.\nBest practices associated designing building data collection instruments.Quality control practices implemented data collection.\nBest practices associated managing reviewing data collection.\nBest practices associated managing reviewing data collection.","code":""},{"path":"collect.html","id":"collect-assurance","chapter":"11 Data Collection","heading":"11.2 Quality assurance","text":"\nFigure 11.2: Common education research data collection methods\nEducation researchers collect original data many ways (see Figure 11.2). focus chapter data collected via forms (.e., document spaces respond questions). Forms widely used collect data education research (.e., think questionnaires, assessments, observation forms, progress monitoring form website), yet poorly developed, can produce problematic data issues.focus forms discount importance data collected means video audio recording, issues participant privacy data security integrity absolutely also considered. However, even types data collection efforts, often teams ultimately still coding data using sort form (e.g., observation form), supporting need build forms collect quality data.collecting information using forms can certainly best fix data errors data collection cleaning process. However, one effective ways ensure quality data correct source. means designing items building data collection tools way produces valid, reliable, secure data. creating original data collection instruments, five ways collect higher quality data.Using good questionnaire design principlesImplementing series pilot testChoosing data collection tools meet needsBuilding instrument end mindEnsuring complianceWe discuss phases .NoteIf collecting data using standardized assessment, along provided instrument (e.g., computer-adaptive testing program, testing booklet), information section applicable best adhere guidelines provided assessment company. can skip Section 11.2.5.","code":""},{"path":"collect.html","id":"collect-design","chapter":"11 Data Collection","heading":"11.2.1 Questionnaire design","text":"Chapter 8 discussed importance documenting instrument items data dictionary creating data collection instruments. develop items add data dictionary original data source, vital consider questionnaire design.instruments (e.g., cognitive assessments) typically standardized items, instruments, surveys, often predefined, allowing researchers freedom design instrument can lead negative effects errors, bias, potential harm (DIME Analytics 2021a; Northern Illinois University 2023). Question ordering, response option ordering, question wording, can impact participant responses. questionnaire design actually outside scope book, tips help collect valid, reliable, ethical survey data. addition following tips, make sure consult methodologist ensure questionnaire appropriately designed answer research questions, plan issues missing data.Follow technical documentation existing scales.\nusing existing scale, discussed Section 8.4.1.1, make sure follow technical documentation associated scale (e.g., item wording, response options, item order). ensures using scale intended, also improves opportunities integrate data replicate findings across studies used scales.\nusing existing scale, discussed Section 8.4.1.1, make sure follow technical documentation associated scale (e.g., item wording, response options, item order). ensures using scale intended, also improves opportunities integrate data replicate findings across studies used scales.Use existing standards possible.\nOrganizations National Institutes Health National Center Education Statistics developed repositories (Common Data Elements62 Common Education Data Standards63) standardized question wording paired set allowable response options commonly used data elements. Using standards collecting commonly used variables, demographics, provides following benefits (ICPSR 2022; Kush et al. 2020):\nReduces bias\nAllows harmonization data across research studies also across field\nallows researchers draw conclusions using larger samples comparing data time.\nalso reduces costs integrating datasets.\n\nImproves interpretation information\n\nOrganizations National Institutes Health National Center Education Statistics developed repositories (Common Data Elements62 Common Education Data Standards63) standardized question wording paired set allowable response options commonly used data elements. Using standards collecting commonly used variables, demographics, provides following benefits (ICPSR 2022; Kush et al. 2020):\nReduces bias\nAllows harmonization data across research studies also across field\nallows researchers draw conclusions using larger samples comparing data time.\nalso reduces costs integrating datasets.\n\nImproves interpretation information\nReduces biasAllows harmonization data across research studies also across field\nallows researchers draw conclusions using larger samples comparing data time.\nalso reduces costs integrating datasets.\nallows researchers draw conclusions using larger samples comparing data time.also reduces costs integrating datasets.Improves interpretation informationMake sure questions clearly worded answer choices clear comprehensive.\nConsider language might interpreted. question wording confusing? Can response options misinterpreted?\nRather asking “county ?” looking participant’s current location, specific ask, “county currently reside ?”.\nRather asking “parent ?” providing response options “m” “f”, “m” “f” interpreted “male” “female”, clearly write response options make sure comprehensive (“mother”, “father”, “legal guardian”, forth).\nRather asking “children siblings?” can confusing, remove negative ask, “children siblings?” (T. Reynolds, Schatschneider, Logan 2022).\n\nquestion leading/biased?\nresponse options ordered leading way?\n\none way answer question?\nresponse categories mutually exclusive exhaustive (ICPSR 2020)?\n\nConsider language might interpreted. question wording confusing? Can response options misinterpreted?\nRather asking “county ?” looking participant’s current location, specific ask, “county currently reside ?”.\nRather asking “parent ?” providing response options “m” “f”, “m” “f” interpreted “male” “female”, clearly write response options make sure comprehensive (“mother”, “father”, “legal guardian”, forth).\nRather asking “children siblings?” can confusing, remove negative ask, “children siblings?” (T. Reynolds, Schatschneider, Logan 2022).\nRather asking “county ?” looking participant’s current location, specific ask, “county currently reside ?”.Rather asking “parent ?” providing response options “m” “f”, “m” “f” interpreted “male” “female”, clearly write response options make sure comprehensive (“mother”, “father”, “legal guardian”, forth).Rather asking “children siblings?” can confusing, remove negative ask, “children siblings?” (T. Reynolds, Schatschneider, Logan 2022).question leading/biased?\nresponse options ordered leading way?\nresponse options ordered leading way?one way answer question?\nresponse categories mutually exclusive exhaustive (ICPSR 2020)?\nresponse categories mutually exclusive exhaustive (ICPSR 2020)?Consider data ethics questionnaire design (Gaddy Scott 2020; Kaplowitz Johnson 2020; Kopper Parry 2021; Mathematica 2023; Narvaiz 2023).\nConsider item tie questions outcomes.\nDon’t cause undue burden participants collecting data just data.\ncollecting demographic information, provide explanation information necessary used research.\n\nReview question wording.\npotential harm participants? benefits outweigh risks?\nsensitive questions included, make sure discuss protect respondent’s information.\n\nMake questions inclusive population also capturing categories relevant research.\nquestion multiple choice, still include “” option open-text field.\ndemographic information, allow participants select one option.\n\nConsider including one general free-text field survey allow participants provide additional information feel captured elsewhere.\nConsider item tie questions outcomes.\nDon’t cause undue burden participants collecting data just data.\ncollecting demographic information, provide explanation information necessary used research.\nDon’t cause undue burden participants collecting data just data.collecting demographic information, provide explanation information necessary used research.Review question wording.\npotential harm participants? benefits outweigh risks?\nsensitive questions included, make sure discuss protect respondent’s information.\npotential harm participants? benefits outweigh risks?sensitive questions included, make sure discuss protect respondent’s information.Make questions inclusive population also capturing categories relevant research.\nquestion multiple choice, still include “” option open-text field.\ndemographic information, allow participants select one option.\nquestion multiple choice, still include “” option open-text field.demographic information, allow participants select one option.Consider including one general free-text field survey allow participants provide additional information feel captured elsewhere.Limit collection personally identifiable information (PII).\nCollecting identifiable information balancing act protecting participant confidentiality collecting information necessary implement study. often need collect identifying information either purposes record linking purposes related study outcomes (e.g., scoring assessment based participant’s age).\ngeneral rule, want collect PII absolutely necessary project, (Gaddy Scott 2020). discussed Chapter 4, PII can include direct identifiers (e.g., name email) well indirect identifiers (e.g., date birth). sharing data, PII need removed altered protect confidentiality.\nCollecting identifiable information balancing act protecting participant confidentiality collecting information necessary implement study. often need collect identifying information either purposes record linking purposes related study outcomes (e.g., scoring assessment based participant’s age).general rule, want collect PII absolutely necessary project, (Gaddy Scott 2020). discussed Chapter 4, PII can include direct identifiers (e.g., name email) well indirect identifiers (e.g., date birth). sharing data, PII need removed altered protect confidentiality.Survey Design Resources","code":""},{"path":"collect.html","id":"pilot-the-instrument","chapter":"11 Data Collection","heading":"11.2.2 Pilot the instrument","text":"Gathering feedback instruments integral part quality assurance process. three phases piloting instrument (DIME Analytics 2021b) (see Figure 11.3).Gathering internal feedback items\ndiscussed Section 8.4.1, items instrument added data dictionary, data management working group (DMWG) (see Chapter 6) review data dictionary provide feedback.\ndiscussed Section 8.4.1, items instrument added data dictionary, data management working group (DMWG) (see Chapter 6) review data dictionary provide feedback.Piloting instrument content\nDMWG approved items collected, second phase piloting can begin. Create printable draft instrument can shared people study population gather feedback. Consult IRB determine approval required piloting instrument study population.\nDMWG approved items collected, second phase piloting can begin. Create printable draft instrument can shared people study population gather feedback. Consult IRB determine approval required piloting instrument study population.Piloting instrument data related issues\ninstrument created chosen data collection tool, share instrument team review. interested whether data collecting accurate, comprehensive, usable. discuss phase greater detail Section 11.2.4.\ninstrument created chosen data collection tool, share instrument team review. interested whether data collecting accurate, comprehensive, usable. discuss phase greater detail Section 11.2.4.Last, move piloting phases, remember make updates tool also data dictionary relevant documentation (e.g., data cleaning plan).\nFigure 11.3: Data collection instrument pilot phases\n","code":""},{"path":"collect.html","id":"collect-tools","chapter":"11 Data Collection","heading":"11.2.3 Choose quality data collection tools","text":"content piloting completed, teams ready begin building instruments data collection tools (see Figure 11.2 examples tools). Research teams may restricted tools use collect data variety reasons including limited resources, research design, population studied, sensitivity levels data, chosen instrument (e.g., existing assessment can collected using provided tool). However, flexibility choose collect data, pick tool meets various needs project also providing data quality security controls. Things consider choosing data collection tool :Needs project\ncrowdsourcing required?\nmulti-site access required?\nentering data (.e., data collectors, participants)?\nparticipants entering data, tool accessible population?\n\ntechnical requirements tool (.e., internet available plan use web-based tool)?\ntool customizable features necessary instrument (e.g., branching logic, automated email reminders, options embed data, options calculate scores tool)?\ncrowdsourcing required?multi-site access required?entering data (.e., data collectors, participants)?\nparticipants entering data, tool accessible population?\nparticipants entering data, tool accessible population?technical requirements tool (.e., internet available plan use web-based tool)?tool customizable features necessary instrument (e.g., branching logic, automated email reminders, options embed data, options calculate scores tool)?Compliance security\nConsider classification level data source (See Chapter 4)\ntools approved institution protect sensitivity level data?\n\ncollecting anonymous data, option anonymize responses tool (e.g., remove IP Address identifying metadata collected tool)?\ntool include data backups?\nConsider classification level data source (See Chapter 4)\ntools approved institution protect sensitivity level data?\ntools approved institution protect sensitivity level data?collecting anonymous data, option anonymize responses tool (e.g., remove IP Address identifying metadata collected tool)?tool include data backups?Training needed\nadditional team training needed allow team use /build instruments tool?\nadditional team training needed allow team use /build instruments tool?Associated costs\ncost associated tool? budget tool?\nadditional costs line (e.g., collecting data paper means someone need hand enter data later)?\ncost associated tool? budget tool?additional costs line (e.g., collecting data paper means someone need hand enter data later)?Data quality features\ntool allow set data validation?\ntool version control?\ntool features deal fraud/bots?\ntool allow set data validation?tool version control?tool features deal fraud/bots?variety tool options, nutshell comes data collected via forms, data collection tools can categorized one two ways—electronic paper. addition choosing tools based criteria mentioned section, general benefits associated method also considered, especially research team control data collection tool built (Cohen, Manion, Morrison 2007; Douglas, Ewell, Brauer 2023; Gibson 2021; ICPSR 2020; Malow et al. 2021; Society Critical Care Medicine 2018; Van Bochove, Alper, Gu 2023) (See Table 11.1).Table 11.1: Comparison data collection tool benefitsNoteIf choose collect data electronic (also called digital) format, highly recommend using web-based tool directly feeds shared database rather offline tools store data individual devices. Using web-based tool, data stored remotely database can easily downloaded connected time. additional work required.However, collecting data various tablets field, forms offline later connected web-based form, data stored individually tablet. may less secure (e.g., tablet becomes corrupted), may also require additional data wrangling work including downloading data tablet secure storage location day combining files single dataset. use electronic tool site internet, consider using one many tools (e.g., Qualtrics, SurveyCTO) allow collect data using offline app upload data back platform internet connection .Tool Comparison Resources","code":""},{"path":"collect.html","id":"collect-build","chapter":"11 Data Collection","heading":"11.2.4 Build with the end in mind","text":"create data collection tool, want build end mind. means taking time consider data collect translated dataset (Beals Schectman 2014; Lewis 2022b; UK Data Service 2023). Recall Chapter 3, ultimately need data rectangular format, organized according basic data organization rules, order analyzable. process building tools end mind fairly different electronic tools compared paper forms going talk two processes separately.","code":""},{"path":"collect.html","id":"collect-electronic","chapter":"11 Data Collection","heading":"11.2.4.1 Electronic data collection","text":"ever created data collection instrument expected export data looks like image left Figure 11.4, instead export data looks like image right, understand important spend time planning data collected tool.\nFigure 11.4: comparison data collected without planning data collected planning\nfirst thing want building tool bring data dictionary. data dictionary guide build instrument. tools, REDCap, provide option upload data dictionary can used automate creation data collection forms opposed building scratch (Patridge Bardyn 2018). However, building instrument manually, adhering following guidelines ensure collect data easier interpret usable, also reduce amount time need spend future data cleaning (Lewis 2022b).Include items data dictionary.\naddition original data collection items, also includes variables derived data collection either automatically tool manually entered data collectors (e.g., total correct, age calculation).\n, however, include variables plan derive add data data collection, data cleaning phase (e.g., treatment, standard scores).\naddition original data collection items, also includes variables derived data collection either automatically tool manually entered data collectors (e.g., total correct, age calculation)., however, include variables plan derive add data data collection, data cleaning phase (e.g., treatment, standard scores).Name items correct variable name data dictionary (UK Data Service 2023).\nexample, instead using platform default name Q2, rename item tch_years.\nmentioned Section 9.4, ’s also best concatenate time component variable names project longitudinal. makes difficult reuse instrument time periods, creating additional work team.\nexample, instead using platform default name Q2, rename item tch_years.mentioned Section 9.4, ’s also best concatenate time component variable names project longitudinal. makes difficult reuse instrument time periods, creating additional work team.Code values data dictionary.\nexample, “strongly agree” = 1 | “agree” = 2 | “disagree” = 3 | “strongly disagree” = 4\nMany times, tools assign default value response options values may align ’ve designated data dictionary.\nedit survey, continue check coded values change due reordering, removal, addition new response options.\nexample, “strongly agree” = 1 | “agree” = 2 | “disagree” = 3 | “strongly disagree” = 4Many times, tools assign default value response options values may align ’ve designated data dictionary.edit survey, continue check coded values change due reordering, removal, addition new response options.Add data validation reduce errors missing data (UK Data Service 2023).\nContent validation open-text boxes\nRestrict entry type assigned data dictionary (e.g., numeric).\nRestrict entry format assigned data dictionary (e.g., YYYY-MM-DD).\nRestrict ranges based allowable ranges data dictionary (e.g., 1–50).\neven include validating previous responses (e.g., “SchoolA” selected previous question, grade level 6–8, “SchoolB” selected, grade level 7–8).\n\n\nResponse validation\nConsider use forced-response request-response options reduce missing data.\nForced-response options allow participants move forward without completing item. Request-response options notify respondent skip question ask still like move forward without responding.\naware adding forced-response option sensitive questions potential harmful produce bad data. adding forced-response option sensitive question, consider allowing participants opt-another way (e.g., “Prefer answer”).\n\n\nContent validation open-text boxes\nRestrict entry type assigned data dictionary (e.g., numeric).\nRestrict entry format assigned data dictionary (e.g., YYYY-MM-DD).\nRestrict ranges based allowable ranges data dictionary (e.g., 1–50).\neven include validating previous responses (e.g., “SchoolA” selected previous question, grade level 6–8, “SchoolB” selected, grade level 7–8).\n\nRestrict entry type assigned data dictionary (e.g., numeric).Restrict entry format assigned data dictionary (e.g., YYYY-MM-DD).Restrict ranges based allowable ranges data dictionary (e.g., 1–50).\neven include validating previous responses (e.g., “SchoolA” selected previous question, grade level 6–8, “SchoolB” selected, grade level 7–8).\neven include validating previous responses (e.g., “SchoolA” selected previous question, grade level 6–8, “SchoolB” selected, grade level 7–8).Response validation\nConsider use forced-response request-response options reduce missing data.\nForced-response options allow participants move forward without completing item. Request-response options notify respondent skip question ask still like move forward without responding.\naware adding forced-response option sensitive questions potential harmful produce bad data. adding forced-response option sensitive question, consider allowing participants opt-another way (e.g., “Prefer answer”).\n\nConsider use forced-response request-response options reduce missing data.\nForced-response options allow participants move forward without completing item. Request-response options notify respondent skip question ask still like move forward without responding.\naware adding forced-response option sensitive questions potential harmful produce bad data. adding forced-response option sensitive question, consider allowing participants opt-another way (e.g., “Prefer answer”).\nForced-response options allow participants move forward without completing item. Request-response options notify respondent skip question ask still like move forward without responding.aware adding forced-response option sensitive questions potential harmful produce bad data. adding forced-response option sensitive question, consider allowing participants opt-another way (e.g., “Prefer answer”).Choose appropriate type format display item.\nBecome familiar various question types available tool (e.g., rank order, multiple choice, text box, slider scale).\nBecome familiar various formats (e.g., radio button, drop-, checkbox).\nexample, item rank order question (ranking three items), creating question multi-line, free-text entry form may lead duplicate entries (entering rank 1 ). However, using something like rank order question type drag drop format ensures participants allowed duplicate rankings.\nBecome familiar various question types available tool (e.g., rank order, multiple choice, text box, slider scale).Become familiar various formats (e.g., radio button, drop-, checkbox).example, item rank order question (ranking three items), creating question multi-line, free-text entry form may lead duplicate entries (entering rank 1 ). However, using something like rank order question type drag drop format ensures participants allowed duplicate rankings.finite number response options item, number isn’t large (less ~ 20) use controlled vocabularies (.e., pre-defined list values) rather open-text field (OpenAIRE_eu 2018; UK Data Service 2023).\nexample, list school name drop-item rather participants enter school name.\nprevents variation text entry (e.g., “Sunvalley Middle”, “sunvalley”, “Snvally Middle”), ultimately creates unnecessary data cleaning work may even lead unusable values.\n\nexample, list school name drop-item rather participants enter school name.\nprevents variation text entry (e.g., “Sunvalley Middle”, “sunvalley”, “Snvally Middle”), ultimately creates unnecessary data cleaning work may even lead unusable values.\nprevents variation text entry (e.g., “Sunvalley Middle”, “sunvalley”, “Snvally Middle”), ultimately creates unnecessary data cleaning work may even lead unusable values.infinite number response options item number options large, use open-text box.\ncan create searchable field tool, allowing participants easily sift options, absolutely . Otherwise, use text-box opposed participants scroll large list options.\nConsider adding examples possible response options clarify looking .\nUsing open-ended text boxes mean regroup information categories later cleaning process. just time-consuming requires interpretation decision-making part data cleaner.\ncan create searchable field tool, allowing participants easily sift options, absolutely . Otherwise, use text-box opposed participants scroll large list options.Consider adding examples possible response options clarify looking .Using open-ended text boxes mean regroup information categories later cleaning process. just time-consuming requires interpretation decision-making part data cleaner.ask one piece information per question.\nSeparating information prevents confusion case participant data collector swaps order information.\nexample, rather asking “Please list number students algebra class geometry class”, split two separate questions questions download two separate items dataset: “Please list number algebra class”; “please list number geometry class”.\nalso includes simple examples splitting first_name last_name two separate fields.\nSeparating information prevents confusion case participant data collector swaps order information.example, rather asking “Please list number students algebra class geometry class”, split two separate questions questions download two separate items dataset: “Please list number algebra class”; “please list number geometry class”.also includes simple examples splitting first_name last_name two separate fields.protect participant privacy ensure integrity data, consider adding line introduction web-based instrument, instructing participants close browser upon completion others may access responses.Last, possible, export instrument human-readable document perform final checks.\nquestions accounted ?\nresponse options accounted coded ?\nskip logic shown expected?\nquestions accounted ?response options accounted coded ?skip logic shown expected?tool created, last step pilot data issues (see Figure 11.3). Collect sample responses team members. Create feedback checklist complete review instrument (Gibson Louw 2020). Assign different reviewers enter survey using varying criteria (e.g., different schools, different grade levels, branching options). Let team members know actively try break things—try enter nonsensical values, try skip items, try enter duplicate entries (Kopper Parry 2020). problems tool, now time find .sample responses collected team members, export sample data using chosen data capture process (see Chapter 12). Comparing export data dictionary, review data following:unexpected missing variables?unexpected variable names?unexpected values variables?missing values expect data?unexpected variable formats?data exporting analyzable, rectangular format? (see Chapter 3)issues found either team feedback reviewing exported sample data, take time update tool needed starting data collection. also time update documentation. review exported file, update data dictionary reflect unexpected variables included (e.g., metadata), unexpected formatting, well newly discovered recoding calculations required data cleaning process. example, upon downloading sample data, learn “select ” question exports differently expected, now time add information, along necessary future transformations, data dictionary. also great time update data cleaning plan (see Section 8.3.3) new transformations required.","code":""},{"path":"collect.html","id":"collect-paper","chapter":"11 Data Collection","heading":"11.2.4.2 Paper data collection","text":"many situations collecting data electronically may feasible best option project. definitely trickier design paper tool way prevents bad data, still steps can take improve data quality.Use data dictionary guide create paper form.\nMake sure questions included response options accurately added form.\nMake sure questions included response options accurately added form.clear instructions complete paper form (Kopper Parry 2021).\nMake sure overall instructions top form also explicit instructions question completed.\nwrite answers (e.g., margin)\nanswers recorded (e.g., YYYY-MM-DD, 3-digit number)\nmany answers recorded (e.g., circle one answer, check applicable boxes)\nnavigate branching logic (e.g., include visual arrows)\n\nMake sure overall instructions top form also explicit instructions question completed.\nwrite answers (e.g., margin)\nanswers recorded (e.g., YYYY-MM-DD, 3-digit number)\nmany answers recorded (e.g., circle one answer, check applicable boxes)\nnavigate branching logic (e.g., include visual arrows)\nwrite answers (e.g., margin)answers recorded (e.g., YYYY-MM-DD, 3-digit number)many answers recorded (e.g., circle one answer, check applicable boxes)navigate branching logic (e.g., include visual arrows)ask one piece information per question reduce confusion interpretation.tool created, want pilot instrument team data issues (see Figure 11.4). Using feedback collected, edit tool needed sending field.Last, unless paper data collected using machine-readable form, need manually entered electronic format data capture phase. talk data entry specifically Section 12.2, point instrument creation great time create annotated instrument (Neild, Robinson, Agufa 2022). includes taking copy instrument writing associated codes alongside item (.e., variable name value codes). annotated instrument can useful data entry process serve linking key instrument data dictionary. See Figure 11.5 example annotated instrument wave 1 Florida State Twin Registry project shared LDbase repository (Hart, Schatschneider, Taylor 2018).\nFigure 11.5: Annotated parent survey wave 1 Florida State Twin Registry project (2018)\n","code":""},{"path":"collect.html","id":"identifiers","chapter":"11 Data Collection","heading":"11.2.4.3 Identifiers","text":"building data collection tools, matter paper electronic, vitally important make sure collecting unique identifiers (Kopper Parry 2021). Whether participants enter unique identifier form link study ID (see Section 10.4) form way, ’s important accidentally collect anonymous data. Without unique identifiers data, unable link data across time forms. possible, want avoid collecting names unique identifiers following reasons (McKenzie 2010):protect confidentiality, want use names little possible forms.\nused forms, want remove soon possible.\nused forms, want remove soon possible.Names unique.\ncollect names, ’ll want ask additional identifying information combined, make participant unique (e.g., student name email).\ncollect names, ’ll want ask additional identifying information combined, make participant unique (e.g., student name email).Names change (e.g., someone gets married/divorced).much room error.\nnames hand entered, endless issues case sensitivity, spelling errors, special characters, spacing, forth.\nnames hand entered, endless issues case sensitivity, spelling errors, special characters, spacing, forth.issues make difficult link data. decide collect names, remember need remove names data processing replace unique study identifiers (see Section 14.3 information process).Rather de-identify data cleaning process, another option collect different type unique identifier, pre-link unique study identifiers names instrument, removing many issues (DIME Analytics 2021a; Gibson Louw 2020). discuss methods separately electronic data paper data.NoteIf study designed collect anonymous data, assign study identifiers participant identifying information collected instruments (e.g., name, email, date birth). also want make sure tool collects identifying metadata, IP Address worker IDs case crowdsourcing tools (e.g., MTurk), information included downloaded data.Remember collect anonymous data, able link data across measures across time. However, study randomizes participants entity (e.g., school district), need collect identifying information entity order cluster information (e.g., school name).","code":""},{"path":"collect.html","id":"electronic-data","chapter":"11 Data Collection","heading":"11.2.4.3.1 Electronic Data","text":"many ways might consider collecting unique identifiers names. possible options provided . method choose depend data collection design, participant population, tool capabilities, team expertise.Create unique links participants\nMany tools allow preload contact list participants (participant tracking database) includes names study IDs. Using list, tool can create unique links participant. error-proof way ensure study IDs entered correctly.\nexport data, correct ID already linked participant can choose export identifying information (e.g., names, emails) data.\nusing method, make sure build data check system. example, participant opens unique link, verify identity asking, “{first name}?” “initials {initials}?”. order protect participant identities, share full names.\nsay yes, move forward. say , system redirects someone contact. ensures participants completing someone else’s survey IDs connected correct participant.\n\nMany tools allow preload contact list participants (participant tracking database) includes names study IDs. Using list, tool can create unique links participant. error-proof way ensure study IDs entered correctly.export data, correct ID already linked participant can choose export identifying information (e.g., names, emails) data.using method, make sure build data check system. example, participant opens unique link, verify identity asking, “{first name}?” “initials {initials}?”. order protect participant identities, share full names.\nsay yes, move forward. say , system redirects someone contact. ensures participants completing someone else’s survey IDs connected correct participant.\nsay yes, move forward. say , system redirects someone contact. ensures participants completing someone else’s survey IDs connected correct participant.Provide one link participants separately, email, person, mail, provide participants study ID enter system.\nmight preferred method collecting data computer lab tablets school site, tool option create unique links.\ncan possibly introduce error participant enters study ID incorrectly.\nSimilar first option, participant enters ID, verify identity.\n\nNote participants becoming aware study identifier, identifiers associated participants. However, team, Institutional Review Board (IRB), uncomfortable participants knowing study IDs can also consider using “double ID” yet another set unchanging unique identifiers use sole purpose data collection. identifiers need tracked participant tracking database need replaced study IDs clean data.\nmight preferred method collecting data computer lab tablets school site, tool option create unique links.can possibly introduce error participant enters study ID incorrectly.\nSimilar first option, participant enters ID, verify identity.\nSimilar first option, participant enters ID, verify identity.Note participants becoming aware study identifier, identifiers associated participants. However, team, Institutional Review Board (IRB), uncomfortable participants knowing study IDs can also consider using “double ID” yet another set unchanging unique identifiers use sole purpose data collection. identifiers need tracked participant tracking database need replaced study IDs clean data.previously assigned study identifiers (e.g., consent assent process part instrument), can participants enter identifying information (e.g., name) tool assign unique identifier participants.\nUsing method, can potentially download two separate files.\nOne just instrument data assigned study ID, name removed\nOne just identifying information assigned study ID (information added participant tracking database)\n\nUsing method, can potentially download two separate files.\nOne just instrument data assigned study ID, name removed\nOne just identifying information assigned study ID (information added participant tracking database)\nOne just instrument data assigned study ID, name removedOne just identifying information assigned study ID (information added participant tracking database)","code":""},{"path":"collect.html","id":"paper-data","chapter":"11 Data Collection","heading":"11.2.4.3.2 Paper Data","text":"take paper forms field consider following connect data participant (O’Toole et al. 2018; T. Reynolds, Schatschneider, Logan 2022).Write study ID, relevant identifiers (e.g., school ID teacher ID), page data collection form attach cover sheet participant name relevant information (see Figure 11.6). return office, can remove cover sheet left ID form.\nID enter data entry form data capture process, name.\nRemoving cover sheet ensures data entry team sees study ID enter data, increasing privacy minimizing number people see participant names.\nHowever, removing cover sheet, double check study identifiers participant database make sure information correct\nMake plan cover sheets (either shred longer needed, store securely locked file cabinet shred later point)\nID enter data entry form data capture process, name.Removing cover sheet ensures data entry team sees study ID enter data, increasing privacy minimizing number people see participant names.However, removing cover sheet, double check study identifiers participant database make sure information correctMake plan cover sheets (either shred longer needed, store securely locked file cabinet shred later point)\nFigure 11.6: Example cover sheet paper data collection instrument\n","code":""},{"path":"collect.html","id":"collect-irb","chapter":"11 Data Collection","heading":"11.2.5 Ensure compliance","text":"collecting human subjects data study considered research (see Glossary definitions terms), important consult applicable IRB specific requirements moving forward data collection efforts. discussed Chapter 4, IRB committee assesses ethics safety research studies involving human subjects. IRB application required project, review process can take several weeks , common IRB request revisions submission materials. Make sure review timeline give plenty time work process need begin recruitment data collection.Informed consent agreements, assents participants age 18, commonly required IRBs research studies collect human subjects data. discussed Chapter 4, agreements ensure participants fully understand asked voluntarily agree participate study. several categories information required include consent form (e.g., description study, types data collected, risks benefits participant, participant privacy maintained) (Turing Way Community 2022). Make sure consult applicable IRB included. increase federal data sharing requirements, important time also consider want gain consent public data sharing (Levenstein Lyle 2018). two risks posed data sharing important address consent—loss privacy using data purposes participants agree . Meyer (2018) provides general best practices consider adding language public data sharing consent form.Don’t promise destroy data (unless funder/IRB explicitly requires ).\nincorporate data retention sharing plans including letting participants know access data.\nincorporate data retention sharing plans including letting participants know access data.Don’t promise share data.\nget consent retain share data (consider adding specific repository plan share data ).\nConsider offering tiered levels consent participants may want data publicly shared allow .\nget consent retain share data (consider adding specific repository plan share data ).Consider offering tiered levels consent participants may want data publicly shared allow .Don’t promise research analyses collected data limited certain topics.\nsay data may used future research share general purposes (e.g., replication, new analyses).\nsay data may used future research share general purposes (e.g., replication, new analyses).review ways plan de-identify data thoughtful considering risks re-identification (e.g., small sample size sub-groups).essentially three different ways can go obtaining consent data sharing (Gilmore, Kennedy, Adolph 2018).Include line public data sharing consent participate research.\nmethod, participant consents agreeing participate research study data shared publicly.\nmethod, participant consents agreeing participate research study data shared publicly.participants consent data sharing time provide research study consent, provide separate consent form purposes public data sharing.participants consent data sharing separate consent form, later time, research activities completed.\nObtaining consent way ensures participants fully aware data collected can make informed decision future data.\nObtaining consent way ensures participants fully aware data collected can make informed decision future data.Consult IRB determine preferred method obtaining consent public data sharing. use method 2 3, important track participant study consent status tracking database (discussed Chapter 10), also add field track consent status data sharing publicly share data given permission . also want consider included final analysis sample. include consented participants analysis, publicly available dataset match analysis sample people consent data sharing. may need consider options using controlled-access repository share full sample purposes replication. discuss different methods data sharing Chapter 16.","code":""},{"path":"collect.html","id":"building-consent-forms","chapter":"11 Data Collection","heading":"11.2.5.1 Building consent forms","text":"required collect consent study, quality assurance considered forms well. Keeping consent assent forms secure top priority team due identifiable information form. also important able clearly identify consenting individual form. Whether collect consent paper electronically, make sure clear quality assurance plan.Use institution IRB approved tools collect consent.collecting paper consent, make sure able clearly identify consenting individual (e.g., participant printed name signature alone may sufficient due duplicate names, nicknames used, illegible handwriting). One option pre-print names relevant information forms school staff write participant names forms handing .Templates Resources","code":""},{"path":"collect.html","id":"collect-control","chapter":"11 Data Collection","heading":"11.3 Quality control","text":"addition implementing quality assurance measures data collection, equally important implement several quality control measures data collection underway. measures include:Field data managementOngoing data checksTracking data collection dailyCollecting data consistentlyWe discuss measures section.","code":""},{"path":"collect.html","id":"collect-field","chapter":"11 Data Collection","heading":"11.3.1 Field data management","text":"data collection efforts include field data collection (e.g., data collectors administering assessments school), several steps team can implement keep data secure field, help project coordinator keep better track happens field, lead accurate usable data. best practices field data collection include following (DIME Analytics 2021a):Keep data secure field.\nMake sure paper forms kept folder (even lock box) times, promptly returned office (e.g., left car, left someone’s home).\nespecially important considering paper consent forms. forms contain identifiable participant information, form misplaced, longer consent collect participant’s data.\n\nEnsure electronic data collection devices (e.g., phones, tablets) password protected never left open unattended. Keep identifiable information encrypted field devices (.e., data encoded password can decipher ). may also consider remote wiping capabilities portable devices case loss theft (O’Toole et al. 2018).\nMake sure paper forms kept folder (even lock box) times, promptly returned office (e.g., left car, left someone’s home).\nespecially important considering paper consent forms. forms contain identifiable participant information, form misplaced, longer consent collect participant’s data.\nespecially important considering paper consent forms. forms contain identifiable participant information, form misplaced, longer consent collect participant’s data.Ensure electronic data collection devices (e.g., phones, tablets) password protected never left open unattended. Keep identifiable information encrypted field devices (.e., data encoded password can decipher ). may also consider remote wiping capabilities portable devices case loss theft (O’Toole et al. 2018).Create tracking sheets use field.\nsheets include names /identifiers every participant data collectors collecting data .\nNext participant, include relevant information track \ndata collected (.e., check box)\ncollected data (.e., data collector initials ID)\nDate data collected\nwell notes section describe potential issues data (e.g., “Student leave classroom halfway assessment” “Student refused continue assessment”)\n\ntracking sheet allows project coordinator keep track occurring field information can accurately recorded participant tracking database forms can sent back completion needed.\nsheets include names /identifiers every participant data collectors collecting data .Next participant, include relevant information track \ndata collected (.e., check box)\ncollected data (.e., data collector initials ID)\nDate data collected\nwell notes section describe potential issues data (e.g., “Student leave classroom halfway assessment” “Student refused continue assessment”)\ndata collected (.e., check box)collected data (.e., data collector initials ID)Date data collectedAs well notes section describe potential issues data (e.g., “Student leave classroom halfway assessment” “Student refused continue assessment”)tracking sheet allows project coordinator keep track occurring field information can accurately recorded participant tracking database forms can sent back completion needed.Check physical data field.\nImmediately upon completing form, data collectors spot checks. problems found, follow participant correction possible.\nCheck missing data\nCheck duplicate answers given (.e., two answers circled question one)\nCheck answers provided outside assigned area (e.g., answers written margins)\nCheck calculations scoring (e.g., basals, ceilings, raw scores)\n\nImmediately upon completing form, data collectors spot checks. problems found, follow participant correction possible.\nCheck missing data\nCheck duplicate answers given (.e., two answers circled question one)\nCheck answers provided outside assigned area (e.g., answers written margins)\nCheck calculations scoring (e.g., basals, ceilings, raw scores)\nCheck missing dataCheck duplicate answers given (.e., two answers circled question one)Check answers provided outside assigned area (e.g., answers written margins)Check calculations scoring (e.g., basals, ceilings, raw scores)Assign field supervisor. person assigned :\nanother round data checks field data collector returns physical forms -site central location (e.g., data collectors set teacher’s lounge).\nEnsure data equipment accounted returned office.\navailable trouble shooting needed.\nanother round data checks field data collector returns physical forms -site central location (e.g., data collectors set teacher’s lounge).Ensure data equipment accounted returned office.available trouble shooting needed.another round physical data spot checking soon data returned office (see Figure 11.7).\nproject coordinator may round checking tracking information participant database.\nissues found, note tracking database send form back field correction.\npaper forms mailed back participants, rather returned field data collectors, still important -office spot checks. possible, reach participants corrections.\nproject coordinator may round checking tracking information participant database.issues found, note tracking database send form back field correction.paper forms mailed back participants, rather returned field data collectors, still important -office spot checks. possible, reach participants corrections.wave data collection wraps , collect feedback data collectors improve future data collection efforts.\nwent well? didn’t?\nwent well? didn’t?\nFigure 11.7: series spot checks occur paper data\nTracking sheet templates","code":""},{"path":"collect.html","id":"ongoing-data-checks","chapter":"11 Data Collection","heading":"11.3.2 Ongoing data checks","text":"collect data via web-based form, want perform frequent data quality checks, similar checks performed content data piloting phase. want check programming errors (e.g., skip logic programmed incorrectly) well response quality errors (e.g., bots, survey comprehension) (DIME Analytics 2021a; Gibson 2021). Consider following:Checks comprehension\nquestions misinterpreted? form contains free-text field, spot-check see responses make sense.\nquestions misinterpreted? form contains free-text field, spot-check see responses make sense.Checks missing data\nitems skipped skipped?\nparticipants/data collectors finishing forms?\nitems skipped skipped?participants/data collectors finishing forms?Checks ranges formats\nvalues unexpected formats falling outside unexpected ranges?\nvalues unexpected formats falling outside unexpected ranges?Checks duplicate forms\nduplicate entries participants?\nduplicate entries participants?skip logic working expected?\npeople directed correct location based responses items?\npeople directed correct location based responses items?checks can performed programmatically (.e., can write script program R pull check things like range values recurring schedule). checks may require manual effort (e.g., downloading data recurring schedule reviewing open-ended questions nonsensical responses). errors found, consider revising instrument prevent future errors possible without jeopardizing consistency data.","code":""},{"path":"collect.html","id":"tracking-data-collection","chapter":"11 Data Collection","heading":"11.3.3 Tracking data collection","text":"Throughout data collection team tracking completion forms (e.g., consents, paperwork, data collection forms) participant database (see Chapter 10). includes paper forms, electronic forms stored devices, well web-based data coming . team may designate one person track data (e.g., project coordinator), may designate multiple. working across multiple sites, multiple teams, likely one people site tracking data comes .tracking best practices include:track data physically (paper electronic).\nNever track data “complete” someone just tells collected.\ncan always mark information “notes” field track “complete” physical data.\n\nNever track data “complete” someone just tells collected.\ncan always mark information “notes” field track “complete” physical data.\ncan always mark information “notes” field track “complete” physical data.Track daily data collection.\nwait end data collection track data collected.\nhelps ensure don’t miss opportunity collect data thought never actually collected.\nwait end data collection track data collected.helps ensure don’t miss opportunity collect data thought never actually collected.track complete data “complete”.\nReview data marking “complete”, including consents, assents, administrative forms. Make tracking step immediately spot checking process. form partially completed plan send back field completion, mark “notes” mark “completed”. “partially completed” option, can mark option.\nReview data marking “complete”, including consents, assents, administrative forms. Make tracking step immediately spot checking process. form partially completed plan send back field completion, mark “notes” mark “completed”. “partially completed” option, can mark option.mentioned Chapter 10, use tool REDCap collection tracking, may need manual tracking. Completion fields may automatically update data collected. ’ll need determine needed based specific scenario.","code":""},{"path":"collect.html","id":"collecting-data-consistently","chapter":"11 Data Collection","heading":"11.3.4 Collecting data consistently","text":"important collect data consistently entire project ensure interoperability harmonization information. Keep following consistent across repeated collections form (e.g., Spanish English version form, Site Site B form, wave 1 wave 2 collecting form):Variable names\nUse names items\nRemember ’s best add time component variable names time (See Section 9.4.1 information).\nUse names itemsRemember ’s best add time component variable names time (See Section 9.4.1 information).Variable types formats\nexample, gender collected numeric variable one form, keep numeric variable forms.\n, svy_date collected YYYY-MM-DD one form, keep format across forms.\nexample, gender collected numeric variable one form, keep numeric variable forms., svy_date collected YYYY-MM-DD one form, keep format across forms.Value codes\nMake sure response options consistently coded using values (e.g., “” = 0 | “yes” = 1) (see Section 9.5 information).\nMake sure response options consistently coded using values (e.g., “” = 0 | “yes” = 1) (see Section 9.5 information).Question type format\nexample, slider question used “Percent time homework”, continue ask question using slider question.\nexample, slider question used “Percent time homework”, continue ask question using slider question.Failing collect data consistently many consequences.can make difficult impossible compare outcomes.makes work less reproducible.reduces ability combine data (.e., append dissimilar variables).can lead errors interpretation.Last, collecting data consistently also means measuring things way time across forms don’t bias results. slightest change item wording response options can result dramatic changes outcomes (ICPSR 2022; Pew Research Center 2023). item absolutely needs edited study begins (e.g., response option left ), version edited variable (e.g., stress1 stress1_v2) note variable edited data dictionary. Similarly, items added instrument later point study, make sure follow quality assurance procedures including adding items data dictionary noting items added, adding instrument.","code":""},{"path":"collect.html","id":"bot-detection","chapter":"11 Data Collection","heading":"11.4 Bot detection","text":"web-based data collection efforts chapter assume making private link sharing targeted list (e.g., students classroom, teachers school). However, may times need publicly recruit collect data study, opens instrument plethora data quality issues. Bots, fraudulent data, incoherent synthetic responses issues can plague online data collection efforts, particularly crowdsourcing platforms (Douglas, Ewell, Brauer 2023; Veselovsky, Ribeiro, West 2023; Webb Tangney 2022). possible, avoid using public survey links. One possible workaround first create public link screener. participants verified screener, send private, unique link instrument.workaround possible need use public link, quality assurance suggestions can help secure instrument detect fraud include following (Arndt et al. 2022; Simone 2019; Teitcher et al. 2015):posting link social mediaUsing CAPTCHA verification, CAPTCHA alternative, distinguish human machineUsing tools allow block suspicious geolocationsNot automating payment upon survey completionIncluding open-ended questionsBuilding attention/logic checks surveyAsking questions twice (early end)Last, implement quality control checks bots fraudulent responses analyzing data providing payments participants. following types things worth looking :Forms completed short period timeForms collected suspicious geolocationsDuplicated nonsensical responses open-ended questionsNonsensical responses attention logic checking questionsInconsistent responses across repeated questions","code":""},{"path":"collect.html","id":"review","chapter":"11 Data Collection","heading":"11.5 Review","text":"Recall Chapter 6, discussed designing visualizing data collection workflow planning phase. ’ve learned chapter, errors can happen point workflow, important consider entire data collection process holistically integrate quality assurance quality control procedures throughout. Figure 11.8 helps us see practices fit different phases workflow.workflow developed quality assurance control practices integrated, consider ensure team implements practices fidelity. Document specifics plan SOP (see Section 8.2.7), including assigning roles responsibilities task process. Last, train team implement data collection SOP, implement refresher trainings needed.\nFigure 11.8: Integrating quality assurance control data collection workflow\nInstrument Workflow Resources","code":""},{"path":"capture.html","id":"capture","chapter":"12 Data Capture","heading":"12 Data Capture","text":"\nFigure 12.1: Data capture research project life cycle\ndata collection period complete, next phase cycle capture data. extracting, creating, acquiring flat file, consisting data previously collected electronically paper, can save designated storage location. quantitative research typically want capture data electronic, rectangular format can easily analyzed shared (see Chapter 3). chapter review common ways capture data based three data collection methods (see Figure 12.2). Similar data collection, possible data errors occur phase. reviewing data capture methods, also cover data quality can managed phase.\nFigure 12.2: Common data capture methods\n","code":""},{"path":"capture.html","id":"capture-electronic","chapter":"12 Data Capture","heading":"12.1 Electronic data capture","text":"discussed Chapter 11, electronic data can collected using variety software (either web-based offline). Since electronic forms typically funnel data spreadsheet database, makes process data capture much easier compared paper data. However, still much consider.data captured?\ncommon way capture web-based forms download platform.\nmay also able capture data via API (application programming interface). regularly need capture data quality control purposes, using API can great way remove burden manually logging program going point click process downloading file. Instead, can write script, program R, extract data. script created, can run often want. However, option tool API available (e.g., Qualtrics).\n\nusing devices connect internet, consider securely pull files devices.\ncommon way capture web-based forms download platform.\nmay also able capture data via API (application programming interface). regularly need capture data quality control purposes, using API can great way remove burden manually logging program going point click process downloading file. Instead, can write script, program R, extract data. script created, can run often want. However, option tool API available (e.g., Qualtrics).\nmay also able capture data via API (application programming interface). regularly need capture data quality control purposes, using API can great way remove burden manually logging program going point click process downloading file. Instead, can write script, program R, extract data. script created, can run often want. However, option tool API available (e.g., Qualtrics).using devices connect internet, consider securely pull files devices.file type data captured ?\nelectronic data collection tools provide option export one file formats (e.g., SPSS, CSV, XLSX). important choose file type analyzable (.e., rectangular formatted), opposed something like PDF file. rectangular file type choose mostly depend project plans. Things consider include:\nwant embedded metadata, variable value labels, raw file? , choice narrow options (e.g., SPSS file allows export numeric values also able view variable value labels file).\nwant non-proprietary, interoperable format? yes, want capture data file type, CSV, require proprietary software view.\nfile types create issues variables?\ninstance, XLSX well-known applying unwanted formatting values. example, assessment tool collects age format “years-months”, oftentimes Microsoft Excel change variable date, converting value “10-2” (10 years 2 months old) “2-Oct”. suitable file type situation may CSV TXT file, apply formatting.\n\nfile structure don’t want work ?\nexample, structure SPSS file may look different compared XLSX file depending tool. tool like Qualtrics, XLSX CSV file may export multiple header rows whereas SPSS file .\n\n\nelectronic data collection tools provide option export one file formats (e.g., SPSS, CSV, XLSX). important choose file type analyzable (.e., rectangular formatted), opposed something like PDF file. rectangular file type choose mostly depend project plans. Things consider include:\nwant embedded metadata, variable value labels, raw file? , choice narrow options (e.g., SPSS file allows export numeric values also able view variable value labels file).\nwant non-proprietary, interoperable format? yes, want capture data file type, CSV, require proprietary software view.\nfile types create issues variables?\ninstance, XLSX well-known applying unwanted formatting values. example, assessment tool collects age format “years-months”, oftentimes Microsoft Excel change variable date, converting value “10-2” (10 years 2 months old) “2-Oct”. suitable file type situation may CSV TXT file, apply formatting.\n\nfile structure don’t want work ?\nexample, structure SPSS file may look different compared XLSX file depending tool. tool like Qualtrics, XLSX CSV file may export multiple header rows whereas SPSS file .\n\nwant embedded metadata, variable value labels, raw file? , choice narrow options (e.g., SPSS file allows export numeric values also able view variable value labels file).want non-proprietary, interoperable format? yes, want capture data file type, CSV, require proprietary software view.file types create issues variables?\ninstance, XLSX well-known applying unwanted formatting values. example, assessment tool collects age format “years-months”, oftentimes Microsoft Excel change variable date, converting value “10-2” (10 years 2 months old) “2-Oct”. suitable file type situation may CSV TXT file, apply formatting.\ninstance, XLSX well-known applying unwanted formatting values. example, assessment tool collects age format “years-months”, oftentimes Microsoft Excel change variable date, converting value “10-2” (10 years 2 months old) “2-Oct”. suitable file type situation may CSV TXT file, apply formatting.file structure don’t want work ?\nexample, structure SPSS file may look different compared XLSX file depending tool. tool like Qualtrics, XLSX CSV file may export multiple header rows whereas SPSS file .\nexample, structure SPSS file may look different compared XLSX file depending tool. tool like Qualtrics, XLSX CSV file may export multiple header rows whereas SPSS file .additional formatting options need considered?\naddition choosing file type, may options tool allows consider. available options worded vary depending tool use. However, examples options may encounter include:\nOptions export text values categorical fields export numeric values associated category. options may limited chosen file type (e.g., text values may available CSV SPSS file).\nOptions formatting “select ” (multi-response) questions. Typically tools provide two options (see Figure 12.3).\nExport selections one variable, selection separated comma. can imagine, can get messy export text responses contain commas.\nSplit option column.\n\nOptions recoding seen unanswered questions.\ntools may allow recode blanks value -99. Selecting option enables better determine values missing seen seen purposefully skipped. can especially helpful “select ” questions cell values blank option selected. options selected, can difficult determine entire question skipped options purposefully selected, unless seen unanswered cells recoded.\n\nOptions export variables tagged identifiers.\ntool allows tag certain fields identifiable (e.g., name, email), may option exclude variables export.\n\n\naddition choosing file type, may options tool allows consider. available options worded vary depending tool use. However, examples options may encounter include:\nOptions export text values categorical fields export numeric values associated category. options may limited chosen file type (e.g., text values may available CSV SPSS file).\nOptions formatting “select ” (multi-response) questions. Typically tools provide two options (see Figure 12.3).\nExport selections one variable, selection separated comma. can imagine, can get messy export text responses contain commas.\nSplit option column.\n\nOptions recoding seen unanswered questions.\ntools may allow recode blanks value -99. Selecting option enables better determine values missing seen seen purposefully skipped. can especially helpful “select ” questions cell values blank option selected. options selected, can difficult determine entire question skipped options purposefully selected, unless seen unanswered cells recoded.\n\nOptions export variables tagged identifiers.\ntool allows tag certain fields identifiable (e.g., name, email), may option exclude variables export.\n\nOptions export text values categorical fields export numeric values associated category. options may limited chosen file type (e.g., text values may available CSV SPSS file).Options formatting “select ” (multi-response) questions. Typically tools provide two options (see Figure 12.3).\nExport selections one variable, selection separated comma. can imagine, can get messy export text responses contain commas.\nSplit option column.\nExport selections one variable, selection separated comma. can imagine, can get messy export text responses contain commas.Split option column.Options recoding seen unanswered questions.\ntools may allow recode blanks value -99. Selecting option enables better determine values missing seen seen purposefully skipped. can especially helpful “select ” questions cell values blank option selected. options selected, can difficult determine entire question skipped options purposefully selected, unless seen unanswered cells recoded.\ntools may allow recode blanks value -99. Selecting option enables better determine values missing seen seen purposefully skipped. can especially helpful “select ” questions cell values blank option selected. options selected, can difficult determine entire question skipped options purposefully selected, unless seen unanswered cells recoded.Options export variables tagged identifiers.\ntool allows tag certain fields identifiable (e.g., name, email), may option exclude variables export.\ntool allows tag certain fields identifiable (e.g., name, email), may option exclude variables export.\nFigure 12.3: Two different ways may export “select ” question\nfile stored?\ndecision based guidelines ’ve laid data storage documentation (see Chapter 13).\ndecision based guidelines ’ve laid data storage documentation (see Chapter 13).files named?\ntool may provide name file, may need renamed something meaningful based style guide rules (see Section 9.3). importantly, name files consistently across data sources waves.\ntool may provide name file, may need renamed something meaningful based style guide rules (see Section 9.3). importantly, name files consistently across data sources waves.documentation needs accompany data capture?\nREADME can beneficial store alongside file anything file future person managing data aware (see Section 8.3.1).\nchangelog can also beneficial (see Section 8.3.2) store file. common redownload raw data file due errors found new participants added. changelog can help team identify recent version raw data file, well understand differences files.\nREADME can beneficial store alongside file anything file future person managing data aware (see Section 8.3.1).changelog can also beneficial (see Section 8.3.2) store file. common redownload raw data file due errors found new participants added. changelog can help team identify recent version raw data file, well understand differences files.checks need happen data handed ?\nimportant person responsible data capture basic review file handing data next step.\nformat file look expected? data ? variables expected?\nparticipants data? excellent time compare number unique participants file number participants completed data participant tracking database. numbers match, person charge data capture begin reconciling errors handing data.\nparticipant accidentally dropped file? someone incorrectly marked complete tracking database? duplicate entries file?\nerrors can corrected (e.g., someone incorrectly tracked data point, participant left capture process), corrections made now. corrections involve manipulating raw data (e.g., reconciling duplicate IDs data, ID incorrectly entered data), corrections made time. Instead, added README file corrected data cleaning phase.\n\n\n\nimportant person responsible data capture basic review file handing data next step.\nformat file look expected? data ? variables expected?\nparticipants data? excellent time compare number unique participants file number participants completed data participant tracking database. numbers match, person charge data capture begin reconciling errors handing data.\nparticipant accidentally dropped file? someone incorrectly marked complete tracking database? duplicate entries file?\nerrors can corrected (e.g., someone incorrectly tracked data point, participant left capture process), corrections made now. corrections involve manipulating raw data (e.g., reconciling duplicate IDs data, ID incorrectly entered data), corrections made time. Instead, added README file corrected data cleaning phase.\n\n\nformat file look expected? data ? variables expected?participants data? excellent time compare number unique participants file number participants completed data participant tracking database. numbers match, person charge data capture begin reconciling errors handing data.\nparticipant accidentally dropped file? someone incorrectly marked complete tracking database? duplicate entries file?\nerrors can corrected (e.g., someone incorrectly tracked data point, participant left capture process), corrections made now. corrections involve manipulating raw data (e.g., reconciling duplicate IDs data, ID incorrectly entered data), corrections made time. Instead, added README file corrected data cleaning phase.\n\nparticipant accidentally dropped file? someone incorrectly marked complete tracking database? duplicate entries file?\nerrors can corrected (e.g., someone incorrectly tracked data point, participant left capture process), corrections made now. corrections involve manipulating raw data (e.g., reconciling duplicate IDs data, ID incorrectly entered data), corrections made time. Instead, added README file corrected data cleaning phase.\nerrors can corrected (e.g., someone incorrectly tracked data point, participant left capture process), corrections made now. corrections involve manipulating raw data (e.g., reconciling duplicate IDs data, ID incorrectly entered data), corrections made time. Instead, added README file corrected data cleaning phase.capture data?\ndoesn’t necessarily matter takes responsibility. matters person expertise capture data responsibility documented. person capturing data person oversees data collection, important still assign data collection supervisor responsibility documenting relevant information README.\ndoesn’t necessarily matter takes responsibility. matters person expertise capture data responsibility documented. person capturing data person oversees data collection, important still assign data collection supervisor responsibility documenting relevant information README.NoteIt important never make changes directly raw data files. also includes making changes directly data data collection tool. see errors raw data file can’t fixed simply re-downloading data, make notes README future correction noted earlier section. corrections can made data cleaning process. one exception rule accidentally collect data non-consented participant. case, may best delete data participant directly data collection tool record kept.","code":""},{"path":"capture.html","id":"documenting-electronic-data-capture","chapter":"12 Data Capture","heading":"12.1.1 Documenting electronic data capture","text":"decisions made documented time developing data collection tools. Making decisions early allows also implement pilot testing data checking processes. instance, plan capture data exporting CSV file data collection platform variety options selected, want use method data piloting data checking process. allows know exactly data look like data collection complete make adjustments needed.discussed Chapter 6, data capture process added workflow diagram detailed SOP (see Section 8.2.7). decisions process exist relevant SOP. ensures workflows standardized reproducible. ’ve learned section, one deviation SOP potential produce different data product (e.g., format CSV file compared SPSS file can vary). can produce errors, can also undermine reproducibility data cleaning pipeline. Imagine scenario data cleaning syntax written import CSV file expected format, format changes. pipeline longer reproducible. Last, documenting timeline data capture process occur can also beneficial person responsible data capture, well people responsible subsequent phases data cleaning.example data capture steps might add student survey data collection SOP.","code":"[Project Coordinator Name]\n1. Download a CSV file with the following options selected\n  - Use numeric values\n  - Recode seen but unanswered questions as -99\n  - Split multi-response fields into columns\n2. Save the file in wave# -> student -> survey -> raw\n  - Name the file \"pn_w#_stu_svy_raw_YYYY-MM-DD.csv\"\n3. Add a README to the folder as needed to describe any known issues with the data\n  - Add a changelog as needed when new datasets are downloaded\n4. Open and review the file\n  - Compare the variables in the file to the data dictionary to ensure the file looks as expected\n  - Compare the number of rows in the file to the number of surveys tracked as complete in the participant tracking database\n    - If the numbers do not align, correct errors (or note them in a README) and redownload the survey as needed.\n5. Notify the data manager that the data is ready for cleaning.\n"},{"path":"capture.html","id":"capture-paper","chapter":"12 Data Capture","heading":"12.2 Paper data capture","text":"common method capturing paper forms manual entry. capturing electronic data fairly quick straightforward, planning implementing paper data entry much involved. Similar electronic data collection, want start planning data entry long data collected, need build data entry tool data capture phase (e.g., creating data collection tools).can imagine, manually entering data comes potential many data quality issues. developing data entry process, important implement quality assurance control practices similar discussed Chapter 11.Choose quality data entry toolBuild data entry form end mindDevelop data entry procedure","code":""},{"path":"capture.html","id":"choose-a-quality-data-entry-tool","chapter":"12 Data Capture","heading":"12.2.1 Choose a quality data entry tool","text":"Unless entering data required proprietary assessment scoring tool, need choose data entry tool. choosing tool, already using relational database participant tracking, may make sense use database data entry data can stored one location tables can linked (e.g., REDCap, FileMaker, Microsoft Access). However, need choose new tool data entry, criteria choosing one similar reviewed Section 11.2.3. Considerations project needs, security, costs, data quality still reviewed.addition reviewing criteria, can also beneficial use tool allows create entry forms (also called data entry screens), similar form saw Figure 10.9, rather entering directly spreadsheet. Building data entry screen laid similar paper form can help reduce errors data entry. Data entered form fed table can exported.however, choose use spreadsheet program SPSS Microsoft Excel data entry, important aware limitations possible issues tools including:Possible formatting issues\nexample, Microsoft Excel formatting may cause errors data (e.g., dates get formatted numeric, strings get formatted dates, leading zeros get dropped values).\nexample, Microsoft Excel formatting may cause errors data (e.g., dates get formatted numeric, strings get formatted dates, leading zeros get dropped values).Potential skip around\nspreadsheet, ability click anywhere makes easy enter data wrong cell skip cells completely (Eaker 2016). may even delete write existing data accident. ’s also possible incorrectly sort data resulting errors (T. Reynolds, Schatschneider, Logan 2022).\nspreadsheet, ability click anywhere makes easy enter data wrong cell skip cells completely (Eaker 2016). may even delete write existing data accident. ’s also possible incorrectly sort data resulting errors (T. Reynolds, Schatschneider, Logan 2022).","code":""},{"path":"capture.html","id":"build-with-the-end-in-mind","chapter":"12 Data Capture","heading":"12.2.2 Build with the end in mind","text":"export save dataset data entry tool, meet data organization rules (see Chapter 3), variables formatted described data dictionary, including correct name, variable type, allowable values. order accomplish goal, need build data entry screens, whether spreadsheet form layout, following rules similar discussed Section 11.2.4.Include every item form.\nassessments consider entering item-level data summary variables derived field. types variables can beneficial final project datasets. Make sure variables also accounted data dictionary.\nassessments consider entering item-level data summary variables derived field. types variables can beneficial final project datasets. Make sure variables also accounted data dictionary.Make sure items laid order appear paper form people entering data can easily follow flow (T. Reynolds, Schatschneider, Logan 2022).Using annotated instrument discussed Section 11.2.4.2, name items data entry screen match final item names (e.g., instead Q2 use final name tch_years).quicker data entry, less errors, allow people enter numeric values associated response options annotated instrument rather text values (e.g., enter 1 rather “strongly disagree”). prefer use text values, build drop-values, removing variation entry.Design data entry tool include content response validation.\nRestrict data type, format, ranges, values.\nallow people skip items.\nRestrict data type, format, ranges, values.allow people skip items.using data entry tool, want pilot issues, just like electronic data collection tools (see Section 11.2.4.1). Collect sample responses team members collect feedback work well entering data. download, using chosen download format, simply review data already final format (e.g., Microsoft Excel). Check data looks expect make edits entry tool needed.","code":""},{"path":"capture.html","id":"capture-entry","chapter":"12 Data Capture","heading":"12.2.3 Develop a data entry procedure","text":"building reliable data entry tool absolutely important ensuring data quality, developing clear standard data entry process even important. Figure 12.4 shows series decisions make regarding data entry process.\nFigure 12.4: flow decisions make regarding data entry process\nLet’s walk decisions made.create data entry tools, enter data, oversee process?paper forms stored pulled?entry databases spreadsheets stored can accessed?data entry rules?\nvalues entered categorical variables (numeric values text values)?\nfree-text entered prevent inconsistencies?\nadding data validation (e.g., allowing numeric values) help remove inconsistencies, rules may needed depending items. Examples rules include:\nEnter decimals leading zero (e.g. 0.4 .4)\nEnter “yes” values “Y” (e.g., change values “y” “yes” -> “Y”)\nenter numeric values measurements (e.g., 5 “5cm”)\n\n\nmissing data handled (e.g., fill -99)?\ndone team member comes across common data errors?\nSomeone circled one response item?\nSomeone written responses margin?\nSomeone written value range unallowable response?\n\nvalues entered categorical variables (numeric values text values)?free-text entered prevent inconsistencies?\nadding data validation (e.g., allowing numeric values) help remove inconsistencies, rules may needed depending items. Examples rules include:\nEnter decimals leading zero (e.g. 0.4 .4)\nEnter “yes” values “Y” (e.g., change values “y” “yes” -> “Y”)\nenter numeric values measurements (e.g., 5 “5cm”)\n\nadding data validation (e.g., allowing numeric values) help remove inconsistencies, rules may needed depending items. Examples rules include:\nEnter decimals leading zero (e.g. 0.4 .4)\nEnter “yes” values “Y” (e.g., change values “y” “yes” -> “Y”)\nenter numeric values measurements (e.g., 5 “5cm”)\nEnter decimals leading zero (e.g. 0.4 .4)Enter “yes” values “Y” (e.g., change values “y” “yes” -> “Y”)enter numeric values measurements (e.g., 5 “5cm”)missing data handled (e.g., fill -99)?done team member comes across common data errors?\nSomeone circled one response item?\nSomeone written responses margin?\nSomeone written value range unallowable response?\nSomeone circled one response item?Someone written responses margin?Someone written value range unallowable response?team members denote form entered?\nexample, staff can write initials form entry files can stored new drawer location denote first second entry.\nexample, staff can write initials form entry files can stored new drawer location denote first second entry.steps performed moving next phase data cleaning?\nSimilar process Section 12.1, imperative whoever overseeing data entry process check data handing next step data cleaning.\nimportantly, check see correct number participants exist file compared number participants data marked collected tracking database (.e., duplicate entries, missing entries).\ndata entry data tracking errors exist, fix mistakes needed finalizing entry process.\n\nSimilar process Section 12.1, imperative whoever overseeing data entry process check data handing next step data cleaning.importantly, check see correct number participants exist file compared number participants data marked collected tracking database (.e., duplicate entries, missing entries).\ndata entry data tracking errors exist, fix mistakes needed finalizing entry process.\ndata entry data tracking errors exist, fix mistakes needed finalizing entry process.Last, file type exported saved (e.g., CSV, XLSX, SPSS), files stored, named?\nStore according storage rules (see Chapter 13) name files according style guide (see Section 9.3).\nStore according storage rules (see Chapter 13) name files according style guide (see Section 9.3).NoteAs reminder, data capture phase time , capture data already collected. time score, calculate, add additional fields. time enter exact items found form. Creating additional variables performing data quality checks occur data cleaning phase.exception rule collected assessment requires entry proprietary scoring program. data entered, tools often export file includes derived scores assessment, still considered raw captured data sources.","code":""},{"path":"capture.html","id":"double-entry","chapter":"12 Data Capture","heading":"12.2.3.1 Double entry","text":"Last, data quality can improved double entering data. studies, Schmitt Burchinal (2011) found error-rate 5-10% data entered second person double-check data entry improves data quality. several ways double checking data including visual checking read aloud methods, double entry method shown reliable error-reducing technique (Barchard et al. 2020), ensuring displayed paper form entered database. typical double entry process looks something like .designated team member creates two identical entry forms. One person enters forms first entry screen, different person enters forms second entry screen. Depending tool might two separate files, two separate tabs spreadsheet, two separate tables forms database.\nimportant second entry completed different person systematic errors created one person’s interpretation information repeated across files.\nimportant second entry completed different person systematic errors created one person’s interpretation information repeated across files.entries complete, system used check inconsistencies across datasets.\nsystem varies across tools. tools built systems checking errors across entry screens. tools may require build system (e.g., write formulas compare cells draft syntax compare spreadsheets). Ultimately, comparisons done, report tells errors exist across two forms.\nsystem varies across tools. tools built systems checking errors across entry screens. tools may require build system (e.g., write formulas compare cells draft syntax compare spreadsheets). Ultimately, comparisons done, report tells errors exist across two forms.Using information gained comparing entry screens, designated team member makes corrections (Yenni et al. 2019). involves pulling original paper forms seeing correct value error.\nvarying ways can make corrections point. can make corrections just one form, can make corrections forms, can make corrections third, new form contains correct data. Different tools handle different ways.\nHowever, creating system, consider making corrections forms. way, make correction whichever entry file error. corrections made, can run comparison system , let know errors corrected. errors fixed, can choose either file “master” raw data file.\nvarying ways can make corrections point. can make corrections just one form, can make corrections forms, can make corrections third, new form contains correct data. Different tools handle different ways.However, creating system, consider making corrections forms. way, make correction whichever entry file error. corrections made, can run comparison system , let know errors corrected. errors fixed, can choose either file “master” raw data file.following one example process look like.Data entered two spreadsheets following quality assurance control procedures. , files imported R.function diffdf package (Gower-Page Martin 2020) run check errors report returned (see Figure 12.5).\ncan see identifies error mast1 variable. tch_id = 1235, entry file 1 (BASE) different value entry file 2 (COMPARE).\ncan see identifies error mast1 variable. tch_id = 1235, entry file 1 (BASE) different value entry file 2 (COMPARE).Paper forms checked see true reported answer value corrected corresponding entry file. value incorrect entry files, files corrected.Updated files imported back R comparison system run ensure errors exist.\nFigure 12.5: report displaying differences two entry files\nDepending amount data collected can time-consuming process. Double data entry matter weighing costs benefits. double entering data best way reduce data errors, cost double entering data might high, may decide double enter portion data gain smaller benefit.","code":""},{"path":"capture.html","id":"documenting-paper-data-capture","chapter":"12 Data Capture","heading":"12.2.4 Documenting paper data capture","text":"Whatever decisions throughout process, document SOP assign team members step. includes assigning someone create entry files, oversee data entry, create double entry comparison system, conduct comparison, make corrections, final checks handing data . Make sure train team system implemented consistently. types technical processes, addition -person training sessions, can also helpful record share videos covering procedures team members can review often necessary.","code":""},{"path":"capture.html","id":"scanning-forms","chapter":"12 Data Capture","heading":"12.2.5 Scanning forms","text":"possible may collect paper data using forms can scanned converted automatically machine-readable dataset. Depending whether team personally scanning whether external company captures data, potential save time energy compared manual data entry process. may also potential less error-prone manual entry, yet process still error-free caution taken capturing data (Jørgensen Karlsmose 1998). still important data checks ensure correct values recorded electronic file.","code":""},{"path":"capture.html","id":"capture-extant","chapter":"12 Data Capture","heading":"12.3 Extant data","text":"common education research also capture external supplemental data sources either link original data sources describe information sample. process capturing externally collected data vary widely depending source. Furthermore, quality usability data can also vary widely. section going review practices help acquire better, interpretable data. divide discussion two types data sources—non-public public.","code":""},{"path":"capture.html","id":"non-public-data-sources","chapter":"12 Data Capture","heading":"12.3.1 Non-public data sources","text":"Non-public, restricted-use, data sources files directly accessed public website (e.g., student education records, statewide longitudinal data systems). data typically individual-level may contain sensitive, usually identifiable, information combination variables enable identification. Acquiring sources usually involves data request process. Every data request system different Figure 12.6 provides example process might look like. important begin looking planning phase understand request initiated.\nFigure 12.6: Example non-public confidential data request process\nalready included provider’s data request process, important add quality assurance process sharing following information provider.periods requesting data (e.g., 2023-24 school year)variables requesting\nplan link data, make sure list includes unique identifier allows link external data existing original data.\nplan link data, make sure list includes unique identifier allows link external data existing original data.Variable details\nplanning combine data multiple sources (e.g., multiple school districts), can require hours harmonization make data comparable due variations data collected across agencies. can helpful let providers know exactly like variables formatted including:\nVariable type (e.g., numeric, text)\nVariable formats (e.g., DOB YYYY-MM-DD)\nValue coding (e.g., specify code FRPL categories)\nhandle missing data (e.g., leave cell blank)\naggregate summary data (e.g., number days absent full year term)\ncalculated variables (e.g., age assessment) consider requesting raw inputs calculate values (e.g., request date assessment DOB)\n\ncan help standardize inputs reduce confusion interpretation (Feeney et al. 2021).\nplanning combine data multiple sources (e.g., multiple school districts), can require hours harmonization make data comparable due variations data collected across agencies. can helpful let providers know exactly like variables formatted including:\nVariable type (e.g., numeric, text)\nVariable formats (e.g., DOB YYYY-MM-DD)\nValue coding (e.g., specify code FRPL categories)\nhandle missing data (e.g., leave cell blank)\naggregate summary data (e.g., number days absent full year term)\ncalculated variables (e.g., age assessment) consider requesting raw inputs calculate values (e.g., request date assessment DOB)\nVariable type (e.g., numeric, text)Variable formats (e.g., DOB YYYY-MM-DD)Value coding (e.g., specify code FRPL categories)handle missing data (e.g., leave cell blank)aggregate summary data (e.g., number days absent full year term)calculated variables (e.g., age assessment) consider requesting raw inputs calculate values (e.g., request date assessment DOB)can help standardize inputs reduce confusion interpretation (Feeney et al. 2021).Figure 12.7 example might provide information provider.\nFigure 12.7: Example variable request external data provider\nalso want make sure acquire following information:data shared\nmany data files provided file contain (e.g., enrollment file, assessment file, attendance file)?\nfile formats provided (e.g., CSV files)?\ndata shared (.e., timeline)?\ndata shared (e.g., email, drop secure folder)?\ndata contain identifiable information, make sure use secure file transfer method (see Chapter 13). received, make sure follow data sharing agreements around data stored.\n\nmany data files provided file contain (e.g., enrollment file, assessment file, attendance file)?file formats provided (e.g., CSV files)?data shared (.e., timeline)?data shared (e.g., email, drop secure folder)?\ndata contain identifiable information, make sure use secure file transfer method (see Chapter 13). received, make sure follow data sharing agreements around data stored.\ndata contain identifiable information, make sure use secure file transfer method (see Chapter 13). received, make sure follow data sharing agreements around data stored.points contact\nneed contact information acquiring data, also need know contact questions concerns come data received.\nneed contact information acquiring data, also need know contact questions concerns come data received.documentation accompany file\nReceiving data dictionaries codebooks along data vital allowing correctly interpret variables. especially important observing variations variables measured across sites even within sites across time (e.g., test score measured differently subsequent year).\ndocumentation exist, provide data provider form complete allows enter relevant, variable information (see Figure 12.8 example).\nvariable represents\nAllowable variable ranges\nCategorical code definitions\nvariable captured calculated (e.g., hand entered)\nuniverse variable (e.g., grades 3–5)\ndata quality concerns variables\n\nreceive new exports year, make sure request documentation year. possible way variables collected recorded change time.\nReceiving data dictionaries codebooks along data vital allowing correctly interpret variables. especially important observing variations variables measured across sites even within sites across time (e.g., test score measured differently subsequent year).documentation exist, provide data provider form complete allows enter relevant, variable information (see Figure 12.8 example).\nvariable represents\nAllowable variable ranges\nCategorical code definitions\nvariable captured calculated (e.g., hand entered)\nuniverse variable (e.g., grades 3–5)\ndata quality concerns variables\nvariable representsAllowable variable rangesCategorical code definitionsHow variable captured calculated (e.g., hand entered)universe variable (e.g., grades 3–5)data quality concerns variablesIf receive new exports year, make sure request documentation year. possible way variables collected recorded change time.\nFigure 12.8: Sample documentation form external data provider complete\nreceive external files, make sure perform quality control checks saving preparing data cleaning.Review files ensure participants accounted requested variables included.\nTrack information received participant tracking database (.e., track school record received stu_id = 1234). help determine duplicates missing cases.\nCompare variables data variables request. everything accounted ?\nReach back contact help needed.\nTrack information received participant tracking database (.e., track school record received stu_id = 1234). help determine duplicates missing cases.Compare variables data variables request. everything accounted ?Reach back contact help needed.Make sure necessary information correctly interpret data (.e., required documentation).Last, store files manner adheres applicable agreements name files according style guide rules.NoteWhen working external datasets, possible encounter inconsistencies across data sources (e.g., student shown different school across two files), well duplicate records within data source (e.g., student two state reading assessment scores) (Levesque, Fitzgerald, Pfeiffer 2015). anomalies can happen due human error due circumstances student mobility. may able work data provider solve data issues, others may important develop document data management rules consistently apply external data sources data cleaning phase (e.g., duplicate assessment records exist, earliest assessment date used).","code":""},{"path":"capture.html","id":"public-data-sources","chapter":"12 Data Capture","heading":"12.3.2 Public data sources","text":"Publicly available data sources typically aggregated (.e., state, district, school level) de-identified individual level datasets available various agencies state departments education federal agencies. datasets often extracted downloading file, although organizations may sophisticated API capabilities. quality datasets may vary. tips working publicly available datasets :Extract data early project.\nEven date data need, ’s important get sense early data looks like (e.g., variables included, file types data stored , files structured). helps prepare future data wrangling needs.\nEven date data need, ’s important get sense early data looks like (e.g., variables included, file types data stored , files structured). helps prepare future data wrangling needs.Find associated documentation read thoroughly. Types documentation look :\nData dictionaries codebooks\ndocuments help interpret use variables correctly.\n\nChangelogs\nPublic data sources constantly updating (e.g., new data acquired, errors found). ’s important understand version data working .\n\nData quality documentation\ndocumentation helps make aware known issues data.\n\nData dictionaries codebooks\ndocuments help interpret use variables correctly.\ndocuments help interpret use variables correctly.Changelogs\nPublic data sources constantly updating (e.g., new data acquired, errors found). ’s important understand version data working .\nPublic data sources constantly updating (e.g., new data acquired, errors found). ’s important understand version data working .Data quality documentation\ndocumentation helps make aware known issues data.\ndocumentation helps make aware known issues data.hesitate reach help.\nTypically, site include contact information questions. Never hesitate reach contact something understand data.\nTypically, site include contact information questions. Never hesitate reach contact something understand data.extracting data across states (e.g., Missouri Department Elementary Secondary Education Oklahoma State Department Education), aware information may easily comparable. may find states use similar standards, common states collect store data different ways (e.g., different state assessments, different ways reporting enrollment). Depending data needs, may better use data source aggregates information across states. Examples data sources include Department Education’s Common Core Data (https://nces.ed.gov/ccd/) EDFacts (https://www2.ed.gov//inits/ed/edfacts/index.html. needing use multiple data sources, tools, Urban Institute Education Data Explorer https://educationdata.urban.org/data-explorer, even harmonized variables documentation across several federal government datasets, allowing researchers access multiple data sources single site.files extracted, store according data storage plans (see Chapter 13) name according style guide rules.","code":""},{"path":"capture.html","id":"documenting-external-data-capture","chapter":"12 Data Capture","heading":"12.3.3 Documenting external data capture","text":"Make sure every step external data capture process documented appropriate locations (e.g., SOP, research protocol). Responsibilities need assigned throughout process, investigating data request procedures, communicating providers, acquiring data files. mentioned Section 8.4.1.2, also want make sure data sources documented data dictionary. possible data source come data dictionary, continuity, may need reformat document match project data dictionaries formatted. data source come data dictionary, want create one source. useful data cleaning validation purposes, also data sharing purposes later .","code":""},{"path":"store.html","id":"store","chapter":"13 Data Storage and Security","heading":"13 Data Storage and Security","text":"\nFigure 13.1: Data storage research project life cycle\nbegin capture data, important well-planned structure securely storing working data active study. need plan storing data files, also need plan storing project files (e.g., meeting notes, documentation, participant tracking databases). team implement structure early files stored consistently securely entire project, just data collection life cycle begins. several goals keep mind setting file storage security system active project.File security: Ensuring files lost, corrupted, edited unexpectedly.Protecting confidentiality: Making sure sensitive information seen accessed unauthorized individuals.Accessibility usability files: Making sure team can easily find files able understand files contain.","code":""},{"path":"store.html","id":"store-plan","chapter":"13 Data Storage and Security","heading":"13.1 Planning short-term data storage","text":"planning storage security process, data files particular, important gather relevant information making plan. typical process developing plan may begin like :Review data needs stored often.\nUse documents data sources catalog (see Section 5.3) data collection timeline (see Section 8.2.6) better understand data storage needs.\nUse documents data sources catalog (see Section 5.3) data collection timeline (see Section 8.2.6) better understand data storage needs.Take inventory data storage solutions available .\nterms electronic data, institutions different licenses partnerships varying software companies may approve approve different tools (e.g., Dropbox, SharePoint, Box, Google Drive).\nterms electronic data, institutions different licenses partnerships varying software companies may approve approve different tools (e.g., Dropbox, SharePoint, Box, Google Drive).Consider compliance.\nMake note data storage laws, policies, agreements data subject (e.g., IRB policies, data sharing agreements, funder policies).\nMake note data storage laws, policies, agreements data subject (e.g., IRB policies, data sharing agreements, funder policies).Review classification levels.\nReview data source’s classification level (see 4.2) ensure choosing storage solutions appropriate sensitivity level data.\nReview data source’s classification level (see 4.2) ensure choosing storage solutions appropriate sensitivity level data.process help narrow data storage solutions data source. However, series decisions need made depending type data working , paper (e.g., paper consent form) electronic (e.g., CSV file questionnaire data, Microsoft Access participant tracking database). remainder section review series decisions make type data, well provide best practices along way.","code":""},{"path":"store.html","id":"store-electronic","chapter":"13 Data Storage and Security","heading":"13.1.1 Electronic data","text":"reviewed relevant information Section 13.1, several decisions need made deciding setting structures storing securely working electronic data.Review additional criteria.\nnarrowing storage solutions based available tools (e.g., cloud storage, institution network drive, personal device) meet compliance needs, electronic data storage locations can narrowed based criteria.\nVersioning availability: manual version control beneficial major changes, helpful store files location automated file versioning fail-safe case accidents unintended overwriting files.\nSize storage space: need make sure storage contains enough space files.\nConsider many files storing, well amount information stored file (e.g., number rows columns dataset). file types use (e.g., CSV, XLSX, SPSS) also impact size file.\n\nComfort level team: helpful choose storage space team comfortable working ability train use .\nAccessibility: Consider accessibility storage location users (e.g., staff access location -site), well compatibility different operating system.\nCollaboration: Consider storage method handles multi-user editing files.\nFile sharing: can beneficial use storage platform allows file sharing links, rather sharing actual file. way updates made file, changes shown link, rather send updated version file.\nCosts: Consider costs associated potential storage solutions.\n\nnarrowing storage solutions based available tools (e.g., cloud storage, institution network drive, personal device) meet compliance needs, electronic data storage locations can narrowed based criteria.\nVersioning availability: manual version control beneficial major changes, helpful store files location automated file versioning fail-safe case accidents unintended overwriting files.\nSize storage space: need make sure storage contains enough space files.\nConsider many files storing, well amount information stored file (e.g., number rows columns dataset). file types use (e.g., CSV, XLSX, SPSS) also impact size file.\n\nComfort level team: helpful choose storage space team comfortable working ability train use .\nAccessibility: Consider accessibility storage location users (e.g., staff access location -site), well compatibility different operating system.\nCollaboration: Consider storage method handles multi-user editing files.\nFile sharing: can beneficial use storage platform allows file sharing links, rather sharing actual file. way updates made file, changes shown link, rather send updated version file.\nCosts: Consider costs associated potential storage solutions.\nVersioning availability: manual version control beneficial major changes, helpful store files location automated file versioning fail-safe case accidents unintended overwriting files.Size storage space: need make sure storage contains enough space files.\nConsider many files storing, well amount information stored file (e.g., number rows columns dataset). file types use (e.g., CSV, XLSX, SPSS) also impact size file.\nConsider many files storing, well amount information stored file (e.g., number rows columns dataset). file types use (e.g., CSV, XLSX, SPSS) also impact size file.Comfort level team: helpful choose storage space team comfortable working ability train use .Accessibility: Consider accessibility storage location users (e.g., staff access location -site), well compatibility different operating system.Collaboration: Consider storage method handles multi-user editing files.File sharing: can beneficial use storage platform allows file sharing links, rather sharing actual file. way updates made file, changes shown link, rather send updated version file.Costs: Consider costs associated potential storage solutions.Choose final storage location.\nmay allowed store files different locations depending sensitivity level, effective solution create collaborative research environment (UK Data Service 2023). , designate highest level security needed (e.g., institution network drive), keep , many possible, project-related files stored location, assigning access files folders needed. Keeping files located central, consistent location often provides benefit data security (e.g., user access controls, different versions documents different computers) well accessibility (e.g., team members can find documents).\nmay allowed store files different locations depending sensitivity level, effective solution create collaborative research environment (UK Data Service 2023). , designate highest level security needed (e.g., institution network drive), keep , many possible, project-related files stored location, assigning access files folders needed. Keeping files located central, consistent location often provides benefit data security (e.g., user access controls, different versions documents different computers) well accessibility (e.g., team members can find documents).Design folder structure according style guide.\nFollowing style guide, create folder structure team members begin storing files stored consistently.\nalready designated style guide, note best practice, possibly mandate institution, store participant tracking database separately research study data (.e., separate folder restricted access). participant tracking database contain personally identifiable information (PII), also one linking key study codes participant names stored alongside datasets.\nSimilarly, informed consent forms collected electronically also stored alongside research study data. stored separate, secure location.\n\nFollowing style guide, create folder structure team members begin storing files stored consistently.\nalready designated style guide, note best practice, possibly mandate institution, store participant tracking database separately research study data (.e., separate folder restricted access). participant tracking database contain personally identifiable information (PII), also one linking key study codes participant names stored alongside datasets.\nSimilarly, informed consent forms collected electronically also stored alongside research study data. stored separate, secure location.\nalready designated style guide, note best practice, possibly mandate institution, store participant tracking database separately research study data (.e., separate folder restricted access). participant tracking database contain personally identifiable information (PII), also one linking key study codes participant names stored alongside datasets.Similarly, informed consent forms collected electronically also stored alongside research study data. stored separate, secure location.Set additional security systems.\nData backups\nimportant regularly backup data. Consider using something similar 3-2-1 rule, keeping three copies data, two different types storage media, one location guard data loss (Briney 2015; UK Data Service 2023). Talk institution department help setting system.\n\nUser access\nAssign user access folders files based sensitivity levels, quality control needs, applicable policies, agreements, plans.\n\nData backups\nimportant regularly backup data. Consider using something similar 3-2-1 rule, keeping three copies data, two different types storage media, one location guard data loss (Briney 2015; UK Data Service 2023). Talk institution department help setting system.\nimportant regularly backup data. Consider using something similar 3-2-1 rule, keeping three copies data, two different types storage media, one location guard data loss (Briney 2015; UK Data Service 2023). Talk institution department help setting system.User access\nAssign user access folders files based sensitivity levels, quality control needs, applicable policies, agreements, plans.\nAssign user access folders files based sensitivity levels, quality control needs, applicable policies, agreements, plans.Designate rules working securely data.\nComplete required trainings (e.g., CITI trainings, training, internal training).\nConsistently name folders files according style guide.\nkeep copies files.\nOutside making data backups, keep copies files different folders. opens door edits made one copy . happens, team members may working different versions files. want copy file one location (e.g., SOP “documentation” folder “project_coordination” folder), storage systems allow link documents location (.e., “project_coordination” folder contains link SOP “documentation” folder).\n\nSecure devices (O’Toole et al. 2018; Princeton University 2023a).\nChoose safe passwords protect devices.\nleave devices open unattended working field.\nprotection devices (e.g., date antivirus software, firewall, encryption).\nworking remotely, use password protected Wi-Fi use secure connections (e.g., VPN, 2FA) working data files.\nfiles stored detachable media (e.g., external hard drives, CDs, flash drives) typically stored behind two locks use (e.g., locked file cabinet locked storage room).\n\nSecurely transmit data files.\ntransmitting data, either internally externally, important use secure methods, especially data contain PII. general rule, moderate highly sensitive data transmitted via email. Use secure, institution approved, file transfer method includes encryption.\n\nComplete required trainings (e.g., CITI trainings, training, internal training).Consistently name folders files according style guide.keep copies files.\nOutside making data backups, keep copies files different folders. opens door edits made one copy . happens, team members may working different versions files. want copy file one location (e.g., SOP “documentation” folder “project_coordination” folder), storage systems allow link documents location (.e., “project_coordination” folder contains link SOP “documentation” folder).\nOutside making data backups, keep copies files different folders. opens door edits made one copy . happens, team members may working different versions files. want copy file one location (e.g., SOP “documentation” folder “project_coordination” folder), storage systems allow link documents location (.e., “project_coordination” folder contains link SOP “documentation” folder).Secure devices (O’Toole et al. 2018; Princeton University 2023a).\nChoose safe passwords protect devices.\nleave devices open unattended working field.\nprotection devices (e.g., date antivirus software, firewall, encryption).\nworking remotely, use password protected Wi-Fi use secure connections (e.g., VPN, 2FA) working data files.\nfiles stored detachable media (e.g., external hard drives, CDs, flash drives) typically stored behind two locks use (e.g., locked file cabinet locked storage room).\nChoose safe passwords protect devices.leave devices open unattended working field.protection devices (e.g., date antivirus software, firewall, encryption).working remotely, use password protected Wi-Fi use secure connections (e.g., VPN, 2FA) working data files.files stored detachable media (e.g., external hard drives, CDs, flash drives) typically stored behind two locks use (e.g., locked file cabinet locked storage room).Securely transmit data files.\ntransmitting data, either internally externally, important use secure methods, especially data contain PII. general rule, moderate highly sensitive data transmitted via email. Use secure, institution approved, file transfer method includes encryption.\ntransmitting data, either internally externally, important use secure methods, especially data contain PII. general rule, moderate highly sensitive data transmitted via email. Use secure, institution approved, file transfer method includes encryption.","code":""},{"path":"store.html","id":"store-paper","chapter":"13 Data Storage and Security","heading":"13.1.2 Paper data","text":"Working paper data involves reviewing another set decisions planning data storage security.Choose final storage location.\nreviewing available locations well applicable laws, policies, agreements, want consider additional criteria accessibility storage site, physical storage size needs, storage costs, security location. commonly required files containing PII, store behind two locks.\nreviewing available locations well applicable laws, policies, agreements, want consider additional criteria accessibility storage site, physical storage size needs, storage costs, security location. commonly required files containing PII, store behind two locks.Consistently structure file cabinets folders.\nmay style guide created organizing physical folders files, still important consistently structure name clarity. example, organize drawers time period (e.g., wave 1), organize folders data source (e.g., student survey).\nmay style guide created organizing physical folders files, still important consistently structure name clarity. example, organize drawers time period (e.g., wave 1), organize folders data source (e.g., student survey).Securely work files.\ndiscussed Sections 11.3.1 12.2.3, team members work files, important staff understand rules process returning files back designated storage location use (.e., files left desks).\ndiscussed Sections 11.3.1 12.2.3, team members work files, important staff understand rules process returning files back designated storage location use (.e., files left desks).","code":""},{"path":"store.html","id":"oversight","chapter":"13 Data Storage and Security","heading":"13.1.3 Oversight","text":"Whether working electronic paper data, make sure assign responsibilities team members tasks creating electronic directory structures physical folder structures, adding removing storage access, overseeing data backups, monitoring training compliance. Without oversight processes, easy errors occur.","code":""},{"path":"store.html","id":"documentation-and-dissemination","chapter":"13 Data Storage and Security","heading":"13.2 Documentation and dissemination","text":"make plan short-term data storage, plan added necessary documentation (e.g., DMP, research protocol, informed consent forms, SOPs). plan approved, important deviate plan unless revisions also approved. especially important case informed consents. participants agreed data storage terms consent (e.g., identifying information stored separate study data), terms honored.Last, information needs disseminated team members ensure fidelity data storage security plan. Add pertinent information documents staff required review (.e., team data security policy onboarding/offboarding checklists) ensure information reviewed. addition, make sure embed information team project related staff training.","code":""},{"path":"clean.html","id":"clean","chapter":"14 Data Cleaning","heading":"14 Data Cleaning","text":"\nFigure 14.1: Data cleaning research project life cycle\nEven well-designed data collection capture efforts, data still require least additional processing format feel confident sharing. done data processing, data cleaning phase, largely depend planned transformations data, well level quality assurance control processes implemented collection capture. chapter review standard data cleaning steps considered every education research project.\nimportant emphasize , collecting longitudinal data, data cleaning needs happen every wave data collection. wave data collected captured raw data stored, data cleaning process begin. best case scenario, data cleaning wrapped next wave data collection. Cleaning data wave, opposed waiting end project, two large benefits.Allows catch errors early fix .\ncleaning data may find data missing unexpectedly one variables, values incorrectly coded, forgot restrict input type. cleaning data wave, able correct errors instrument order collect better data next round.\ncleaning data may find data missing unexpectedly one variables, values incorrectly coded, forgot restrict input type. cleaning data wave, able correct errors instrument order collect better data next round.Data ready need .\nProposal, report, publication deadlines come fast. various needs arise, rather first take time clean data, waiting someone team clean , data always available use cleaned regularly occurring schedule.\nProposal, report, publication deadlines come fast. various needs arise, rather first take time clean data, waiting someone team clean , data always available use cleaned regularly occurring schedule.","code":""},{"path":"clean.html","id":"clean-type","chapter":"14 Data Cleaning","heading":"14.1 Data cleaning for data sharing","text":"Data cleaning process organizing transforming raw data dataset can easily accessed analyzed. Data cleaning can essentially result two different types datasets; dataset curated general data sharing purposes, dataset cleaned specific analysis. former means dataset still true, raw form, de-identified minimally altered allow data correctly interpreted (Cook et al. 2021; Neild, Robinson, Agufa 2022; Van Dijk, Schatschneider, Hart 2021). dataset cleaned general data sharing means includes entire study sample (one removed), missing data still labelled missing (imputation done), analysis-specific variables calculated. cleaning taken care another phase cleaning analyses.Ultimately, can think data three distinct phases (see Figure 14.2).Raw data\nuntouched raw file comes directly data collection capture source. data collected electronically, file extract tool. data collected paper, data entered machine-readable format. external data source, file download receive external provider.\neducation research data typically shared outside research team usually contains identifiable information often needs wrangling decipherable end user.\nuntouched raw file comes directly data collection capture source. data collected electronically, file extract tool. data collected paper, data entered machine-readable format. external data source, file download receive external provider.education research data typically shared outside research team usually contains identifiable information often needs wrangling decipherable end user.general clean study data\ndataset publicly share one discussing chapter.\ndataset publicly share one discussing chapter.analytic data\ndataset created general clean dataset (either team researchers), altered specific analysis (T. Reynolds, Schatschneider, Logan 2022). dataset typically also publicly shared repository time publication allow replication associated analysis. Since dataset analysis specific, discuss type data cleaning book.\ndataset created general clean dataset (either team researchers), altered specific analysis (T. Reynolds, Schatschneider, Logan 2022). dataset typically also publicly shared repository time publication allow replication associated analysis. Since dataset analysis specific, discuss type data cleaning book.\nFigure 14.2: three phases data\n","code":""},{"path":"clean.html","id":"clean-criteria","chapter":"14 Data Cleaning","heading":"14.2 Data quality criteria","text":"cleaning data, need shared understanding expect data look like cleaned. Adhering common standards data quality allows data consistently cleaned organized within across projects. several data quality criteria commonly agreed upon (DeCoster 2023; Elgabry 2019; Schmidt et al. 2021; Van Bochove, Alper, Gu 2023). Upon cleaning data general data sharing, data meet following criteria.Complete\nnumber rows dataset match number completed forms tracked participant tracking database. means forms collected captured (either entered retrieved). also means removed extraneous data doesn’t belong (e.g., duplicates, participants aren’t final sample).\nnumber columns data match number variables data dictionary (.e., variables accidentally dropped). Similarly, unexpected missing data variables (.e., data collected, exist dataset).\nnumber rows dataset match number completed forms tracked participant tracking database. means forms collected captured (either entered retrieved). also means removed extraneous data doesn’t belong (e.g., duplicates, participants aren’t final sample).number columns data match number variables data dictionary (.e., variables accidentally dropped). Similarly, unexpected missing data variables (.e., data collected, exist dataset).Valid\nVariables conform constraints laid data dictionary (e.g., variable types, allowable variable values ranges, item-level missingness aligns variable universe rules defined skip patterns)\nVariables conform constraints laid data dictionary (e.g., variable types, allowable variable values ranges, item-level missingness aligns variable universe rules defined skip patterns)Accurate\nOftentimes way know whether value true .\nHowever, possible use implicit knowledge participant data source (.e., ghost knowledge) (Boykis 2021) determine values inaccurate (e.g., value exists school know data collected wave).\nalso possible check alignment variable values within across sources determine accuracy.\nexample, student 2nd grade, teacher ID associated 2nd grade teacher. , date birth collected student survey match date birth collected school district.\n\n\nOftentimes way know whether value true .\nHowever, possible use implicit knowledge participant data source (.e., ghost knowledge) (Boykis 2021) determine values inaccurate (e.g., value exists school know data collected wave).\nalso possible check alignment variable values within across sources determine accuracy.\nexample, student 2nd grade, teacher ID associated 2nd grade teacher. , date birth collected student survey match date birth collected school district.\n\nHowever, possible use implicit knowledge participant data source (.e., ghost knowledge) (Boykis 2021) determine values inaccurate (e.g., value exists school know data collected wave).also possible check alignment variable values within across sources determine accuracy.\nexample, student 2nd grade, teacher ID associated 2nd grade teacher. , date birth collected student survey match date birth collected school district.\nexample, student 2nd grade, teacher ID associated 2nd grade teacher. , date birth collected student survey match date birth collected school district.Consistent\nVariable values consistently measured, formatted, coded within column (e.g., values survey date formatted YYYY-MM-DD).\nAcross repeated collections form, variables consistently named, measured, formatted, coded well (e.g., free/reduced priced lunch consistently named coded using code/label pair across cohorts).\nVariable values consistently measured, formatted, coded within column (e.g., values survey date formatted YYYY-MM-DD).Across repeated collections form, variables consistently named, measured, formatted, coded well (e.g., free/reduced priced lunch consistently named coded using code/label pair across cohorts).De-identified\nconfidentiality promised participants, data needs de-identified. early phases data cleaning, simply means direct identifiers (see Chapter 4) removed data replaced study codes (.e., participant unique identifier). publicly sharing data, additional work may required remove indirect identifiers well discuss Chapter 16.\nconfidentiality promised participants, data needs de-identified. early phases data cleaning, simply means direct identifiers (see Chapter 4) removed data replaced study codes (.e., participant unique identifier). publicly sharing data, additional work may required remove indirect identifiers well discuss Chapter 16.Interpretable\nVariables named match data dictionary names human machine-readable (see Section 9.4). needed, variable value labels added embedded metadata aid interpretation.\nVariables named match data dictionary names human machine-readable (see Section 9.4). needed, variable value labels added embedded metadata aid interpretation.Analyzable\ndataset rectangular (rows columns), machine-readable format adheres basic data organization rules (see Section 3.2).\ndataset rectangular (rows columns), machine-readable format adheres basic data organization rules (see Section 3.2).","code":""},{"path":"clean.html","id":"clean-check","chapter":"14 Data Cleaning","heading":"14.3 Data cleaning checklist","text":"Recall Section 8.3.3, helpful write data cleaning plan, dataset data sources catalog (see Section 8.2.2), begin cleaning raw data. Writing plan early allows get feedback planned alterations, also provides structure cleaning process, preventing meandering potentially forgetting important steps. plan need overly detailed, include actionable steps walk cleaning data.many ways, writing data cleaning plan personalized process. steps needed wrangle raw data quality dataset vary greatly depending happening specific raw data file. However, produce datasets consistently meet data quality standards discussed Section 14.2, can helpful follow standardized checklist data cleaning steps (see Figure 14.3). steps, although general , elaborated data cleaning plan, specific data source, can help produce dataset meets data quality standards. Following checklist helps ensure data cleaned consistent standardized manner within across projects.\nFigure 14.3: Data cleaning checklist\nwrite data cleaning plan, can add checklist steps relevant data remove steps relevant. order steps fluid can moved around needed. two exceptions . First, accessing raw data always number one course, important rule never work directly raw data file (Borer et al. 2009; Broman Woo 2018). Either make copy file connect raw file ways directly editing file. raw data file single source truth data source. make errors data cleaning process, always able go back raw data start need . Second, reviewing data always step number two. Waiting review data ’ve started cleaning means may waste hours time cleaning data learn later participants missing, data organized expected, even working wrong file.","code":""},{"path":"clean.html","id":"clean-steps","chapter":"14 Data Cleaning","heading":"14.3.1 Checklist steps","text":"Let’s review step specifically involves write data cleaning plan, able determine steps relevant cleaning specific data source.Access raw data.\nDepending plan clean data (e.g., using code manual cleaning), well programs plan use data cleaning (e.g., Excel, SPSS, R, Stata), may look like reading file statistical program, may look like making copy raw data file renaming “clean”. Either way, just ensure making edits raw data file.\nDepending plan clean data (e.g., using code manual cleaning), well programs plan use data cleaning (e.g., Excel, SPSS, R, Stata), may look like reading file statistical program, may look like making copy raw data file renaming “clean”. Either way, just ensure making edits raw data file.basic review raw data (see Figure 14.4).\nCheck rows data\nnumber cases data match number tracked forms participant tracking database? duplicates? anyone missing?\n\nCheck columns data\nnumber variables data dictionary match number variables dataset? Remember looking variables captured directly source (.e., variables derived cleaning process).\nvariable types values expected?\n\nCheck rows data\nnumber cases data match number tracked forms participant tracking database? duplicates? anyone missing?\nnumber cases data match number tracked forms participant tracking database? duplicates? anyone missing?Check columns data\nnumber variables data dictionary match number variables dataset? Remember looking variables captured directly source (.e., variables derived cleaning process).\nvariable types values expected?\nnumber variables data dictionary match number variables dataset? Remember looking variables captured directly source (.e., variables derived cleaning process).variable types values expected?\nFigure 14.4: Reviewing rows columns raw data file\nNoteBefore starting review process, may need pre-work put data analyzable format (e.g., second row data variable labels, want drop second row left variable names first row values associated variable remaining cells). Without work first, difficult accurately review data.Find missing data.\nFind missing cases.\ncases marked complete tracking database data missing, investigate error. form incorrectly tracked tracking database? form entered data capture phase?\nerror tracking database, fix error time.\nOtherwise, search missing forms, add raw data, start step number 1 data cleaning process.\n\n\nFind missing variables.\nmissing variables, investigate error. variable incorrectly added data dictionary? , variable somehow dropped data capture process data import file copying process?\nFix error appropriate location start step number 1.\n\n\nFind missing cases.\ncases marked complete tracking database data missing, investigate error. form incorrectly tracked tracking database? form entered data capture phase?\nerror tracking database, fix error time.\nOtherwise, search missing forms, add raw data, start step number 1 data cleaning process.\n\ncases marked complete tracking database data missing, investigate error. form incorrectly tracked tracking database? form entered data capture phase?\nerror tracking database, fix error time.\nOtherwise, search missing forms, add raw data, start step number 1 data cleaning process.\nerror tracking database, fix error time.Otherwise, search missing forms, add raw data, start step number 1 data cleaning process.Find missing variables.\nmissing variables, investigate error. variable incorrectly added data dictionary? , variable somehow dropped data capture process data import file copying process?\nFix error appropriate location start step number 1.\n\nmissing variables, investigate error. variable incorrectly added data dictionary? , variable somehow dropped data capture process data import file copying process?\nFix error appropriate location start step number 1.\nFix error appropriate location start step number 1.Adjust sample.\nRemove duplicate cases.\nFirst, make sure duplicates true duplicates (.e., incorrectly entered identifiers data entry errors). incorrect identifiers, forms accidentally entered data entry team, corrected time.\nerror comes data entry process (e.g., team member entered ID incorrectly, team member entered form twice), can helpful go back data entry files fix errors source. export new files start data cleaning process step 1.\nerror comes directly data collection instrument (e.g., participant entered incorrect ID web-based form), errors can corrected data cleaning process.\n\ntrue duplicates (.e., participant completed form ), duplicates need removed. Follow decisions written documentation (e.g., research protocol, SOP) ensure removing duplicates consistently (e.g., always keep first complete record form).\n\nRemove participants part final sample (.e., meet inclusion criteria).\nRemove duplicate cases.\nFirst, make sure duplicates true duplicates (.e., incorrectly entered identifiers data entry errors). incorrect identifiers, forms accidentally entered data entry team, corrected time.\nerror comes data entry process (e.g., team member entered ID incorrectly, team member entered form twice), can helpful go back data entry files fix errors source. export new files start data cleaning process step 1.\nerror comes directly data collection instrument (e.g., participant entered incorrect ID web-based form), errors can corrected data cleaning process.\n\ntrue duplicates (.e., participant completed form ), duplicates need removed. Follow decisions written documentation (e.g., research protocol, SOP) ensure removing duplicates consistently (e.g., always keep first complete record form).\nFirst, make sure duplicates true duplicates (.e., incorrectly entered identifiers data entry errors). incorrect identifiers, forms accidentally entered data entry team, corrected time.\nerror comes data entry process (e.g., team member entered ID incorrectly, team member entered form twice), can helpful go back data entry files fix errors source. export new files start data cleaning process step 1.\nerror comes directly data collection instrument (e.g., participant entered incorrect ID web-based form), errors can corrected data cleaning process.\nerror comes data entry process (e.g., team member entered ID incorrectly, team member entered form twice), can helpful go back data entry files fix errors source. export new files start data cleaning process step 1.error comes directly data collection instrument (e.g., participant entered incorrect ID web-based form), errors can corrected data cleaning process.true duplicates (.e., participant completed form ), duplicates need removed. Follow decisions written documentation (e.g., research protocol, SOP) ensure removing duplicates consistently (e.g., always keep first complete record form).Remove participants part final sample (.e., meet inclusion criteria).NoteIn special case purposefully collect duplicate observations participant (.e., reliability purposes), want keep one row per participant final study dataset. , decision rule need added documentation duplicates dealt consistently (e.g., always keep primary observer’s record).De-identify data.\nconfidentiality promised participants, need de-identify data. data already contain assigned study IDs, replace direct identifiers (e.g., names, emails) data study IDs using roster participant tracking database. process creates coded data (see Chapter 4 refesher).\npoint focusing removing direct identifiers , Chapter 16, also discuss dealing indirect identifiers publicly sharing data.\nFigure 14.5 shows data de-identification process might look like (O’Toole et al. 2018). order create “coded data” file, horizontally join “raw data” file “roster file” using unique identifiers (case first_name last_name), drop identifying variables.\nwant emphasize importance using join program choice, opposed replacing names IDs hand entering identifiers. possible, want completely avoid hand entry study IDs error-prone can lead many mistakes.\n\nconfidentiality promised participants, need de-identify data. data already contain assigned study IDs, replace direct identifiers (e.g., names, emails) data study IDs using roster participant tracking database. process creates coded data (see Chapter 4 refesher).point focusing removing direct identifiers , Chapter 16, also discuss dealing indirect identifiers publicly sharing data.Figure 14.5 shows data de-identification process might look like (O’Toole et al. 2018). order create “coded data” file, horizontally join “raw data” file “roster file” using unique identifiers (case first_name last_name), drop identifying variables.\nwant emphasize importance using join program choice, opposed replacing names IDs hand entering identifiers. possible, want completely avoid hand entry study IDs error-prone can lead many mistakes.\nwant emphasize importance using join program choice, opposed replacing names IDs hand entering identifiers. possible, want completely avoid hand entry study IDs error-prone can lead many mistakes.\nFigure 14.5: Process creating de-identified dataset\nNoteAt point data cleaning, data contain open-text responses, reviewing free text identifiable information well. Remove instance names replace placeholder “<name>” indicate information redacted.Drop irrelevant columns.\ncan think examples metadata collected survey platform. columns may completely irrelevant study cause clutter final dataset.\ncan think examples metadata collected survey platform. columns may completely irrelevant study cause clutter final dataset.Split columns needed (see Figure 14.6).\ndiscussed Section 3.2, variable collect one piece information. split one variable multiple variables one thing measured per variable.\ndiscussed Section 3.2, variable collect one piece information. split one variable multiple variables one thing measured per variable.\nFigure 14.6: Splitting one column multiple columns\nRename variables.\nRename variables correspond names provided data dictionary.\nRename variables correspond names provided data dictionary.Normalize variables (see Figure 14.7).\n, term normalize used summarize process returning variable normal, expected, state.\nCompare variable types raw data variable types expected data dictionary. align? , ?\nexample, may need remove unexpected characters $ % preventing variable numeric type. accidentally inserted white space letters variable.\n\n, term normalize used summarize process returning variable normal, expected, state.Compare variable types raw data variable types expected data dictionary. align? , ?\nexample, may need remove unexpected characters $ % preventing variable numeric type. accidentally inserted white space letters variable.\nexample, may need remove unexpected characters $ % preventing variable numeric type. accidentally inserted white space letters variable.\nFigure 14.7: Normalizing variable\nStandardize variables.\n, using term standardize convey process checking consistency.\ncolumns consistently measured, coded, formatted according data dictionary? , need standardized.\nmay involve rescaling variables (e.g., age measured months wave 1 age measured years wave 2 need rescaled).\nmay mean updating variable format (e.g., converting consistent date format).\nmay mean collapsing categories free text categorical variables (e.g., m | M | male = “male”).\n\n, using term standardize convey process checking consistency.columns consistently measured, coded, formatted according data dictionary? , need standardized.\nmay involve rescaling variables (e.g., age measured months wave 1 age measured years wave 2 need rescaled).\nmay mean updating variable format (e.g., converting consistent date format).\nmay mean collapsing categories free text categorical variables (e.g., m | M | male = “male”).\nmay involve rescaling variables (e.g., age measured months wave 1 age measured years wave 2 need rescaled).may mean updating variable format (e.g., converting consistent date format).may mean collapsing categories free text categorical variables (e.g., m | M | male = “male”).NoteIn case Figure 14.8, kind standardization needs happen can perform steps joining names de-identification purposes. Keys need standardized across files linking can occur.\nFigure 14.8: Standardizing variable\nUpdate variable types\nnormalizing standardizing variables, can now convert variable types match types ’ve listed data dictionary (e.g., convert string numeric)\nnormalizing standardizing variables, can now convert variable types match types ’ve listed data dictionary (e.g., convert string numeric)NoteIt’s important normalize updating variable types. Updating variable types normalizing result lost data (.e., converting character column numeric, column still contains cells character values, often recode cells missing).Recode variables\ncategorical value codes (see Chapter 9.5) match data dictionary, now time recode (e.g., expected “” = 1, data exported “” = 14)\ndiscussed Chapter 3.2, also includes recoding implicit values, explicitly (e.g., missing values implied 0, recode 0)\ncan also recode variables planned data dictionary (e.g., reverse coded item) (see Figure 14.9)\ncategorical value codes (see Chapter 9.5) match data dictionary, now time recode (e.g., expected “” = 1, data exported “” = 14)discussed Chapter 3.2, also includes recoding implicit values, explicitly (e.g., missing values implied 0, recode 0)can also recode variables planned data dictionary (e.g., reverse coded item) (see Figure 14.9)\nFigure 14.9: Reverse coding variable\nConstruct additional variables\ntime construct analysis-specific variables. time create calculate variables always part core study dataset. variables chosen data management working group early added data dictionary. Examples variables might add:\ntime components (e.g., wave)\ngrouping variables (e.g., treatment)\nforeign keys (e.g., sch_id teacher file)\nmeasure composite summary scores\ncompletion variables data quality flags\nvariables created scoring purposes (e.g., age)\nvariables want added core sharing dataset (e.g., categorizing open-ended text response variable)\ntime construct analysis-specific variables. time create calculate variables always part core study dataset. variables chosen data management working group early added data dictionary. Examples variables might add:time components (e.g., wave)grouping variables (e.g., treatment)foreign keys (e.g., sch_id teacher file)measure composite summary scorescompletion variables data quality flagsvariables created scoring purposes (e.g., age)variables want added core sharing dataset (e.g., categorizing open-ended text response variable)NoteSome variables may exist sources (e.g., treatment may exist participant tracking database). , variables won’t need created calculated, can simply merged clean dataset using technique similar one described data de-identification step. can export file participant tracking database contains unique identifier (e.g., tch_id) well variables need (e.g., treatment), join file clean data file using unique identifier.Add missing values\nAssign missing value codes based designated schema (documented data dictionary style guide).\nAssign missing value codes based designated schema (documented data dictionary style guide).Add metadata (UK Data Service 2023)\ninteroperable file types (e.g., CSV) highly recommended storing data, can extremely helpful create another copy clean data format, SPSS, allows embedded metadata. file types allow embed variable value code labels can handy data user.\ncan especially helpful plan export variables numeric values (1 | 0), rather text values (“yes” | “”). case, rather flip back forth file data dictionary interpret codes, users can review information variables within file .\nfuture data users may license proprietary file type, file formats can often opened free/open source software (e.g., GNU PSPP) can easily imported variety statistical programs can interpret metadata (e.g., importing SPSS files R Stata).\ninteroperable file types (e.g., CSV) highly recommended storing data, can extremely helpful create another copy clean data format, SPSS, allows embedded metadata. file types allow embed variable value code labels can handy data user.can especially helpful plan export variables numeric values (1 | 0), rather text values (“yes” | “”). case, rather flip back forth file data dictionary interpret codes, users can review information variables within file .future data users may license proprietary file type, file formats can often opened free/open source software (e.g., GNU PSPP) can easily imported variety statistical programs can interpret metadata (e.g., importing SPSS files R Stata).Data validation\ngood practice assume amount error inevitable, even best data management practices place. Errors data can happen many reasons, come mistakes data collection capture process, others come data cleaning process (e.g., coding errors, calculation errors, joining errors). Yet, errors won’t found don’t actively look (Palmer 2023). minimum always validate, check, data errors end data cleaning process. Ideally though, checking every one transformations along way well. can something simple checking category counts categorical variables, means numeric variables, transformations.\ndata cleaned, begin manual method opening data eyeballing . Believe , can actually useful error-catching technique. However, technique. also create tables, calculate summary reliability statistics, create univariate bivariate plots search errors. Codebooks great documents summarizing reviewing lot information (Arslan 2019).\ncan organize data validation process data quality criteria. following sampling checks complete validation process, organized criteria (CESSDA Training Team 2017; ICPSR 2020; Strand 2021; T. Reynolds, Schatschneider, Logan 2022; UK Data Service 2023).\nComplete\nCheck missing cases/duplicate cases.\ncan also helpful check Ns cluster variables completeness (e.g., number students per teacher, number teachers per school) (DeCoster 2023).\n\nCheck missing columns/many columns.\n\nValid Consistent\nCheck variables unallowed categories values range.\nChecking groups can also help illuminate issues (e.g., compare age grade level) (Riederer 2021).\n\nCheck invalid, non-unique, missing study IDs.\nCheck incorrect variable types.\nCheck incorrect formatting.\nCheck missing values (.e., align variable universe rules skip patterns).\n\nAccurate\nCross check agreement across variables (e.g., student 2nd grade associated 2nd grade teacher).\nChecks project-specific unique situations.\n\nDe-identified\ndirect identifiers removed?\n\nInterpretable\nvariables correctly named?\nmetadata applied variables? metadata accurate (e.g., value labels correct, variable labels correct)?\n\n\nvalidation process find errors, first want determine errors originated (.e., data entry, data export, data cleaning), correct appropriate location. errors occurred data entry data export/saving process, may involve creating new raw data file starting cleaning process step 1.\n, however, find true values inaccurate, uninterpretable, outside valid range (.e., represent participant actually reported), need make personal decision deal . examples might deal true errors include:\nLeave data , make note errors documentation, allow future researchers deal values analysis process.\nAssign value code (e.g., “inaccurate value” = -90) recode values .\nCreate data quality indicator variables denote cells untrustworthy values (e.g., age contains true values age_q contains “concerns” = 0 | “quality concerns” = 1).\nfind inconsistencies across different sources, choose one form source truth recode values based form.\ntrue errors correct answer can easily inferred (e.g., 3-item rank order question completed 1, 2, 4), sometimes logical deductive editing can used cases value replaced logical correction (IPUMS USA 2023; Seastrom 2002).\n\nmatter decision , make sure documented appropriate places future users (e.g., data dictionary, data cleaning plan, research protocol).\n\ngood practice assume amount error inevitable, even best data management practices place. Errors data can happen many reasons, come mistakes data collection capture process, others come data cleaning process (e.g., coding errors, calculation errors, joining errors). Yet, errors won’t found don’t actively look (Palmer 2023). minimum always validate, check, data errors end data cleaning process. Ideally though, checking every one transformations along way well. can something simple checking category counts categorical variables, means numeric variables, transformations.data cleaned, begin manual method opening data eyeballing . Believe , can actually useful error-catching technique. However, technique. also create tables, calculate summary reliability statistics, create univariate bivariate plots search errors. Codebooks great documents summarizing reviewing lot information (Arslan 2019).can organize data validation process data quality criteria. following sampling checks complete validation process, organized criteria (CESSDA Training Team 2017; ICPSR 2020; Strand 2021; T. Reynolds, Schatschneider, Logan 2022; UK Data Service 2023).\nComplete\nCheck missing cases/duplicate cases.\ncan also helpful check Ns cluster variables completeness (e.g., number students per teacher, number teachers per school) (DeCoster 2023).\n\nCheck missing columns/many columns.\n\nValid Consistent\nCheck variables unallowed categories values range.\nChecking groups can also help illuminate issues (e.g., compare age grade level) (Riederer 2021).\n\nCheck invalid, non-unique, missing study IDs.\nCheck incorrect variable types.\nCheck incorrect formatting.\nCheck missing values (.e., align variable universe rules skip patterns).\n\nAccurate\nCross check agreement across variables (e.g., student 2nd grade associated 2nd grade teacher).\nChecks project-specific unique situations.\n\nDe-identified\ndirect identifiers removed?\n\nInterpretable\nvariables correctly named?\nmetadata applied variables? metadata accurate (e.g., value labels correct, variable labels correct)?\n\nComplete\nCheck missing cases/duplicate cases.\ncan also helpful check Ns cluster variables completeness (e.g., number students per teacher, number teachers per school) (DeCoster 2023).\n\nCheck missing columns/many columns.\nCheck missing cases/duplicate cases.\ncan also helpful check Ns cluster variables completeness (e.g., number students per teacher, number teachers per school) (DeCoster 2023).\ncan also helpful check Ns cluster variables completeness (e.g., number students per teacher, number teachers per school) (DeCoster 2023).Check missing columns/many columns.Valid Consistent\nCheck variables unallowed categories values range.\nChecking groups can also help illuminate issues (e.g., compare age grade level) (Riederer 2021).\n\nCheck invalid, non-unique, missing study IDs.\nCheck incorrect variable types.\nCheck incorrect formatting.\nCheck missing values (.e., align variable universe rules skip patterns).\nCheck variables unallowed categories values range.\nChecking groups can also help illuminate issues (e.g., compare age grade level) (Riederer 2021).\nChecking groups can also help illuminate issues (e.g., compare age grade level) (Riederer 2021).Check invalid, non-unique, missing study IDs.Check incorrect variable types.Check incorrect formatting.Check missing values (.e., align variable universe rules skip patterns).Accurate\nCross check agreement across variables (e.g., student 2nd grade associated 2nd grade teacher).\nChecks project-specific unique situations.\nCross check agreement across variables (e.g., student 2nd grade associated 2nd grade teacher).Checks project-specific unique situations.De-identified\ndirect identifiers removed?\ndirect identifiers removed?Interpretable\nvariables correctly named?\nmetadata applied variables? metadata accurate (e.g., value labels correct, variable labels correct)?\nvariables correctly named?metadata applied variables? metadata accurate (e.g., value labels correct, variable labels correct)?validation process find errors, first want determine errors originated (.e., data entry, data export, data cleaning), correct appropriate location. errors occurred data entry data export/saving process, may involve creating new raw data file starting cleaning process step 1.\n, however, find true values inaccurate, uninterpretable, outside valid range (.e., represent participant actually reported), need make personal decision deal . examples might deal true errors include:\nLeave data , make note errors documentation, allow future researchers deal values analysis process.\nAssign value code (e.g., “inaccurate value” = -90) recode values .\nCreate data quality indicator variables denote cells untrustworthy values (e.g., age contains true values age_q contains “concerns” = 0 | “quality concerns” = 1).\nfind inconsistencies across different sources, choose one form source truth recode values based form.\ntrue errors correct answer can easily inferred (e.g., 3-item rank order question completed 1, 2, 4), sometimes logical deductive editing can used cases value replaced logical correction (IPUMS USA 2023; Seastrom 2002).\n\nmatter decision , make sure documented appropriate places future users (e.g., data dictionary, data cleaning plan, research protocol).\n, however, find true values inaccurate, uninterpretable, outside valid range (.e., represent participant actually reported), need make personal decision deal . examples might deal true errors include:\nLeave data , make note errors documentation, allow future researchers deal values analysis process.\nAssign value code (e.g., “inaccurate value” = -90) recode values .\nCreate data quality indicator variables denote cells untrustworthy values (e.g., age contains true values age_q contains “concerns” = 0 | “quality concerns” = 1).\nfind inconsistencies across different sources, choose one form source truth recode values based form.\ntrue errors correct answer can easily inferred (e.g., 3-item rank order question completed 1, 2, 4), sometimes logical deductive editing can used cases value replaced logical correction (IPUMS USA 2023; Seastrom 2002).\nLeave data , make note errors documentation, allow future researchers deal values analysis process.Assign value code (e.g., “inaccurate value” = -90) recode values .Create data quality indicator variables denote cells untrustworthy values (e.g., age contains true values age_q contains “concerns” = 0 | “quality concerns” = 1).find inconsistencies across different sources, choose one form source truth recode values based form.true errors correct answer can easily inferred (e.g., 3-item rank order question completed 1, 2, 4), sometimes logical deductive editing can used cases value replaced logical correction (IPUMS USA 2023; Seastrom 2002).matter decision , make sure documented appropriate places future users (e.g., data dictionary, data cleaning plan, research protocol).point, dataset clean. However, may additional transformations performed depending plan store /share datasets.Join data\nmay datasets study need combined current data. Recall Section 3.3, two ways may need join data, horizontally vertically.\nJoining data horizontally (merging)\nMerging commonly used link longitudinal data within participants wide format. case necessary append time component time varying variable names already included (e.g., “w1_”, “w2_”).\nMerging can also used link forms within time (e.g., student survey student assessment) link forms across participant groups (e.g., link student data teacher data).\nmerging data, important files contain linking key (.e., unique identifier allow join files) variable names unique across files. Duplicate variable names allowed merging data.\n\nJoining data vertically (appending)\nAppending may used combine longitudinal data within participants long format. necessary include new variable indicates time period associated row.\nHowever, appending also often used combining forms collected different links captured separate tables (e.g., data collected across sites cohorts).\nappending data, imperative variables identically named formatted across files (.e., data types, value codes, format).\n\n\nDepending data collected captured, well want structure data, may use combination merging appending create desired dataset.\nmerging appending complete, important additional validation checks. correct number rows columns merging appending?\nmay datasets study need combined current data. Recall Section 3.3, two ways may need join data, horizontally vertically.\nJoining data horizontally (merging)\nMerging commonly used link longitudinal data within participants wide format. case necessary append time component time varying variable names already included (e.g., “w1_”, “w2_”).\nMerging can also used link forms within time (e.g., student survey student assessment) link forms across participant groups (e.g., link student data teacher data).\nmerging data, important files contain linking key (.e., unique identifier allow join files) variable names unique across files. Duplicate variable names allowed merging data.\n\nJoining data vertically (appending)\nAppending may used combine longitudinal data within participants long format. necessary include new variable indicates time period associated row.\nHowever, appending also often used combining forms collected different links captured separate tables (e.g., data collected across sites cohorts).\nappending data, imperative variables identically named formatted across files (.e., data types, value codes, format).\n\nJoining data horizontally (merging)\nMerging commonly used link longitudinal data within participants wide format. case necessary append time component time varying variable names already included (e.g., “w1_”, “w2_”).\nMerging can also used link forms within time (e.g., student survey student assessment) link forms across participant groups (e.g., link student data teacher data).\nmerging data, important files contain linking key (.e., unique identifier allow join files) variable names unique across files. Duplicate variable names allowed merging data.\nMerging commonly used link longitudinal data within participants wide format. case necessary append time component time varying variable names already included (e.g., “w1_”, “w2_”).Merging can also used link forms within time (e.g., student survey student assessment) link forms across participant groups (e.g., link student data teacher data).merging data, important files contain linking key (.e., unique identifier allow join files) variable names unique across files. Duplicate variable names allowed merging data.Joining data vertically (appending)\nAppending may used combine longitudinal data within participants long format. necessary include new variable indicates time period associated row.\nHowever, appending also often used combining forms collected different links captured separate tables (e.g., data collected across sites cohorts).\nappending data, imperative variables identically named formatted across files (.e., data types, value codes, format).\nAppending may used combine longitudinal data within participants long format. necessary include new variable indicates time period associated row.However, appending also often used combining forms collected different links captured separate tables (e.g., data collected across sites cohorts).appending data, imperative variables identically named formatted across files (.e., data types, value codes, format).Depending data collected captured, well want structure data, may use combination merging appending create desired dataset.merging appending complete, important additional validation checks. correct number rows columns merging appending?Reshape data\nRecall Section 3.3.2 reviewed various reasons structuring data wide long format.\nwide format, data collected unique subject one row. , unique identifiers repeat.\nlong format, participant identifiers can repeat, unique rows identified combination variables (e.g., stu_id wave together).\n\npoint merging appending data, find need reshape data new format, restructuring process need added data cleaning process.\nRecall Section 3.3.2 reviewed various reasons structuring data wide long format.\nwide format, data collected unique subject one row. , unique identifiers repeat.\nlong format, participant identifiers can repeat, unique rows identified combination variables (e.g., stu_id wave together).\nwide format, data collected unique subject one row. , unique identifiers repeat.long format, participant identifiers can repeat, unique rows identified combination variables (e.g., stu_id wave together).point merging appending data, find need reshape data new format, restructuring process need added data cleaning process.NoteIf working longitudinal data, concatenating time component beginning end variable name (Figure 14.10), rather embedding variable name, makes back forth restructuring process much easier statistical programs.\nFigure 14.10: comparison long wide format\nSave clean data\nfinal step cleaning process export save clean data. can save files one file types depending needs. can helpful save data one format meet various analysis, long-term storage, data sharing needs (e.g., interoperable format like CSV, format contains embedded metadata SPSS).\nfinal step cleaning process export save clean data. can save files one file types depending needs. can helpful save data one format meet various analysis, long-term storage, data sharing needs (e.g., interoperable format like CSV, format contains embedded metadata SPSS).","code":""},{"path":"clean.html","id":"data-cleaning-workflow","chapter":"14 Data Cleaning","heading":"14.4 Data cleaning workflow","text":"Data cleaning standalone process. part larger, well-planned workflow designed produce standardized, reproducible, reliable datasets. Ignoring planning jumping data cleaning haphazard way leads work cleaning process, organize messy work others can understand done. Assign someone oversee implement workflow designate time frame data cleaning begin finalized wave.","code":""},{"path":"clean.html","id":"preliminary-steps","chapter":"14 Data Cleaning","heading":"14.4.1 Preliminary steps","text":"first part creating data cleaning workflow making sure folder structure set according style guide, folders files consistently named according style guide. also important metadata names always provided order (e.g., project -> time -> participant -> instrument -> type). Breaking away standardized naming convention begins erode reproducibility work.Next, want gather necessary documentation used throughout cleaning process.Data dictionary\ndocument, variables named coded according style guide variables transformations approved data management working group.\ndocument, variables named coded according style guide variables transformations approved data management working group.Data cleaning plan\ninclude series steps based standardized data cleaning checklist, transformations reviewed data management working group.\ninclude series steps based standardized data cleaning checklist, transformations reviewed data management working group.README files\nincludes README files, stored alongside raw data files, contain notes may relevant data cleaning process (e.g., project coordinator notes “ID 1234 actually ID 1235”). want integrate information data cleaning plan needed.\nincludes README files, stored alongside raw data files, contain notes may relevant data cleaning process (e.g., project coordinator notes “ID 1234 actually ID 1235”). want integrate information data cleaning plan needed.Participant tracking database\nMake sure database date can compare form completion status numbers Ns dataset.\nMake sure database date can compare form completion status numbers Ns dataset.gather documentation, ready begin data cleaning process.","code":""},{"path":"clean.html","id":"cleaning-data-using-code","chapter":"14 Data Cleaning","heading":"14.4.2 Cleaning data using code","text":"can clean data point click method program like SPSS Microsoft Excel, cleaning data manually typically reproducible, leads errors, time consuming. number one practice can implement improve reproducibility, reliability, efficiency workflow clean data using code (Borer et al. 2009). code can written program team chooses (e.g., R, SAS, Stata, SPSS) saved syntax, script file, can re-run point. writing code may seem time consuming front, numerous benefits.helps thoughtful data cleaning process.allows others review work catch potential errors.can actually save enormous amount time future plan clean data form multiple times (say longitudinal study).allows others reproduce work. simply re-running code file, able get resulting dataset created.However, writing code alone provide desired benefits. must considered.Choose appropriate tool code . Assess things :\ncomfort level program well available support.\nCost access program.\nInteroperability program (.e., others able open, review, run code).\nLimitations (e.g., file size limitations, variable character count limitations).\nDefault settings (e.g., program performs rounding, dates stored).\ncomfort level program well available support.Cost access program.Interoperability program (.e., others able open, review, run code).Limitations (e.g., file size limitations, variable character count limitations).Default settings (e.g., program performs rounding, dates stored).Follow coding style guide.\ndiscussed Section 9.6, coding best practices using relative file paths, including comments, recording session information, reduces errors allows processes reproducible. Adding best practices code style guide ensures team members setting files consistent manner, improving usability code.\ndiscussed Section 9.6, coding best practices using relative file paths, including comments, recording session information, reduces errors allows processes reproducible. Adding best practices code style guide ensures team members setting files consistent manner, improving usability code.Review data upon import.\ndiscussed Section 14.3.1, imperative review data beginning clean ensure thorough understanding happening file. review process can become even relevant reusing syntax file clean data collected multiple times (e.g., longitudinal study). may expect syntax run flawlessly time period, yet anything changes data collection entry process (e.g., variable name changed, new item added, new variable category added), data cleaning syntax longer work intended. ’s best find start cleaning process can adjust data cleaning plan code needed.\ndiscussed Section 14.3.1, imperative review data beginning clean ensure thorough understanding happening file. review process can become even relevant reusing syntax file clean data collected multiple times (e.g., longitudinal study). may expect syntax run flawlessly time period, yet anything changes data collection entry process (e.g., variable name changed, new item added, new variable category added), data cleaning syntax longer work intended. ’s best find start cleaning process can adjust data cleaning plan code needed.transformations code.\nCleaning data using code improves reproducibility transformations, matter small, code. transformations done data outside code, even think something insignificant. work outside code, chain processing lost, work longer reproducible. Code files contain every transformation make raw data clean data.\nCleaning data using code improves reproducibility transformations, matter small, code. transformations done data outside code, even think something insignificant. work outside code, chain processing lost, work longer reproducible. Code files contain every transformation make raw data clean data.Don’t anything random.\nEverything syntax must replicable. Yet, scenarios , without even realizing , producing different results time run code.\nrandomly generate numbers data (e.g., study IDs), use algorithmic pseudorandom number generator (PRNG) (Klein et al. 2018). can easily done statistical programs setting seed. Every time PRNG run seed, produce results (.e., set random numbers). Without , get new random set numbers time syntax run.\nAnother example removing duplicate cases. purposeful remove duplicates. assume raw data always come order. Set parameters syntax dropping cases (e.g., order date drop second occurrence case). Otherwise, point, someone unexpectedly shuffles raw data around re-run syntax, may end dropping different duplicate cases.\n\nEverything syntax must replicable. Yet, scenarios , without even realizing , producing different results time run code.\nrandomly generate numbers data (e.g., study IDs), use algorithmic pseudorandom number generator (PRNG) (Klein et al. 2018). can easily done statistical programs setting seed. Every time PRNG run seed, produce results (.e., set random numbers). Without , get new random set numbers time syntax run.\nAnother example removing duplicate cases. purposeful remove duplicates. assume raw data always come order. Set parameters syntax dropping cases (e.g., order date drop second occurrence case). Otherwise, point, someone unexpectedly shuffles raw data around re-run syntax, may end dropping different duplicate cases.\nrandomly generate numbers data (e.g., study IDs), use algorithmic pseudorandom number generator (PRNG) (Klein et al. 2018). can easily done statistical programs setting seed. Every time PRNG run seed, produce results (.e., set random numbers). Without , get new random set numbers time syntax run.Another example removing duplicate cases. purposeful remove duplicates. assume raw data always come order. Set parameters syntax dropping cases (e.g., order date drop second occurrence case). Otherwise, point, someone unexpectedly shuffles raw data around re-run syntax, may end dropping different duplicate cases.Check transformation.\nmentioned Section 14.3.1, check work along way, don’t wait end script. transformation data:\nReview variables/cases transformations.\nReview errors warning codes.\nwarnings may innocuous (just messages).\nerrors telling code run, need fix something.\nwarnings telling code run run expected . don’t pay attention warnings, may end unexpected results.\n\n\nmentioned Section 14.3.1, check work along way, don’t wait end script. transformation data:\nReview variables/cases transformations.\nReview errors warning codes.\nwarnings may innocuous (just messages).\nerrors telling code run, need fix something.\nwarnings telling code run run expected . don’t pay attention warnings, may end unexpected results.\n\nReview variables/cases transformations.Review errors warning codes.\nwarnings may innocuous (just messages).\nerrors telling code run, need fix something.\nwarnings telling code run run expected . don’t pay attention warnings, may end unexpected results.\nwarnings may innocuous (just messages).errors telling code run, need fix something.warnings telling code run run expected . don’t pay attention warnings, may end unexpected results.Validate data exporting review exporting.\ndiscussed Section 14.3.1, exporting data want run final list sanity checks, based data quality criteria, make sure mistakes missed.\neyeballing summary information helpful, consider writing tests based expectations, produce result TRUE FALSE (e.g., test stu_id falls within range 1000–2000).\n\nexporting data, open exported file. everything look expected (e.g., maybe expected missing data export blanks, exported “NA”)?\ndiscussed Section 14.3.1, exporting data want run final list sanity checks, based data quality criteria, make sure mistakes missed.\neyeballing summary information helpful, consider writing tests based expectations, produce result TRUE FALSE (e.g., test stu_id falls within range 1000–2000).\neyeballing summary information helpful, consider writing tests based expectations, produce result TRUE FALSE (e.g., test stu_id falls within range 1000–2000).exporting data, open exported file. everything look expected (e.g., maybe expected missing data export blanks, exported “NA”)?code review.\none person team understands code, code review great practice integrate workflow. process someone, , review code things readability, usability, efficiency. code review ’s possible create interpretable code well catch errors aware . Code review checklists can implemented standardize process.\none person team understands code, code review great practice integrate workflow. process someone, , review code things readability, usability, efficiency. code review ’s possible create interpretable code well catch errors aware . Code review checklists can implemented standardize process.Resources","code":""},{"path":"clean.html","id":"cleaning-data-manually","chapter":"14 Data Cleaning","heading":"14.4.3 Cleaning data manually","text":"cleaning data code preferred method reasons previously mentioned, require technical expertise every team may . team needs clean data manually, consider two important things.Choose tool based criteria used choosing coding tool (.e., comfort level, cost access, interoperability, default settings). aware potential formatting issues mentioned Section 12.2 cleaning tools like Microsoft Excel.Choose tool based criteria used choosing coding tool (.e., comfort level, cost access, interoperability, default settings). aware potential formatting issues mentioned Section 12.2 cleaning tools like Microsoft Excel.begin cleaning data manually, imperative document every transformation enable reproducibility. may look different depending tool use.\ncleaning data using point click menu program SPSS, performing transformation use “paste” type button copy associated commands syntax file can easily reused (Kathawalla, Silverstein, Syed 2021).\nusing program Microsoft Excel data cleaning, add notes data cleaning plan detailed enough allow anyone replicate exact data cleaning process hand (Carpentries 2023).\nbegin cleaning data manually, imperative document every transformation enable reproducibility. may look different depending tool use.cleaning data using point click menu program SPSS, performing transformation use “paste” type button copy associated commands syntax file can easily reused (Kathawalla, Silverstein, Syed 2021).using program Microsoft Excel data cleaning, add notes data cleaning plan detailed enough allow anyone replicate exact data cleaning process hand (Carpentries 2023).","code":""},{"path":"clean.html","id":"data-versioning-practices","chapter":"14 Data Cleaning","heading":"14.4.4 Data versioning practices","text":"last part workflow consider store data version . First, export save clean datasets, make sure name appropriately differentiate raw clean datasets. active project, typically best store clean datasets respective individual folders (e.g., wave1 -> student -> survey -> clean folder), rather moving clean files separate “master folder”. changes need made files, easier keep track files original locations. Ultimately though, important copy files across folders active project. Keep one single copy clean dataset authenticity purposes (CESSDA Training Team 2017; UK Data Service 2023). end project, may consider moving copying files “master folder” archiving purposes (see Section 15.2).clean datasets saved, common find error data /code later point. Yet, ’ve begun using data ’ve shared others, imperative save existing versions files. need version code data, following guidelines laid style guide. Versioning file names, keeping track different versions changelog (see Section 8.3.2), allows track data lineage, helping users understand data originated well transformations made data. can version files choose, specifically referring final files , -progress, working files yet used shared others.Last, along assigning someone oversee data cleaning, important assign someone oversee versioning process. Versioning files updating documentation takes time consideration, responsibility need explicitly laid order ensure isn’t forgotten.","code":""},{"path":"store-long.html","id":"store-long","chapter":"15 Data Archiving","heading":"15 Data Archiving","text":"\nFigure 15.1: Long-term data storage research project life cycle\ngone cycles data collection preparing wrap grant, need switch gears start thinking archiving data ensure files still accessible usable, long project complete. project may ending, still many reasons retain data long-term including future analyses, opportunities make corrections (e.g., going back paper files error found data), data retention requirements funders institutions. section discuss care files internally, public data sharing archiving discussed Chapter 16. However, processes (preparing internally archive preparing publicly share data) likely happening time.","code":""},{"path":"store-long.html","id":"long-term-storage","chapter":"15 Data Archiving","heading":"15.1 Long-term storage","text":"first thing planning store data long-term review requirements data retention destruction. may requirements data retention destruction depending oversight (see Section 4.3). common oversight require retain data anywhere 3-10 years may specific destruction requirements data contain personally identifiable information (PII) data covered data use agreement. Make sure review relevant policies agreements determine required.understand requirements, make plan retention destruction. required retain data specified number years, consider continue store data documents way meets original goals (e.g., data safety, protecting confidentiality, accessibility usability files). need consider paper electronic files.","code":""},{"path":"store-long.html","id":"paper-data-1","chapter":"15 Data Archiving","heading":"15.1.1 Paper data","text":"end project, want begin boxing paper files long-term storage. Make sure clearly label boxes case need return files later point. Many institutions records management departments can assist long-term storage paper files. departments may able store physical files designated set time, well assist destruction files period ended. Note may want use solution certain longer need easily access paper files (e.g., fixing errors, entering additional information). destroying paper files , make sure choose quality destruction method paper shredding.","code":""},{"path":"store-long.html","id":"electronic-data-1","chapter":"15 Data Archiving","heading":"15.1.2 Electronic data","text":"electronic data long-term storage, want consider two things—file formats storage location (Borer et al. 2009; Briney 2015).File formats\nFirst, choose file types widely used (.e., don’t require proprietary software) accessibility well preventing file formats becoming obsolete (see Table 15.1). means can still keep copies files format SPSS prefer, good practice second copy data non-proprietary format CSV. documentation file formats also considered. Formats PDF TXT often recommended long-term storage text documents CSV good format tabular data dictionaries.\nFirst, choose file types widely used (.e., don’t require proprietary software) accessibility well preventing file formats becoming obsolete (see Table 15.1). means can still keep copies files format SPSS prefer, good practice second copy data non-proprietary format CSV. documentation file formats also considered. Formats PDF TXT often recommended long-term storage text documents CSV good format tabular data dictionaries.Storage location\nSimilar choosing file formats, choose storage location accessible risk becoming corrupt obsolete (e.g., think obsolescence floppy disks). Also, make sure able continue restricting access needed. short-term storage solution meets requirements (e.g., institution network drive), may need anything different preparing long-term storage, important continue implementing good practices keep data safe (e.g., continuing data backups, checking hardware software date).\nWithin storage location, consider copying finalized datasets (.e., cleaned de-identified) “master data” folder ease future accessibility. Restrict access reduce unintended modification files.\nDesign “master data” folder like public repository folder (see Section 16.3)\nAdd README describes files folder contains.\nCopy relevant documentation locations folder (e.g., data dictionaries, project-level documentation).\n\n\nSimilar choosing file formats, choose storage location accessible risk becoming corrupt obsolete (e.g., think obsolescence floppy disks). Also, make sure able continue restricting access needed. short-term storage solution meets requirements (e.g., institution network drive), may need anything different preparing long-term storage, important continue implementing good practices keep data safe (e.g., continuing data backups, checking hardware software date).Within storage location, consider copying finalized datasets (.e., cleaned de-identified) “master data” folder ease future accessibility. Restrict access reduce unintended modification files.\nDesign “master data” folder like public repository folder (see Section 16.3)\nAdd README describes files folder contains.\nCopy relevant documentation locations folder (e.g., data dictionaries, project-level documentation).\n\nDesign “master data” folder like public repository folder (see Section 16.3)\nAdd README describes files folder contains.\nCopy relevant documentation locations folder (e.g., data dictionaries, project-level documentation).\nAdd README describes files folder contains.Copy relevant documentation locations folder (e.g., data dictionaries, project-level documentation).comes time destroy data, make sure permanently delete files, including backups files. deleting PII, often involves just moving files recycle bin computer. Work institution department process.Table 15.1: Potential long-term storage file types","code":""},{"path":"store-long.html","id":"oversight-and-documentation","chapter":"15 Data Archiving","heading":"15.1.3 Oversight and documentation","text":"Last, make sure document plan, including time frames retention destruction, appropriate locations (e.g., DMP, research protocol, informed consent agreements, team data security policy). Assign document responsibilities short-term tasks boxing relocation files, well ongoing long-term tasks maintenance destruction files.Resources","code":""},{"path":"store-long.html","id":"store-long-use","chapter":"15 Data Archiving","heading":"15.2 Internal data use","text":"end project, possibly earlier project, team members want begin analyzing data. important consider make team members aware data available allow team members, research collaborators, access data. likely want researchers going folders grabbing datasets without consulting core team member first. Therefore, important develop system providing data researchers -needed basis. Create data request process team members, external collaborators, request access finalized study datasets. Several things need considered.Add descriptions finalized datasets data inventory inform team availability (see Section 8.1.4).Design system requesting access (e.g., designate person email, develop survey form submitted designated person).\nsystem, researcher describe data requesting, including exact variables need time periods, well purpose analysis. may helpful build data request process involves providing data dictionaries documentation researchers review requesting data.\nsystem also include collecting required agreement forms requestors (e.g., data sharing agreements).\nsystem, researcher describe data requesting, including exact variables need time periods, well purpose analysis. may helpful build data request process involves providing data dictionaries documentation researchers review requesting data.system also include collecting required agreement forms requestors (e.g., data sharing agreements).Decide needs review request ensure application complete (e.g., data manager), needs give final approval data request submission (e.g., principal investigator).Design system gathering data requestors (e.g., provide researchers full datasets, narrow datasets based specific requests).\nnarrowing datasets researchers, new datasets stored? (e.g., “data request” folder)\nnarrowing datasets researchers, new datasets stored? (e.g., “data request” folder)Consider share datasets researchers (e.g., secure link cloud folder, using secure file transfer).Consider track data requests.\nimportant keep track data requests case need reach back researchers situations errors found data. One way keep data request log. log can include information name researcher, date request, project requesting data , researcher email, helpful tracking information (e.g., agreement received, dataset shared). Using log, can reach back researchers needed inform updates regarding shared data.\nimportant keep track data requests case need reach back researchers situations errors found data. One way keep data request log. log can include information name researcher, date request, project requesting data , researcher email, helpful tracking information (e.g., agreement received, dataset shared). Using log, can reach back researchers needed inform updates regarding shared data.example might structure data request folder.Ultimately, want establish standardized efficient process reduces burden team members responsible reviewing, approving, fulfilling data requests also removes ambiguity users request access data (Institute Education Sciences 2019). always, roles responsibilities need assigned step process. Often person facilitates internal data requests one project, likely person fulfills data requests projects. Document request process data security policy (see Section 8.1.5) team members know request data work .","code":"data_requests/\n├── data_request_log.xlsx\n├── lastname1_firstname1\n|   ├── projname_lname-fname_data-sharing-agreement_2023-04-08.pdf\n│   ├── projname_stu_svy_clean_lname-fname_2023-05-02.csv\n│   └── projname_stu_svy_data-dictionary.xlsx\n├── lastname2_firstname2\n│   ├── archive\n│   |   ├── changelog.xlsx\n|   |   └── projname_tch_svy_clean_lname2-fname2_2023-05-15.csv\n|   ├── projname_lname2-fname2_data-sharing-agreement_2023-04-22.pdf\n│   ├── projname_tch_svy_clean_lname2-fname2_2023-06-10.csv\n|   └── projname_tch_svy_data-dictionary.xlsx\n└── ...\n"},{"path":"store-long.html","id":"using-a-repository","chapter":"15 Data Archiving","heading":"15.3 Using a repository","text":"Last, maintaining electronic data long-term sounds like much effort team, options. Many universities institutional repositories may include services data curation preservation. Additionally, several external repositories offer curation preservation services may able deposit data long-term storage. ’s possible depositing data one two options may also align publicly sharing data, review Chapter 16.","code":""},{"path":"share.html","id":"share","chapter":"16 Data Sharing","heading":"16 Data Sharing","text":"\nFigure 16.1: Data sharing research project life cycle\nThroughout project, teams internally sharing data materials variety people (e.g., team members, collaborators, funders) use information variety purposes (e.g., analyses, reports, answer questions). Yet, end project, possibly earlier, ’s important researchers also consider making research data available broader public use. However, publicly sharing project data materials requires lot consideration. chapter first review reasons publicly share data, work series decisions make sharing data.","code":""},{"path":"share.html","id":"share-why","chapter":"16 Data Sharing","heading":"16.1 Why share your data?","text":"notable reason openly sharing data growing number supporting organizations (e.g., funders, journals, institutions) requiring researchers share data. Federal agencies particular want ensure free, open access taxpayer-funded funded research (Nelson 2022). Beyond requirements though, many reasons researchers want share data. One, benefits scientific community improving rigor. Sharing data code helps discourage fabrication encourages validation results replication reproducibility findings (Alston Rick 2021; Cook et al. 2021; Gonzales, Carson, Holmes 2022; Institute Education Sciences 2023b; Klein et al. 2018; Levenstein Lyle 2018; Logan, Hart, Schatschneider 2021; Meyer 2018). Allowing researchers reuse data also reduces need duplicate data collection efforts, saving time, energy, money (Gonzales, Carson, Holmes 2022; Levenstein Lyle 2018; ICPSR 2020), well reducing burden communities frequently targeted data collection (Gaddy Scott 2020). also encourages diversity analysis perspectives (ICPSR 2020; Levenstein Lyle 2018). may researchers novel questions considered original investigators, open data also provides opportunity researchers improve upon experiment new methods, well combine datasets facilitate new discoveries (Cook et al. 2021; Institute Education Sciences 2023b; Logan, Hart, Schatschneider 2021; Meyer 2018). Openly sharing data also provides equitable access high-quality datasets early career scholars, students, underrepresented researchers otherwise may budget, staff, connections collect data (ICPSR 2020; Logan, Hart, Schatschneider 2021). Last, data sharing can unintended benefit promoting efficient sustainable data management practices (Klein et al. 2018). Knowing data documentation eventually shared outside team may motivate researchers think hard organize data management practices way produce materials proud publicly share. say data sharing without challenges, including additional time, energy resources required team prepare data sharing. However, planning data management practices around data sharing plan early can help reduce significant burden may otherwise caused data sharing (Klein et al. 2018; Levenstein Lyle 2018).","code":""},{"path":"share.html","id":"data-sharing-flow-chart","chapter":"16 Data Sharing","heading":"16.2 Data sharing flow chart","text":"series decisions made sharing data (see Figure 16.2). cases data sharing may occur end project, many data sharing decisions actually need made beginning project, write data management plan (DMP) (see Chapter 5). decisions inform workflow active project, well steps need perform preparing data archiving.\nFigure 16.2: Decisions made publicly sharing study data\nsection walk flow chart, discussing information needed make decisions well best practices associated decision.","code":""},{"path":"share.html","id":"share-able","chapter":"16 Data Sharing","heading":"16.2.1 Are you able to share?","text":"comes data, three degrees sharing (Ghent University 2023).Open data\ndata can publicly shared constraints. typically data ownership concerns minimal disclosure risk (e.g., de-identified, highly sensitive).\ndata can publicly shared constraints. typically data ownership concerns minimal disclosure risk (e.g., de-identified, highly sensitive).Controlled data\ndata openly shared, can shared ways restricted access use conditions. typically involves data request system including application /data use agreements, request approved can data accessed. includes things data minimal disclosure risk (e.g., highly sensitive information, identifiable information).\ndata openly shared, can shared ways restricted access use conditions. typically involves data request system including application /data use agreements, request approved can data accessed. includes things data minimal disclosure risk (e.g., highly sensitive information, identifiable information).Closed data\ndata shared due legal, ethical, technical reasons (e.g., proprietary data, data use agreements forbid , participant consent allow data sharing).\ncases, may still possible share data (.e., summary statistics, metadata, documentation), allow information discoverable, reusable, citable (Logan, Hart, Schatschneider 2021; Neild, Robinson, Agufa 2022).\ndata shared due legal, ethical, technical reasons (e.g., proprietary data, data use agreements forbid , participant consent allow data sharing).cases, may still possible share data (.e., summary statistics, metadata, documentation), allow information discoverable, reusable, citable (Logan, Hart, Schatschneider 2021; Neild, Robinson, Agufa 2022).preparing make data sharing decisions, helpful pull data sources catalog (see Section 5.3). Walk source one one consider reasons may prevent sharing data require share data controlled access (Klein et al. 2018; National Institutes Health 2023c; Neild, Robinson, Agufa 2022). ’s important review source individually, rather viewing data holistically, data can differentially shared. data may openly shared data . Ask questions :owner data? permission share data?\nmay involve reviewing data sharing agreements, licenses, documents.\nmay involve reviewing data sharing agreements, licenses, documents.need consent share data? yes, consent form include data sharing language (see Section 11.2.5)?able de-identify data point minimal disclosure risk?compelling legal, ethical, technical reasons share study data?important make decisions based philosophy “open possible, closed necessary” (European Commission. Directorate-General Research & Innovation 2016, 4). want data open facilitate reuse garner benefits mentioned Section 16.1, data closed necessary protect privacy individuals honor prior agreements. However, many reasons able share data can mitigated early planning. Developing consents clearly explain data sharing plans, talking partners early plans share data, can help increase amount data can openly share (Klein et al. 2018; Neild, Robinson, Agufa 2022).","code":""},{"path":"share.html","id":"where-to-share","chapter":"16 Data Sharing","heading":"16.2.2 Where to share?","text":"’ve decided able share data, either publicly restrictive manner, need decide want share data. many options sharing data, options better others. situations, best option sharing data public data repository. may repository chosen , may repository designated funder organization supporting work. cases ideal data sharing location. many benefits sharing public repository (Neild, Robinson, Agufa 2022; UK Data Service 2023).meets FAIR principles making data findable accessible (Section 2.4.1).preferred method data sharing many supporters (e.g., NIH, IES) may required others (e.g., NIJ, NIMH, journals AMPPS).provides hands-approach data sharing, reducing burden maintaining data responding data requests long-term.provides means securely share restricted-access data necessary.\nEven able directly deposit restricted-use data repository (e.g., repository accept restricted-use data, agency partner requires data stored site), repositories still support creation metadata-records, facilitate discovery data still allowing sensitive data maintained shared owner’s chosen data request system (Gonzales, Carson, Holmes 2022; Logan, Hart, Schatschneider 2021).\nEven able directly deposit restricted-use data repository (e.g., repository accept restricted-use data, agency partner requires data stored site), repositories still support creation metadata-records, facilitate discovery data still allowing sensitive data maintained shared owner’s chosen data request system (Gonzales, Carson, Holmes 2022; Logan, Hart, Schatschneider 2021).Repositories provide support data sharing, either direct data curation services offering detailed guidelines share.However, due supporter requirements (e.g., agency partner, institution, funder, journal), legal, technical, ethical reasons, may reason share data ways. following alternative ways share data (Alston Rick 2021; Briney 2015; Klein et al. 2018; Neild, Robinson, Agufa 2022; UK Data Service 2023).Deposit data institutional archive.\nmethod provides benefits reducing burden staff securely storing data, option available academic institutions repositories may provide less service offerings public repository. Furthermore, data stored institutional archive, opposed public repository, may less findable researchers outside institution.\nmethod provides benefits reducing burden staff securely storing data, option available academic institutions repositories may provide less service offerings public repository. Furthermore, data stored institutional archive, opposed public repository, may less findable researchers outside institution.Deposit partner agency.\ncases, data sharing may allowed deposit data agency partnered study (e.g., school district). case, data requests go partner.\ncases, data sharing may allowed deposit data agency partnered study (e.g., school district). case, data requests go partner.Share lab, personal, project website.\nsystem provides accessibility, sustainable. method requires significant commitment team. Sharing way requires publicize site increase visibility, well commit resources building maintaining secure reliable data request pipeline. Furthermore, websites change links break, reducing long-term accessibility data.\nsystem provides accessibility, sustainable. method requires significant commitment team. Sharing way requires publicize site increase visibility, well commit resources building maintaining secure reliable data request pipeline. Furthermore, websites change links break, reducing long-term accessibility data.Supplemental materials attached article stored publisher’s website.\nconcern method materials lost journal changes publishers publisher changes website.\nconcern method materials lost journal changes publishers publisher changes website.Informal peer--peer sharing.\ndata owners share data peers -needed basis. best case scenario, systematic data request process, similar internal one discussed Section 15.2, used. Yet, informal methods may work fine peers, doesn’t make broader audience aware availability data keeps burden data maintenance responding requests staff.\ntype sharing often synonymous using “data available upon request” statement publication. statements make broader audiences aware data, several studies found data availability statements rarely result access data (Stodden, Seiler, Ma 2018; Vines et al. 2014). better alternative already data shared location direct people system (e.g., link repository).\ndata owners share data peers -needed basis. best case scenario, systematic data request process, similar internal one discussed Section 15.2, used. Yet, informal methods may work fine peers, doesn’t make broader audience aware availability data keeps burden data maintenance responding requests staff.type sharing often synonymous using “data available upon request” statement publication. statements make broader audiences aware data, several studies found data availability statements rarely result access data (Stodden, Seiler, Ma 2018; Vines et al. 2014). better alternative already data shared location direct people system (e.g., link repository).Figure 16.3, modified flow chart created Borghi Van Gulick (2022), can help work process choosing share data source. Ultimately though, matter choose share data, important make decision early impact many decisions need made. particular, choose deposit data repository, want review repository-specific requirements standards make sure accounted DMP (e.g., data format requirements, metadata standards used) data management processes throughout study. Making decision early also allows begin creating schedule ongoing data deposits throughout study something want consider , required funder (ICPSR 2020).\nFigure 16.3: series decisions make deciding share data\n","code":""},{"path":"share.html","id":"choosing-a-repository","chapter":"16 Data Sharing","heading":"16.2.2.1 Choosing a repository","text":"point, may ready choose repository share data . abundance available data repositories choose Registry Research Data Repositories (re3data.org) indexed repositories, allowing researchers search vast landscape options. Several agencies also shared criteria help narrow choices. National Institutes Health (2023b) National Science Technology Council (2022) released desirable characteristics data repositories, Institute Education Sciences also provided set dimensions review considering appropriate repository (Neild, Robinson, Agufa 2022). agency lists reviewed, following questions starting point choosing repository fits needs project (Briney 2015; Gonzales, Carson, Holmes 2022; Goodman et al. 2014; Klein et al. 2018).specific repository required supporter (e.g., funder, journal, institution)?\nyes, don’t need proceed , repository share data . required repository meet specific needs (e.g., want reach specific audience), can always share metadata another repository link repository data shared.\nspecific repository required, also check see supporter preferred list repositories. , may best narrow search recommended options.\nyes, don’t need proceed , repository share data . required repository meet specific needs (e.g., want reach specific audience), can always share metadata another repository link repository data shared.specific repository required, also check see supporter preferred list repositories. , may best narrow search recommended options.domain-specific repository available (.e., caters field specific data type) generalist repositories commonly accepted field?\nDomain-specific repositories may interest researchers field may best option help facilitate discovery datasets. Using domain-specific repository can also help ensure preserving data according recognized standards field. minimum though, using generalist repositories common field improves discoverability.\ndomain-specific repositories commonly used field education research include ICPSR (https://www.icpsr.umich.edu) LDbase (https://www.ldbase.org/).\nNIH also established Generalist Repository Ecosystem Initiative (GREI), consists established generalist repositories support FAIR principles collaborating develop standard set services structures. Generalist repositories ecosystem commonly used education research include OSF (https://osf.io), Zenodo (https://zenodo.org/), Figshare (https://figshare.com/).\nqualitative data, also repositories specifically designed type data, Qualitative Data Repository (https://qdr.syr.edu/).\nDomain-specific repositories may interest researchers field may best option help facilitate discovery datasets. Using domain-specific repository can also help ensure preserving data according recognized standards field. minimum though, using generalist repositories common field improves discoverability.domain-specific repositories commonly used field education research include ICPSR (https://www.icpsr.umich.edu) LDbase (https://www.ldbase.org/).NIH also established Generalist Repository Ecosystem Initiative (GREI), consists established generalist repositories support FAIR principles collaborating develop standard set services structures. Generalist repositories ecosystem commonly used education research include OSF (https://osf.io), Zenodo (https://zenodo.org/), Figshare (https://figshare.com/).qualitative data, also repositories specifically designed type data, Qualitative Data Repository (https://qdr.syr.edu/).repository allow varying access levels?\nCan de-identified data easily accessed wide audience?\naccess options (e.g., download)?\nusers required account access data?\n\nrestricted-use files accepted?\ntransparent process reviewing data access requests? reviews access requests?\nusers able access restricted-use data files (e.g., secure download, virtual data enclave, physical data enclave)?\n\nCan de-identified data easily accessed wide audience?\naccess options (e.g., download)?\nusers required account access data?\naccess options (e.g., download)?users required account access data?restricted-use files accepted?\ntransparent process reviewing data access requests? reviews access requests?\nusers able access restricted-use data files (e.g., secure download, virtual data enclave, physical data enclave)?\ntransparent process reviewing data access requests? reviews access requests?users able access restricted-use data files (e.g., secure download, virtual data enclave, physical data enclave)?cost associated using repository?\nConsider costs store data costs users access data. may also costs associated additional services data curation.\nConsider costs store data costs users access data. may also costs associated additional services data curation.allowable file formats sizes?\nCheck size limits data files entire project. Also check file formats allowed. Certain repositories may file format preferences data files documentation files.\n’ll also want make sure repository provides files back users commonly accepted formats, including least one non-proprietary format.\nCheck size limits data files entire project. Also check file formats allowed. Certain repositories may file format preferences data files documentation files.’ll also want make sure repository provides files back users commonly accepted formats, including least one non-proprietary format.repository long-term sustainability?\nMake sure review repository’s data retention policies ensure meets requirements.\n’ll also want ensure repository plan long-term management data (considering funding infrastructure).\nMake sure review repository’s data retention policies ensure meets requirements.’ll also want ensure repository plan long-term management data (considering funding infrastructure).repository linking capabilities?\nrepository allow link projects, publications, code, data stored external sites?\nrepository allow link projects, publications, code, data stored external sites?clear use guidelines provided?\nclear guidance data can used? repository allow add usage licenses?\nLicenses set clear terms use data. Commonly used license groups include Creative Commons licenses (https://creativecommons.org/) Open Data Commons licenses (https://opendatacommons.org/). commonly used licenses CC ODC-allow others freely reuse materials long cite original creator.\n\nable set different reuse conditions different datasets?\nclear guidance data can used? repository allow add usage licenses?\nLicenses set clear terms use data. Commonly used license groups include Creative Commons licenses (https://creativecommons.org/) Open Data Commons licenses (https://opendatacommons.org/). commonly used licenses CC ODC-allow others freely reuse materials long cite original creator.\nLicenses set clear terms use data. Commonly used license groups include Creative Commons licenses (https://creativecommons.org/) Open Data Commons licenses (https://opendatacommons.org/). commonly used licenses CC ODC-allow others freely reuse materials long cite original creator.able set different reuse conditions different datasets?metadata collected upon deposit?\nrepository collect comprehensive metadata, use standards appropriate field?\nrepository collect comprehensive metadata, use standards appropriate field?repository assign unique persistent identifiers?\nUnique persistent identifiers (PIDs), digital object identifiers (DOIs), provide enduring reference digital object, even object’s URL changes. Repositories assign PIDs support discoverability well allow researchers track use contributions datasets.\nUnique persistent identifiers (PIDs), digital object identifiers (DOIs), provide enduring reference digital object, even object’s URL changes. Repositories assign PIDs support discoverability well allow researchers track use contributions datasets.repository track data provenance?\nimportant ability freely update remove data needed.\ndata amended, repository record data provenance versioning materials assigning updated PIDs?\nimportant ability freely update remove data needed.data amended, repository record data provenance versioning materials assigning updated PIDs?curation quality assurance services available?\nrepository provide curation services ensure data de-identified, high quality, interoperable formats, shared appropriate metadata?\nrepository provide curation services ensure data de-identified, high quality, interoperable formats, shared appropriate metadata?repository measure reuse?\nincludes things like tracking number downloads tracking citations.\nincludes things like tracking number downloads tracking citations.repository appropriate security measures place?\nincludes measures security data (e.g., maintaining backups), well measures ensure participant privacy (e.g., ensuring authorized users able access restricted data).\nincludes measures security data (e.g., maintaining backups), well measures ensure participant privacy (e.g., ensuring authorized users able access restricted data).","code":""},{"path":"share.html","id":"what-data-to-share","chapter":"16 Data Sharing","heading":"16.2.3 What data to share","text":"requirements data shared likely vary depending supporting agency. example, NIH asks researchers share final research data includes “recorded factual material commonly accepted scientific community necessary validate replicate research findings, regardless whether data used support scholarly publications” (National Institutes Health 2023c).Even supporter require broad sharing, general still good policy follow. end study, share data collected captured project, minding legal, ethical, technical reasons share information. includes sharing primary data collected project, raw (item-level) derived variables, well secondary data captured linked sources (e.g., student education records) (ICPSR 2020).sharing, review existing agreements licenses associated data source ensure allowed share format allowed share. Also review applicable consent agreements. want share data outside scope participants agreed . Last, sharing item-level data, review copyright published scales see allowed. publishers may allow share derived scores (Logan 2021).","code":""},{"path":"share.html","id":"processing-of-files","chapter":"16 Data Sharing","heading":"16.2.3.1 Processing of files","text":"discussed Chapter 14, three levels data files, raw, clean, analytic. publicly sharing project data, ’s often best share raw datasets. may seem counterintuitive ideas transparency reproducibility, education research raw datasets often contain identifiable information, despite best efforts collect comprehensible data, typically meet data quality criteria. tend still require sample cleaning (e.g., removing duplicates), well variable renaming, recoding, transformations ensure variables misused misinterpreted future users.Instead useful share general clean datasets discussed Chapter 14. datasets direct identifiers removed, curated allow easier interpretation variables, contain information necessary validate research findings. repository, also possible share analytic datasets created allow replication findings specific reports publications.","code":""},{"path":"share.html","id":"share-combine","chapter":"16 Data Sharing","heading":"16.2.3.2 Organizing files","text":"collecting data across time, across different forms, across different cohorts, want consider whether want combine files sharing want provide distinct files users can merge (Neild, Robinson, Agufa 2022).Combined files\nCombining datasets may great option longitudinal studies many waves data collection. Combining files across time can reduce burden future researchers want view data across time unit analysis. may consider merging data wide format participant level (e.g., student-level dataset, teacher-level dataset, school-level dataset), forms associated case found one row. See Section 3.3.2 information combine files way.\nCombining datasets may great option longitudinal studies many waves data collection. Combining files across time can reduce burden future researchers want view data across time unit analysis. may consider merging data wide format participant level (e.g., student-level dataset, teacher-level dataset, school-level dataset), forms associated case found one row. See Section 3.3.2 information combine files way.Separate files\nUploading datasets separately another option. Keeping data separate files reduces file size. may also make easier future researchers work data. instance, user interested one instrument collected one participant group, datasets separated allows researchers download just file one instrument, rather downloading larger dataset dropping variables relevant research. sharing longitudinal datasets separately, want decide want go ahead add time components variable names (e.g., w1_, w2_), add time component variable (e.g., wave) datasets, removing need future users step combining data (see Section 9.4.1 information adding time dataset).\nsharing datasets separately, also consider developing folder file naming structure allows researchers easily know files working . Also make sure files identifiers (.e., keys) necessary link datasets. Last, ’ll want include README future users helps clarify datasets can combined (refer Section 8.3.1 information).\nUploading datasets separately another option. Keeping data separate files reduces file size. may also make easier future researchers work data. instance, user interested one instrument collected one participant group, datasets separated allows researchers download just file one instrument, rather downloading larger dataset dropping variables relevant research. sharing longitudinal datasets separately, want decide want go ahead add time components variable names (e.g., w1_, w2_), add time component variable (e.g., wave) datasets, removing need future users step combining data (see Section 9.4.1 information adding time dataset).sharing datasets separately, also consider developing folder file naming structure allows researchers easily know files working . Also make sure files identifiers (.e., keys) necessary link datasets. Last, ’ll want include README future users helps clarify datasets can combined (refer Section 8.3.1 information).","code":""},{"path":"share.html","id":"file-formats","chapter":"16 Data Sharing","heading":"16.2.3.3 File formats","text":"funders require data shared electronic format, quantitative data particular, usually means rectangular format. keeping FAIR principles (Section 2.4.1), recommended provide data least one non-proprietary format (see Table 15.1 example formats). discussed Chapter 13, allows broader audience access data, also protects technological obsolescence.However, covered Chapter 14, can beneficial also share data formats embedded metadata (e.g., SPSS, Stata). Providing data non-proprietary format proprietary format widely used field, can give users options also protecting data obsolescence (Institute Education Sciences 2023a; Neild, Robinson, Agufa 2022).importantly though, sharing repository, check see data format requirements. ICPSR, example, encourages submission files embedded metadata, SPSS, Stata, SAS files (ICPSR 2023b). use files curate ASCII data setup files accompany statistical programs. another example, National Archive Criminal Justice Data used National Institute Justice (NIJ), prefers SPSS formats quantitative data, also accept Stata SAS files (National Archive Criminal Justice Data 2023).","code":""},{"path":"share.html","id":"assess-disclosure-risk","chapter":"16 Data Sharing","heading":"16.2.3.4 Assess disclosure risk","text":"publicly sharing study data, imperative conduct disclosure risk assessment. conducting assessment, review variables potentially identify participant, either directly indirectly, also review sensitive variables potential cause harm participants identity disclosed.Direct identifiers\ndiscussed Chapter 4, identifiers unique individual can used directly identify participant (e.g., name, email, IP address, student ID). can helpful mark identifiers data dictionary early keep track removed. unsure exactly direct identifiers check , 18 protected health identifiers listed HIPAA Safe Harbor De-Identification Method 84 good starting point. FERPA 85 also provides list personally identifiable information (PII) review.\ndiscussed Chapter 4, identifiers unique individual can used directly identify participant (e.g., name, email, IP address, student ID). can helpful mark identifiers data dictionary early keep track removed. unsure exactly direct identifiers check , 18 protected health identifiers listed HIPAA Safe Harbor De-Identification Method 84 good starting point. FERPA 85 also provides list personally identifiable information (PII) review.Indirect identifiers\ndataset may technically de-identified removing direct identifiers, still important consider possibility deductive disclosure (Institute Education Sciences 2023a). Research shown possible re-identify someone combination indirect identifiers (Sweeney 2002) (see Table 4.1 examples). care must taken consider ways participants can potentially re-identified data. includes considering following.\nOpen-ended questions: variables may contain information can directly indirectly identify individuals.\nOutliers: someone extreme values variable, may easier identify individual.\nSmall cell sizes: one person took survey particular date, one person fits specific demographic category, easier re-identify individual. NCES Standard 4-2-10, suggests categories least 3 cases minimize risk (Seastrom 2002), others may recommend stringent requirements minimum 5 cases (Schatschneider, Edwards, Shero 2021).\nCombinations variables, crosstabs, can also create small cell-sizes (e.g., student may identifiable school size + special education status + gender + grade level). Generally, indirect identifiers dataset, possible combinations exist, increasing risk re-identification (Morehouse, Kurdi, Nosek 2023).\n\n\nreviewing information, consider information general public may able decipher, also information may known people know participant (e.g., administrator, teacher, parent). also want consider amount potentially publicly available information participant site (e.g., administrative datasets, social media data) likelihood public information used re-identify someone (.e., linking public data study data) (Filip 2023; Meyer 2018; Neild, Robinson, Agufa 2022).\ndataset may technically de-identified removing direct identifiers, still important consider possibility deductive disclosure (Institute Education Sciences 2023a). Research shown possible re-identify someone combination indirect identifiers (Sweeney 2002) (see Table 4.1 examples). care must taken consider ways participants can potentially re-identified data. includes considering following.\nOpen-ended questions: variables may contain information can directly indirectly identify individuals.\nOutliers: someone extreme values variable, may easier identify individual.\nSmall cell sizes: one person took survey particular date, one person fits specific demographic category, easier re-identify individual. NCES Standard 4-2-10, suggests categories least 3 cases minimize risk (Seastrom 2002), others may recommend stringent requirements minimum 5 cases (Schatschneider, Edwards, Shero 2021).\nCombinations variables, crosstabs, can also create small cell-sizes (e.g., student may identifiable school size + special education status + gender + grade level). Generally, indirect identifiers dataset, possible combinations exist, increasing risk re-identification (Morehouse, Kurdi, Nosek 2023).\n\nOpen-ended questions: variables may contain information can directly indirectly identify individuals.Outliers: someone extreme values variable, may easier identify individual.Small cell sizes: one person took survey particular date, one person fits specific demographic category, easier re-identify individual. NCES Standard 4-2-10, suggests categories least 3 cases minimize risk (Seastrom 2002), others may recommend stringent requirements minimum 5 cases (Schatschneider, Edwards, Shero 2021).\nCombinations variables, crosstabs, can also create small cell-sizes (e.g., student may identifiable school size + special education status + gender + grade level). Generally, indirect identifiers dataset, possible combinations exist, increasing risk re-identification (Morehouse, Kurdi, Nosek 2023).\nCombinations variables, crosstabs, can also create small cell-sizes (e.g., student may identifiable school size + special education status + gender + grade level). Generally, indirect identifiers dataset, possible combinations exist, increasing risk re-identification (Morehouse, Kurdi, Nosek 2023).reviewing information, consider information general public may able decipher, also information may known people know participant (e.g., administrator, teacher, parent). also want consider amount potentially publicly available information participant site (e.g., administrative datasets, social media data) likelihood public information used re-identify someone (.e., linking public data study data) (Filip 2023; Meyer 2018; Neild, Robinson, Agufa 2022).Sensitive information\nassessing disclosure risk, also want review variables cause potential harm individual re-identified. Examples variables include health information, special education status, disciplinary status, information risky behaviors (Morehouse, Kurdi, Nosek 2023; Neild, Robinson, Agufa 2022).\nassessing disclosure risk, also want review variables cause potential harm individual re-identified. Examples variables include health information, special education status, disciplinary status, information risky behaviors (Morehouse, Kurdi, Nosek 2023; Neild, Robinson, Agufa 2022).","code":""},{"path":"share.html","id":"share-risk","chapter":"16 Data Sharing","heading":"16.2.3.4.1 Mitigating disclosure risk","text":"De-identification process balancing risks benefits. assessing disclosure risk, need weigh level potential harm may caused participant’s identity uncovered data (e.g., legal repercussions, embarrassment) potential benefits incurred sharing data (e.g., advancing science). Even editing data, amount risk never zero. always possible user can find way re-identify someone combining variables within project datasets, linking project data publicly available information. de-identification process, want decrease risks re-identification without seriously reducing utility dataset (e.g., consider reproducibility findings).discussed Chapter 14, first, direct identifiers completely removed dataset replaced study IDs. time get point preparing data sharing, step hopefully already completed. Yet, may consider. example, reduce participant re-identification risk, even schools districts necessarily promised confidentiality, beneficial remove names replace locations unique study IDs. Furthermore, concerns confidentiality unique study IDs (e.g., schools seen list identifiers can associate participants individual IDs), may want consider assigning new set IDs data publicly sharing. , make sure track sets identifiers participant tracking database.Next, consider indirect identifiers sensitive variables exist data. dealing variable types, variety commonly used methods reducing disclosure risk. Examples methods can easily applied (.e., require special technical expertise) change underlying values data listed (Filip 2023; Garfinkel 2015; Logan, Hart, Schatschneider 2021; Morehouse, Kurdi, Nosek 2023; Neild, Robinson, Agufa 2022; Schatschneider, Edwards, Shero 2021).Redaction: Eliminate entire variable data.\nmethod used direct identifiers may also used indirect identifiers pose disclosure risks.\nImportant indirect identifiers consider open-ended text variables verbatim responses. Although identifiers, name, removed variables data cleaning phase (see Section 14.3.1), participant responses still unique potentially identifiable, increasing risk disclosure. ’s important review responses determine level risk. team determines open-text variable redacted, researchers can still maintain information coding common responses creating new categorical variable. variable, coding scheme, documented future users.\n\nmethod used direct identifiers may also used indirect identifiers pose disclosure risks.\nImportant indirect identifiers consider open-ended text variables verbatim responses. Although identifiers, name, removed variables data cleaning phase (see Section 14.3.1), participant responses still unique potentially identifiable, increasing risk disclosure. ’s important review responses determine level risk. team determines open-text variable redacted, researchers can still maintain information coding common responses creating new categorical variable. variable, coding scheme, documented future users.\nImportant indirect identifiers consider open-ended text variables verbatim responses. Although identifiers, name, removed variables data cleaning phase (see Section 14.3.1), participant responses still unique potentially identifiable, increasing risk disclosure. ’s important review responses determine level risk. team determines open-text variable redacted, researchers can still maintain information coding common responses creating new categorical variable. variable, coding scheme, documented future users.Suppression: Remove data particular cell row.\ncan either leave cell missing fill code indicate value suppressed.\ncan either leave cell missing fill code indicate value suppressed.Generalization: Reduce precision data. includes techniques :\nReporting range opposed distinct values (e.g., range years teaching opposed number years)\nUsing rounded values rather exact numbers\nCollapsing categories (e.g., creating “” category special education categories Ns < 5)\nCreating summary variables (e.g., use date data collection date birth create age variable, allowing remove date birth date data collection)\nReport larger units (e.g., reporting age years opposed age months, reporting state region-level geography opposed county district)\ngeography particular, HIPAA safe harbor method recommends removing geography smaller state (U.S. Department Health Human Services 2012).\n\nReporting range opposed distinct values (e.g., range years teaching opposed number years)Using rounded values rather exact numbersCollapsing categories (e.g., creating “” category special education categories Ns < 5)Creating summary variables (e.g., use date data collection date birth create age variable, allowing remove date birth date data collection)Report larger units (e.g., reporting age years opposed age months, reporting state region-level geography opposed county district)\ngeography particular, HIPAA safe harbor method recommends removing geography smaller state (U.S. Department Health Human Services 2012).\ngeography particular, HIPAA safe harbor method recommends removing geography smaller state (U.S. Department Health Human Services 2012).Truncation: Also called top bottom coding, involves restricting upper lower ranges mask outliers (e.g., top code income $150k “$150k higher”).Share unlinked files: find potential re-identification caused linking across files (e.g., linking student file teacher file), indirect information contained files necessary analysis purposes, may consider sharing set files contain linking variables. However, ideal limits future use cases data.cases, easily applied methods satisfactory. However, situations risk disclosure minimal level potential harm also minimal, may consider using advanced techniques. Since techniques require technical expertise potential drastically alter data applied correctly, important consult someone expertise methods attempting (e.g., methodologists, repository curators, research data librarians). advanced techniques include following.Swapping: Matching cases one key variables, swapping values indirect identifiers interest.Perturbing: Adding random statistical noise data (e.g., multiply values variable random number).Microaggregation: Replace individual’s value cell average value small group.process de-identifying data data sharing done alone. Schedule one meetings data management working group review data develop plan. Bring outside expertise needed, especially implementing advanced data de-identification techniques. Last, make sure document de-identification methods appropriate locations (e.g., research protocol, data cleaning plan, data dictionary).Resources","code":""},{"path":"share.html","id":"sharing-controlled-access-data","chapter":"16 Data Sharing","heading":"16.2.3.4.2 Sharing controlled access data","text":"find de-identifying data alters way distorts data quality structure, believe risks sharing data still minimal, consider sharing controlled manner (ICPSR 2020; Meyer 2018; Morehouse, Kurdi, Nosek 2023; Neild, Robinson, Agufa 2022; Schatschneider, Edwards, Shero 2021). discussed Section 16.2.1, still possible share files restricted access. repository files can shared means secure downloads, virtual data enclaves, even onsite data enclaves. Access restricted data permitted application process requestors complete detailed data use agreement. See Figure 16.4 example restricted access dataset available United States Department Health Human Services. Administration Children Families, Office Planning, Research Evaluation (2023) ICPSR data repository.\nFigure 16.4: example restricted access data ICPSR\nsharing data repository allows share restricted data, can still share metadata repository, along information users contact requesting access restricted-use data share personal system. matter share data, order maximize public benefit, still consider openly sharing data. may simply summary statistics (e.g., means, standard deviations) provided tables. involve sharing two sets files. example, public access version file sensitive variables removed/altered restricted-use version file sensitive variables retained. However, sure consider possible disclosure risks sharing ensure someone access restricted public files able identify individuals. Also make sure inconsistencies files created process (ICPSR 2020; Logan, Hart, Schatschneider 2021; Neild, Robinson, Agufa 2022; Schatschneider, Edwards, Shero 2021) .","code":""},{"path":"share.html","id":"what-documentation-to-share","chapter":"16 Data Sharing","heading":"16.2.4 What documentation to share","text":"2022 OSTP memo (Nelson 2022), stated federal agencies expected develop data sharing policies elicit free open access scientific data “sufficient quality validate replicate research findings”. ’ve learned throughout book, sharing data alone sufficient enable data reuse (Hardwicke et al. 2018). must accompanied thorough documentation allow user understand data provenance. considering data documentation, consider amount documentation, also quality. higher quality documentation provide, higher likelihood data reused (Goodman et al. 2014).deciding exactly documents share, check funder see specific documents required. depositing data repository, check required well. repository may mandate suggest types documentation provide. ICPSR example provides suggested documentation include, codebooks, instruments, README files, project summary documents, publications (ICPSR 2023b).want share documents levels project (project, data, variable). level documentation provide unique contributions help users understand background project, files related, interpret use variables. Ideas share level provided (see Chapter 8 details documents).Project-level documentation\nResearch protocol\ndocument, may called names (e.g., project summary document), provides , , , , study. summation everything occurred study provides users background knowledge necessary correctly interpret use data.\nAlong research protocol, can also share variety helpful supplemental documents including, limited :\nParticipant flow diagrams\nTimelines\nCopies data collection instruments\nCopies consent forms\n\n\nProject-level README\nREADME can serve many purposes, case, README top data sharing directory can beneficial outlining high-level information project (.e., title, overview, contributors), well providing file tree describes files organized directory.\n\nResearch protocol\ndocument, may called names (e.g., project summary document), provides , , , , study. summation everything occurred study provides users background knowledge necessary correctly interpret use data.\nAlong research protocol, can also share variety helpful supplemental documents including, limited :\nParticipant flow diagrams\nTimelines\nCopies data collection instruments\nCopies consent forms\n\ndocument, may called names (e.g., project summary document), provides , , , , study. summation everything occurred study provides users background knowledge necessary correctly interpret use data.Along research protocol, can also share variety helpful supplemental documents including, limited :\nParticipant flow diagrams\nTimelines\nCopies data collection instruments\nCopies consent forms\nParticipant flow diagramsTimelinesCopies data collection instrumentsCopies consent formsProject-level README\nREADME can serve many purposes, case, README top data sharing directory can beneficial outlining high-level information project (.e., title, overview, contributors), well providing file tree describes files organized directory.\nREADME can serve many purposes, case, README top data sharing directory can beneficial outlining high-level information project (.e., title, overview, contributors), well providing file tree describes files organized directory.example project-level README file.Dataset-level documentation\nDataset-level README\ncase, README organized rectangular format can helpful describe set files specific folder (e.g., student data folder). README can list every file folder provide information allows users understand file contains well datasets may linked. especially beneficial cases sharing individual files expectation future users link time. Adding README clarifies identifiers can used link files (see Figure 8.13 example).\n\nSyntax files\ncases, unlikely going want publicly share data cleaning code. one, typically sharing raw data associated cleaning code, cleaning code useful reproducibility purposes. Second, depending amount data collected amount cleaning required data, cleaning code can overwhelming future user sift . Sometimes can 20 scripts multiple instruments collected, across multiple participant groups, multiple waves. likely helpful anyone, outside just learning coding practices (can actually helpful teaching learning purposes). cases though, necessary share data cleaning code unless really want . However, plan share analytic files repository, imperative share code associated creation analytic datasets well code necessary reproduce findings (Renbarger et al. 2022).\n\nData cleaning plans\nalways necessary share data cleaning code, especially sharing raw data, can helpful share data cleaning plans. Providing plans allows transparency decision-making process occurred transforming raw data clean shareable data, may help future users interpretation.\n\nDataset-level README\ncase, README organized rectangular format can helpful describe set files specific folder (e.g., student data folder). README can list every file folder provide information allows users understand file contains well datasets may linked. especially beneficial cases sharing individual files expectation future users link time. Adding README clarifies identifiers can used link files (see Figure 8.13 example).\ncase, README organized rectangular format can helpful describe set files specific folder (e.g., student data folder). README can list every file folder provide information allows users understand file contains well datasets may linked. especially beneficial cases sharing individual files expectation future users link time. Adding README clarifies identifiers can used link files (see Figure 8.13 example).Syntax files\ncases, unlikely going want publicly share data cleaning code. one, typically sharing raw data associated cleaning code, cleaning code useful reproducibility purposes. Second, depending amount data collected amount cleaning required data, cleaning code can overwhelming future user sift . Sometimes can 20 scripts multiple instruments collected, across multiple participant groups, multiple waves. likely helpful anyone, outside just learning coding practices (can actually helpful teaching learning purposes). cases though, necessary share data cleaning code unless really want . However, plan share analytic files repository, imperative share code associated creation analytic datasets well code necessary reproduce findings (Renbarger et al. 2022).\ncases, unlikely going want publicly share data cleaning code. one, typically sharing raw data associated cleaning code, cleaning code useful reproducibility purposes. Second, depending amount data collected amount cleaning required data, cleaning code can overwhelming future user sift . Sometimes can 20 scripts multiple instruments collected, across multiple participant groups, multiple waves. likely helpful anyone, outside just learning coding practices (can actually helpful teaching learning purposes). cases though, necessary share data cleaning code unless really want . However, plan share analytic files repository, imperative share code associated creation analytic datasets well code necessary reproduce findings (Renbarger et al. 2022).Data cleaning plans\nalways necessary share data cleaning code, especially sharing raw data, can helpful share data cleaning plans. Providing plans allows transparency decision-making process occurred transforming raw data clean shareable data, may help future users interpretation.\nalways necessary share data cleaning code, especially sharing raw data, can helpful share data cleaning plans. Providing plans allows transparency decision-making process occurred transforming raw data clean shareable data, may help future users interpretation.Variable-level documentation\nData dictionaries /codebooks\ndocuments help users correctly interpret variables dataset. least one documents must shared, . Recall data dictionaries provide overview variables exist dataset, displayed tabular format (Section 8.4.1). Codebooks provide somewhat similar information, addition summary statistics variable, usually provided text format (Section 8.4.2).\n\nData dictionaries /codebooks\ndocuments help users correctly interpret variables dataset. least one documents must shared, . Recall data dictionaries provide overview variables exist dataset, displayed tabular format (Section 8.4.1). Codebooks provide somewhat similar information, addition summary statistics variable, usually provided text format (Section 8.4.2).\ndocuments help users correctly interpret variables dataset. least one documents must shared, . Recall data dictionaries provide overview variables exist dataset, displayed tabular format (Section 8.4.1). Codebooks provide somewhat similar information, addition summary statistics variable, usually provided text format (Section 8.4.2).Metadata\ndiscussed Chapter 8, sharing data repository, metadata likely collected repository deposit materials. metadata can added levels, minimum repository likely collect project-level metadata (e.g., title, creator, date, key words). machine-readable metadata aid discoverability reusability materials.\ndiscussed Chapter 8, sharing data repository, metadata likely collected repository deposit materials. metadata can added levels, minimum repository likely collect project-level metadata (e.g., title, creator, date, key words). machine-readable metadata aid discoverability reusability materials.sharing documentation, make sure assessed forms disclosure risk. Review code, data dictionaries, screenshots, forth, instances names identifying information used redact PII sharing (Neild, Robinson, Agufa 2022). also important consider copyright issues may encounter. published measure give permission share item-specific information, may need remove exact verbiage documentation (e.g., data dictionaries, codebooks) replace generic language “item 1 assessment name” (Logan 2021).","code":"Project title and subtitle\n\nBrief project overview\nDescribe this project or resource.\n\nContributors\nList all contributors.\n\nRepository overview\nProvide an overview of the directory structure and files, for example:\n\nstudy_name/\n|-- README.txt\n|-- documentation\n    |--study_name_project_summary_document.pdf\n    |--study_name_data_dictionary.xlsx\n    |--study_name_stu_svy_data_cleaning_plan.txt\n|-- data\n    |-- README.txt\n    |--study_name_w1_stu_svy_clean.csv\n    |--study_name_w2_stu_svy_clean.csv\n|-- analysis\n    |--README.txt\n    |--data\n    |--manuscripts\n    |--output\n    |--syntax\n\nApplicable instructions\nAny instructions/tools necessary to use files or replicate results.\n\nAdditional resources\nPoint interested users to any related literature and/or documentation.\n"},{"path":"share.html","id":"file-formats-1","chapter":"16 Data Sharing","heading":"16.2.4.1 File formats","text":", sharing data repository, check see required suggested documentation formats. example, ICPSR specifies variety formats documentation submission including Microsoft Word, ASCII, DDI XML format turn convert documentation XML PDF format (ICPSR 2023b). ’ll also want check metadata standards repository complies , DDI standards, requires additional considerations part archive takes care standardizing information .depositing repository, repository strict requirements, sharing documentation non-proprietary formats recommended. files anyone can open matter software . PDFs text files generally good formats. rectangular format used, documents data dictionary, CSV files can created still opened spreadsheet program. researchers also started share documentation searchable formats, including HTML, make easier sift large amounts information.","code":""},{"path":"share.html","id":"when-to-share","chapter":"16 Data Sharing","heading":"16.2.5 When to share","text":"important thing consider required funder, supporters. Federal funders likely required time frames. example, NIH expects researchers share data later time publication end grant, whichever comes first (National Institutes Health 2021). funders, National Institute Mental Health (NIMH), expectations grant awardees share data throughout grant regular schedule (National Institute Mental Health 2023).repository may also preferences data deposited. example, data can deposited time ICPSR, recommend begin uploading data soon possible data collection allow time data curation (ICPSR 2023c). choose make ongoing deposits data, want consider like embargo data required share. means delay public release data later time point choosing. allows continually deposit data, example reduce workload end study, also allowing sole access data project active. choose deposit data ongoing basis, make sure repository allows edit, update, version data errors found changes needed point project.","code":""},{"path":"share.html","id":"share-file","chapter":"16 Data Sharing","heading":"16.3 Repository file structure","text":"repositories predefined file structure require little effort part set . However, many repositories hands allow set structures way works well . Similar followed style guide (Chapter 9) setting internal team project electronic file structures, want follow style guide rules setting data sharing file structure. organized store information descriptive name folders files. want remove many cognitive barriers possible increase likelihood materials reused. someone opens project feel confused point looking , likely leave move new project. Users want feel confident understand project use materials. Also make sure use additional services provided repository may also aid discoverability interpretation (e.g., wikis, linking relevant materials).example one way might set repository small project collected longitudinal data students teachers. “analysis” folder added , addition sharing general clean study files, also plan include files created specific analyses. adding “analysis” folder, can helpful include another project-level README top folder, describing helpful information specific analysis, well overview folder organized.Resources","code":"study_name/\n├── README.txt (project-level)\n├── documentation\n|   ├── study_name_project_summary_document.pdf\n|   ├── study_name_stu_svy_data-dictionary.csv\n|   ├── study_name_tch_svy_data-dictionary.csv\n|   ├── data_cleaning_plans\n|   |   ├── study_name_stu_svy_data_cleaning_plan.txt\n|   |   └── study_name_tch_svy_data_cleaning_plan.txt\n├── data\n|   ├── stu\n|   ├── README.txt (dataset-level)\n|   |   ├── w1\n|   |   |   ├── study_name_w1_stu_svy_clean.csv (CSV format)\n|   |   |   └── study_name_w1_stu_svy_clean.sav (SPSS format)\n|   |   ├── w2\n|   |   |   ├── study_name_w2_stu_svy_clean.csv\n|   |   |   └── study_name_w2_stu_svy_clean.sav\n|   ├── tch\n|   ├── README.txt (dataset-level)\n|   |   ├── w1\n|   |   |   ├── study_name_w1_tch_svy_clean.csv\n|   |   |   └── study_name_w1_tch_svy_clean.sav\n|   |   ├── w2\n|   |   |   ├── study_name_w2_tch_svy_clean.csv\n|   |   |   └── study_name_w2_tch_svy_clean.sav\n├── analysis (if relevant to this repository)\n|   ├── README.txt\n|   |   └── ...\n|   ├── data (this would contain analytic data files)\n|   |   └── ...\n|   ├── manuscripts\n|   |   └── ...\n|   ├── outputs\n|   |   └── ...\n|   ├── syntax\n|   |   └── ...\n└──\n"},{"path":"share.html","id":"roles-and-responsibilities","chapter":"16 Data Sharing","heading":"16.4 Roles and responsibilities","text":"every phase research life cycle, important assign roles responsibilities throughout process. beginning project, take inventory expertise capacity share data take note gaps.need expertise data de-identification techniques?need expertise developing data use agreements assigning licenses?yes, begin looking may fill gaps (e.g., research data librarians, methodologists, data curation specialists repository). Consider responsibilities need covered process. Many required tasks (e.g., data cleaning, documentation) require additional planning, roles responsibilities designated phases. However, several new tasks specific phase (e.g., creating data use agreements, assessing disclosure risk), tasks vary depending sharing repository institutional archive (e.g., communicating repository staff, troubleshooting issues) sharing (e.g., developing data request sharing system). Even data shared, depending data shared, may also need assign responsibilities ongoing maintenance (e.g., responding access requests). data sharing plan formalized, documented necessary locations (e.g., DMP, research protocol, SOPs, informed consent forms).organizations put together data sharing checklists. checklists may help begin assigning team members specified responsibilities.Resources","code":""},{"path":"share.html","id":"revisions","chapter":"16 Data Sharing","heading":"16.5 Revisions","text":"publicly sharing study data materials, researchers often concerned errors may found (Beaudry et al. 2022; Houtkoop et al. 2018; Levenstein Lyle 2018). errors found data publicly sharing, ideal, important recognize first person happened . researchers come across errors data sharing successfully made plans addressing problem (Aboumatar et al. 2021; Bishop 2014; Grave 2021; Laskowski 2020; Strand 2020). Depending ’ve shared used data, different ways address errors.First, used data publication, contact journal make aware errors found. journal may provide options including opportunity revise retract article. Next, want update shared data.data shared repository institutional archive:Make appropriate edits data upload new version repository.\nMany repositories assign project, data, new version number, along new DOI, denote changes project.\nrepository provide place note reason revisions, add information changelog README project folder (Kopper, Sautmann, Turitto 2023b).\nMany repositories assign project, data, new version number, along new DOI, denote changes project.repository provide place note reason revisions, add information changelog README project folder (Kopper, Sautmann, Turitto 2023b).repository requires/allows users make account accessing data, may system email current users let know new version data created .data repository institutional archive:Make appropriate edits data save new version. Make note change internal changelog.Make appropriate edits data save new version. Make note change internal changelog., consider personally reaching anyone submitted data request notify errors data., consider personally reaching anyone submitted data request notify errors data.potential others find errors often viewed consequence data sharing, can also view opportunity better science. Giving others chance catch errors data, may otherwise caught (Bishop 2014; Klein et al. 2018; Schoen Solmaz-Ratzlaff 2023), allows us make corrections, ensuring findings derived based inaccurate data. Data sharing also provides incentive us implement rigorous data management practices hopefully improve data integrity create less concern future errors (Klein et al. 2018; Strand 2021).","code":""},{"path":"additional-considerations.html","id":"additional-considerations","chapter":"17 Additional Considerations","heading":"17 Additional Considerations","text":"point, mostly focused simplistic workflow one team one project. However, becoming common projects include multi-site collaborations (e.g., grant shared across multiple research institutions), teams multiple projects. add complexity data management briefly address.","code":""},{"path":"additional-considerations.html","id":"multi-site-collaborations","chapter":"17 Additional Considerations","heading":"17.0.1 Multi-site collaborations","text":"Multi-site, multi-team, collaborations require additional planning around roles responsibilities, workflows, standards. Jumping multi-site collaborations without spending time cross-team planning often leads unfortunate data security, quality, usability concerns. project begins, consider documenting expectations collaboration agreement. developing type agreement, review everything typical data management checklist come agreement decisions. following types multi-site issues also addressed (Briney 2015; Schmitt Burchinal 2011).teams maintain consistency procedures across sites (e.g., shared SOPs, shared style guides, oversight practices)?\nsite handling data tracking, capture, entry, cleaning procedures, imperative processes standardized allow datasets integrated.\nsite handling data tracking, capture, entry, cleaning procedures, imperative processes standardized allow datasets integrated.teams handle data ownership?roles responsibilities across sites?tools used allow multi-site data tracking, collection, entry, storage, sharing?Documents, RACI matrix (Miranda Watts 2022), can help lay expectations team collaborations (Figure 17.1). charts, site assigned task either responsible, accountable, consulted, informed.Responsible: site responsible completing task.Accountable: site provides oversight, ensuring task completed fidelity.Consulted: site always consulted decision made task.Informed: site provided high-level information decisions made.Assigning levels responsibility site allows collaborators clearly see expected project. Within site tasks can assigned specific roles.\nFigure 17.1: Example simplified RACI chart multi-site project collaboration\n","code":""},{"path":"additional-considerations.html","id":"multi-project-teams","chapter":"17 Additional Considerations","heading":"17.0.2 Multi-project teams","text":"Similar multi-site projects, organizing multiple projects within team requires additional coordination. number projects grow, sophistication operations grow well. Consider following (Van den Eynden et al. 2011):Centralize resources.\nCreate templates, SOPs, code snippets (reusable blocks code), style guides can used across projects. Utilize team wiki post shared resources central location team members can easily access . Centralizing resources reduces duplication efforts, also improves standardization, allowing easily compare data across projects.\nCreate templates, SOPs, code snippets (reusable blocks code), style guides can used across projects. Utilize team wiki post shared resources central location team members can easily access . Centralizing resources reduces duplication efforts, also improves standardization, allowing easily compare data across projects.Encourage team science.\nreceive grants, “lone cowboy” model just one person manage everything becomes even less feasible (J. H. Reynolds et al. 2014). Embrace idea takes team people, skilled many different areas (e.g., project management expertise, data management expertise, content expertise, administration expertise), quality research. one grant, potentially feasible hire people fill specialized roles, fund across multiple grants.\nreceive grants, “lone cowboy” model just one person manage everything becomes even less feasible (J. H. Reynolds et al. 2014). Embrace idea takes team people, skilled many different areas (e.g., project management expertise, data management expertise, content expertise, administration expertise), quality research. one grant, potentially feasible hire people fill specialized roles, fund across multiple grants.Create hierarchy roles.\nnumber team members grows, becomes important assign someone foster collaboration oversee fidelity data management standards across projects (Briney 2015). Create hierarchy roles, including data management implementers (e.g., data specialists, data managers) supervisors (e.g., senior data managers, data leads), supervisor role helping prevent internal drift expectation setting, oversight, mentorship.\nnumber team members grows, becomes important assign someone foster collaboration oversee fidelity data management standards across projects (Briney 2015). Create hierarchy roles, including data management implementers (e.g., data specialists, data managers) supervisors (e.g., senior data managers, data leads), supervisor role helping prevent internal drift expectation setting, oversight, mentorship.Create support systems.\nteam large enough, multiple people working data management across different projects, may helpful create data core. internal group data people can meet regularly share knowledge resources, develop modify shared documentation, develop internal data trainings staff, increasing capacity center.\nteam large enough, multiple people working data management across different projects, may helpful create data core. internal group data people can meet regularly share knowledge resources, develop modify shared documentation, develop internal data trainings staff, increasing capacity center.","code":""},{"path":"additional-considerations.html","id":"summary-1","chapter":"17 Additional Considerations","heading":"17.0.3 Summary","text":"Collecting data bit like cooking good meal. clean go, full sleepy much less .- Felicia LeClere (2010)Slow science often used describe antithesis increasingly fast pace academic research, instead suggesting science slower, methodical process (Frith 2020). Likewise, hurry research project along without spending time putting quality data management processes place, increase possibility end putting research world trust. Instead, take time plan data management project begins, implement quality practices throughout life cycle. may difficult support slow process early , remember data management gets easier . templates, protocols, style guides place, documents processes can reused, easing burdens future projects (Levenstein Lyle 2018).one-size-fits-approach data management though (Bergmann 2023; J. H. Reynolds et al. 2014). Projects nuanced way anticipate every way specific project’s data needs managed. Instead, use “buffet approach” implement works best project team (Bergmann 2023). matters practices implemented consistently within project, ultimately produce quality data products accepted field. Similarly, possible practices mentioned book work project, unlikely team bandwidth . Instead, implement “good enough” practices allow achieve quality outcomes desire (Borghi Van Gulick 2022; Wilson et al. 2017). don’t create documentation use sophisticated data cleaning methods. simply need use methods good enough reach goals. Also make sure periodically review data management practices ensure keeping changing requirements, technologies, standards, team/project needs.Last, awareness necessity good data management grows field, can hope systemic changes continue happen, making efforts easier education researchers. institutions, academic libraries, provide data management learning opportunities including workshops, online modules, demand courses, resources still reaching everyone. Integrating data management content required college coursework improve data management practices researchers “winging ” learned data management informal methods. Funding institutions may also begin find ways necessitate data management training applicants. requirements data management sharing expanding, Wilson et al. (2017, 19) suggest “unfair well counterproductive insist researchers things without teaching ”. Furthermore, developing shared standards field education wonders easing burden researchers make fly data management decisions, instead allowing follow set instructions tasks formatting documenting data. Developing standards also benefit anyone interested scientific inquiry, improving consistency quality usability publicly shared data products.","code":""},{"path":"glossary.html","id":"glossary","chapter":"18 Glossary","heading":"18 Glossary","text":"","code":""},{"path":"appendix.html","id":"appendix","chapter":"19 Appendix","heading":"19 Appendix","text":"summary purposes, appendix provides high-level overview common activities occur phase research data management life cycle.DMP (Chapter 5)Review oversight requirements.Create data sources catalog.Create data management plan.Planning (Chapter 6)Develop style guide.Choose storage locations.\nBuild directory structures electronic data physical. folder structures paper data.\nBuild directory structures electronic data physical. folder structures paper data.Develop data management working group (DMWG).\nSchedule planning meetings keep meeting notes.\nReview checklists.\nDevelop workflows.\n\nSchedule planning meetings keep meeting notes.\nReview checklists.\nDevelop workflows.\nReview checklists.Develop workflows.Assign roles responsibilities.Initiate necessary processes (e.g., data request, Institutional Review Board application).Document (Chapter 8)Create research protocol.Create data collection timeline.Create SOPs.\nID schema\nConsent process\nInclusion/exclusion criteria\nData collection processes\nData entry procedures\nID schemaConsent processInclusion/exclusion criteriaData collection processesData entry proceduresCreate data dictionaries.Start data cleaning plans.Create instruments (Chapter 10 Chapter 11)Create participant tracking database.Create data collection instruments.Develop consent forms include data sharing language.Collect data (Chapter 11)Implement quality assurance procedures field.Track data (Chapter 10)Track incoming data daily participant tracking database.Capture data (Chapter 12)Capture original paper electronic data.Capture external data.Store (Chapter 13)Store raw data documents project.Clean Validate (Chapter 14)Clean data.Validate data (e.g., create codebook check errors).Store clean data.Create participant flow diagram.Version (Chapter 14)Version finalized data errors found update changelog.Prepare archive (Chapter 15)Prepare paper electronic data long-term storage.Update data inventory new project datasets.Develop internal data reuse process.Prepare data documentation open sharing (information Chapter 16).Sharing (Chapter 16)Share data documentation open repository, using controlled access needed.","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
