<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 10 Data Collection | Data Management in Large-Scale Education Research</title>
<meta name="author" content="Crystal Lewis">
<meta name="description" content="Figure 10.1: Data collection in the research project life cycle  When collecting original data as part of your study (i.e., you are administering your own survey or assessment as opposed to using...">
<meta name="generator" content="bookdown 0.29 with bs4_book()">
<meta property="og:title" content="Chapter 10 Data Collection | Data Management in Large-Scale Education Research">
<meta property="og:type" content="book">
<meta property="og:image" content="/book_featured.PNG">
<meta property="og:description" content="Figure 10.1: Data collection in the research project life cycle  When collecting original data as part of your study (i.e., you are administering your own survey or assessment as opposed to using...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 10 Data Collection | Data Management in Large-Scale Education Research">
<meta name="twitter:description" content="Figure 10.1: Data collection in the research project life cycle  When collecting original data as part of your study (i.e., you are administering your own survey or assessment as opposed to using...">
<meta name="twitter:image" content="/book_featured.PNG">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.4.0/transition.js"></script><script src="libs/bs3compat-0.4.0/tabs.js"></script><script src="libs/bs3compat-0.4.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Data Management in Large-Scale Education Research</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"><span class="header-section-number">1</span> Preamble</a></li>
<li><a class="" href="rdm.html"><span class="header-section-number">2</span> Research Data Management Overview</a></li>
<li><a class="" href="structure.html"><span class="header-section-number">3</span> Data Structure</a></li>
<li><a class="" href="dmp.html"><span class="header-section-number">4</span> Data Management Plan</a></li>
<li><a class="" href="plan.html"><span class="header-section-number">5</span> Planning Data Management</a></li>
<li><a class="" href="roles.html"><span class="header-section-number">6</span> Project Roles and Responsibilities</a></li>
<li><a class="" href="document.html"><span class="header-section-number">7</span> Documentation</a></li>
<li><a class="" href="style.html"><span class="header-section-number">8</span> Style guide</a></li>
<li><a class="" href="track.html"><span class="header-section-number">9</span> Data Tracking</a></li>
<li><a class="active" href="collect.html"><span class="header-section-number">10</span> Data Collection</a></li>
<li><a class="" href="capture.html"><span class="header-section-number">11</span> Data Capture</a></li>
<li><a class="" href="storage.html"><span class="header-section-number">12</span> Data Storage and Security</a></li>
<li><a class="" href="clean.html"><span class="header-section-number">13</span> Data Cleaning</a></li>
<li><a class="" href="share.html"><span class="header-section-number">14</span> Data Sharing</a></li>
<li><a class="" href="wrapping-it-up-1.html"><span class="header-section-number">15</span> Wrapping It Up</a></li>
<li><a class="" href="call-to-action.html"><span class="header-section-number">16</span> Call to Action</a></li>
<li><a class="" href="glossary.html"><span class="header-section-number">17</span> Glossary</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/Cghlewis/data-mgmt-ed-research-book">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="collect" class="section level1" number="10">
<h1>
<span class="header-section-number">10</span> Data Collection<a class="anchor" aria-label="anchor" href="#collect"><i class="fas fa-link"></i></a>
</h1>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:fig10-1"></span>
<img src="img/lifecycle_track.PNG" alt="Data collection in the research project life cycle" width="70%"><p class="caption">
Figure 10.1: Data collection in the research project life cycle
</p>
</div>
<p>When collecting original data as part of your study (i.e., you are administering your own survey or assessment as opposed to using existing data), data management best practices should be interwoven throughout your data collection process. The number one way to ensure the integrity of your data is to spend time planning your data collection efforts. Not only does planning minimize errors, it also keeps your data secure, valid, and relieves future data cleaning headaches.</p>
<p>If you have ever created a data collection instrument and expected it to export data that looks like the image on the left (Figure <a href="collect.html#fig:fig10-2">10.2</a>), but instead you export data that looks like the image on the right, then you know what I mean. Collecting quality data doesn’t just happen because you create an instrument, it takes careful consideration, structure, and care on the part of the entire team.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:fig10-2"></span>
<img src="img/bad_data_collect.PNG" alt="A comparison of data collected without planning and data collected with planning" width="100%"><p class="caption">
Figure 10.2: A comparison of data collected without planning and data collected with planning
</p>
</div>
<div id="quality-assurance-and-control" class="section level2" number="10.1">
<h2>
<span class="header-section-number">10.1</span> Quality assurance and control<a class="anchor" aria-label="anchor" href="#quality-assurance-and-control"><i class="fas fa-link"></i></a>
</h2>
<p>In addition to planning data collection logistics (i.e. how will data be collected, who will collect it, and when), teams should spend time prior to data collection anticipating potential data integrity problems that may arise during data collection and putting procedures in place that will reduce those errors <span class="citation">(<a href="references.html#ref-dime_analytics_data_2021" role="doc-biblioref">DIME Analytics 2021a</a>; <a href="references.html#ref-northern_illinois_university_data_nodate" role="doc-biblioref">Northern Illinois University n.d.</a>)</span>. As shown in Figure <a href="collect.html#fig:fig10-1">10.1</a>, creating data collection instruments is typically a collaborative effort between the project management and data management team members. Even if the project management team builds the tools, the data management team is overseeing that the data collected from the tool aligns with expectations set in the data dictionary. In this chapter we will review two types of practices that both project management and data management team members can implement that will improve the integrity of your data.</p>
<ol style="list-style-type: decimal">
<li>Quality assurance practices that happen before data is collected
<ul>
<li>Best practices associated with designing and building your data collection instruments</li>
</ul>
</li>
<li>Quality control practices implemented during data collection
<ul>
<li>Best practices associated with managing and reviewing data during collection</li>
</ul>
</li>
</ol>
<p>Before we dive into collecting data, it’s important to first review the ethical and legal considerations of your data collection effort. When working with human subjects it is likely that the Institutional Review Board (IRB) will need to review and approve all of your data collection instruments as well as any agreement forms that will be collected as part of your study. Our next section will provide an overview of the IRB and its requirements as well as best practices for creating agreement forms for participants and partners.</p>
</div>
<div id="institutional-review-board" class="section level2" number="10.2">
<h2>
<span class="header-section-number">10.2</span> Institutional Review Board<a class="anchor" aria-label="anchor" href="#institutional-review-board"><i class="fas fa-link"></i></a>
</h2>
<p>The IRB is a formal organization designated to review and monitor human participant research and ensure that the welfare, rights, and privacy of research participants are maintained throughout the project <span class="citation">(<a href="references.html#ref-oregon_state_university_what_2012" role="doc-biblioref">Oregon State University 2012</a>)</span>. If you are conducting education research with human participants you will most likely have some interaction with and oversight from the IRB. Before reviewing potential requirements, let’s review the history of this administrative body.</p>
<div id="background" class="section level3" number="10.2.1">
<h3>
<span class="header-section-number">10.2.1</span> Background<a class="anchor" aria-label="anchor" href="#background"><i class="fas fa-link"></i></a>
</h3>
<p>In 1974 the IRB was established as part of the National Research Act in response to a long history of unethical research that had been conducted with human participants <span class="citation">(<a href="references.html#ref-qiao_brief_2018" role="doc-biblioref">Qiao 2018</a>)</span>. In 1979, the Belmont Report <span class="citation">(<a href="references.html#ref-the_national_commission_for_the_protection_of_human_subjects_of_biomedical_and_behavioral_research_belmont_1979" role="doc-biblioref">The National Commission for the Protection of Human Subjects of Biomedical and Behavioral Research 1979</a>)</span> outlined a set of ethical principles for doing research with human participants. Those ethical principles included the following <span class="citation">(<a href="references.html#ref-duru_institutional_2023" role="doc-biblioref">Duru and Sautmann 2023</a>; <a href="references.html#ref-huisman_3_nodate" role="doc-biblioref">Huisman n.d.</a>)</span>:</p>
<ol style="list-style-type: decimal">
<li>Respect for persons
<ul>
<li>This included both protecting autonomy of participants by acquiring consent as well as providing a plan to protect participant privacy
<ul>
<li>In practice this means acquiring consent in a way that ensures participants can comprehend what is being asked of them, ensuring that they understand that their participation is voluntary, and ensuring that they understand the plan to protect their privacy</li>
</ul>
</li>
</ul>
</li>
<li>Beneficence
<ul>
<li>This involved maximizing good and minimizing harm in the study, for both participants and society at large
<ul>
<li>In practice this means taking time to assess risk and benefits of your study for both the intervention itself as well as the data collection efforts (e.g., how burdensome is the survey)</li>
</ul>
</li>
</ul>
</li>
<li>Justice
<ul>
<li>This included providing additional care and consideration when working with subjects who are vulnerable to coercion or undue influence (e.g., children, prisoners), as well as making sure practices are non-exploitative and that there is fair distribution of costs and benefits across all participants
<ul>
<li>In practice this involves fairness in the selection of participants</li>
</ul>
</li>
</ul>
</li>
</ol>
<p>Heavily influenced by the Belmont Report, in 1991 the Federal Policy for the Protection of Human Subjects was published, establishing core procedures for human subject protections. The policy, 45 CFR part 46 <span class="citation">(<a href="references.html#ref-office_for_human_research_protections_45_2016" role="doc-biblioref">Office for Human Research Protections 2016</a>)</span>, included four subparts. Subpart A, known as the “Common Rule” for the 15 federal departments and agencies which codified the policy in separate regulations, provided a set of protections for human subjects research including informed consent, review by an IRB, and compliance monitoring <span class="citation">(<a href="references.html#ref-national_institute_of_justice_common_2007" role="doc-biblioref">National Institute of Justice 2007</a>; <a href="references.html#ref-office_for_human_research_federal_2009" role="doc-biblioref">Office for Human Research 2009</a>)</span>.</p>
<p>In 2018 the Common Rule was revised in order to better protect research participants and to reduce administrative burden <span class="citation">(<a href="references.html#ref-office_for_human_research_office_for_human_research_revised_2018" role="doc-biblioref">Office for Human Research Office for Human Research 2018</a>; <a href="references.html#ref-us_department_of_health_and_human_services_whats_nodate" role="doc-biblioref">U.S. Department of Health and Human Services n.d.</a>)</span>. While many revisions were made, some changes that are applicable to education researchers include the following <span class="citation">(<a href="references.html#ref-fordham_university_revised_nodate" role="doc-biblioref">Fordham University n.d.</a>)</span>:</p>
<ul>
<li>Revisions and additions to exempt categories, many of which are applicable to research conducted in educational settings</li>
<li>Reduced burden of continuing review, particularly for exempt and expedited studies</li>
<li>Clarifications on how informed consent should be organized, written, and provided</li>
</ul>
</div>
<div id="requirements" class="section level3" number="10.2.2">
<h3>
<span class="header-section-number">10.2.2</span> Requirements<a class="anchor" aria-label="anchor" href="#requirements"><i class="fas fa-link"></i></a>
</h3>
<p>While each institution’s IRB submission process is different, typically if your study involves working with human subjects you are required to submit an application to the IRB. As part of your application you will be asked to state what review category your study falls under <span class="citation">(<a href="references.html#ref-lafayette_college_three_nodate" role="doc-biblioref">Lafayette College n.d.</a>; <a href="references.html#ref-northwestern_university_exempt_nodate" role="doc-biblioref">Northwestern University n.d.</a>; <a href="references.html#ref-university_of_california_berkeley_exempt_2022" role="doc-biblioref">University of California Berkeley 2022</a>)</span>.</p>
<ol style="list-style-type: decimal">
<li>Exempt
<ul>
<li>These studies usually involve minimal risk and fit within categories predefined by your IRB (e.g., evaluating the use of accepted or revised standardized tests). These studies typically involve a shorter review process and a quicker review than non-exempt studies.</li>
</ul>
</li>
<li>Expedited
<ul>
<li>These studies also involve minimal risk but do not meet criteria for exempt status (e.g., collection of voice, video, or image data from non-vulnerable populations).</li>
</ul>
</li>
<li>Full Review
<ul>
<li>If a study does not fall into one of the two categories above (e.g., collection of information about illegal behavior), it requires full review, discussed by the full board at a convened meeting.</li>
</ul>
</li>
</ol>
<p>As part of your application, common documents you may be required to submit include the following <span class="citation">(<a href="references.html#ref-cabrini_university_submissions_nodate" role="doc-biblioref">Cabrini University n.d.</a>; <a href="references.html#ref-duru_institutional_2023" role="doc-biblioref">Duru and Sautmann 2023</a>)</span>:</p>
<ol style="list-style-type: decimal">
<li>Certificates from human subjects training (e.g., CITI training<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;a href="https://about.citiprogram.org/" class="uri"&gt;https://about.citiprogram.org/&lt;/a&gt;&lt;/p&gt;'><sup>51</sup></a>)</li>
<li>Research protocol (see Chapter <a href="document.html#document">7</a>)
<ul>
<li>When writing your protocol, make sure to review your IRB’s rules around data handling and include this information in your plan. IRBs typically have specific rules for things such as how paper and electronic data must be stored and backed up, how long data should be retained, how data can be transferred and shared, and how data should be anonymized <span class="citation">(<a href="references.html#ref-filip_san_2023" role="doc-biblioref">Filip 2023</a>)</span>.</li>
</ul>
</li>
<li>Study materials (e.g., recruitment materials)</li>
<li>Copies of your instruments (e.g., surveys, interview guides, observation forms)
<ul>
<li>Note that these will need to be created before you can submit to your IRB so make sure to consider timing and start building your instruments early enough to give you time to submit to your IRB before data collection</li>
</ul>
</li>
<li>Copy of informed consent/assent forms
<ul>
<li>Same as above, give yourself plenty of time to submit before you start participant recruitment</li>
</ul>
</li>
<li>If collecting data from sites (e.g., school districts) or sharing data between sites, supporting documentation from those partners may be required (MOUs, data use/sharing agreements, letters of support, confidentiality agreements)</li>
<li>If partnering with other institutions, IRB approval letters from partner institutions may also be required</li>
</ol>
<p>The review process can take several weeks and it is common for the IRB to request revisions to materials. Make sure to review your timeline and give yourself plenty of time to work through this process before you need to begin recruitment and data collection.</p>
</div>
<div id="agreements" class="section level3" number="10.2.3">
<h3>
<span class="header-section-number">10.2.3</span> Agreements<a class="anchor" aria-label="anchor" href="#agreements"><i class="fas fa-link"></i></a>
</h3>
<p>There are several types of agreements that may be required for your research study for both ethical and legal reasons. Here we will discuss the most common type of agreements, informed consent and assent, as well as other agreements used when working with external partners including data sharing agreements, memorandum of understanding documents, and confidentiality agreements.</p>
<div id="consent" class="section level4" number="10.2.3.1">
<h4>
<span class="header-section-number">10.2.3.1</span> Consents<a class="anchor" aria-label="anchor" href="#consent"><i class="fas fa-link"></i></a>
</h4>
<p>Informed consent involves obtaining a participant’s voluntary agreement to participate in your research study. As described in the Belmont Report <span class="citation">(<a href="references.html#ref-the_national_commission_for_the_protection_of_human_subjects_of_biomedical_and_behavioral_research_belmont_1979" role="doc-biblioref">The National Commission for the Protection of Human Subjects of Biomedical and Behavioral Research 1979</a>)</span>, informed consent should meet the following criteria <span class="citation">(<a href="references.html#ref-huisman_3_nodate" role="doc-biblioref">Huisman n.d.</a>)</span>:</p>
<ul>
<li>Describe the study and what is expected of the participant</li>
<li>Use accessible language to ensure comprehension. Avoid technical jargon and explain terms that may not be easily understood.</li>
<li>Explain that participation is voluntary</li>
<li>Review how participant privacy will be maintained</li>
</ul>
<p>With the revised Common Rule, additional requirements for informed consent were added <span class="citation">(<a href="references.html#ref-fordham_university_revised_nodate" role="doc-biblioref">Fordham University n.d.</a>)</span>.</p>
<ul>
<li>The top of the consent must begin with a concise review of key information that allows participants to make informed decisions</li>
<li>All information must be presented with sufficient detail to make decisions, not just bulleted lists of facts</li>
<li>The form must disclose any plans to use participant data for other future research</li>
</ul>
<p>Figure <a href="collect.html#fig:fig10-3">10.3</a> shows common elements that are included in a participant consent form <span class="citation">(<a href="references.html#ref-bellevue_college_elements_nodate" role="doc-biblioref">Bellevue College, n.d.</a>; <a href="references.html#ref-the_turing_way_community_turing_2022" role="doc-biblioref">The Turing Way Community 2022</a>)</span>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:fig10-3"></span>
<img src="img/consent.PNG" alt="Common topics to include in an informed consent information sheet" width="100%"><p class="caption">
Figure 10.3: Common topics to include in an informed consent information sheet
</p>
</div>
<p>Depending on the type of research study, a participant signature or a check box denoting consent may be required. If so, it can be helpful to put the above information on a cover/information sheet, and then have a separate page for signed consent. Before signing, participants should be required to acknowledge that they</p>
<ul>
<li>Have read and understood the information provided</li>
<li>Have been given the opportunity to ask questions</li>
<li>Understand that their participation is voluntary</li>
<li>Understand that they may withdraw from the study at any time</li>
</ul>
<p>Not all studies require active consent <span class="citation">(<a href="references.html#ref-university_of_virginia_when_nodate" role="doc-biblioref">University of Virginia n.d.</a>)</span>. Some studies may allow passive consent which may be obtained by providing an information sheet to all participants with the following type of information:</p>
<p><em>If you consent to be in this study, no additional action is required; simply move forward with the study.</em>
<em>If you choose to withdraw, you can notify a specified contact.</em></p>
<p>Your institution’s IRB will let you know which type of consent is required for your study and what language is required.</p>
<div id="data-sharing" class="section level5" number="10.2.3.1.1">
<h5>
<span class="header-section-number">10.2.3.1.1</span> Data sharing<a class="anchor" aria-label="anchor" href="#data-sharing"><i class="fas fa-link"></i></a>
</h5>
<p>With an increase in federal data sharing requirements, it is very important to consider how you want to gain consent for public data sharing. <span class="citation">Meyer (<a href="references.html#ref-meyer_practical_2018" role="doc-biblioref">2018</a>)</span> provides some general best practices to consider when adding language about public data sharing to a consent form.</p>
<ul>
<li>Don’t promise to destroy your data (unless your funder/IRB explicitly requires it)
<ul>
<li>Do incorporate data-retention and sharing plans including letting participants know who will have access to their data</li>
</ul>
</li>
<li>Don’t promise to not share data
<ul>
<li>Do get consent to retain and share data (consider adding the specific repository you plan to share your data in).</li>
<li>Consider offering tiered levels of consent for participants who may not want all of their data publicly shared but will allow some.</li>
</ul>
</li>
<li>Don’t promise that research analyses of the collected data will be limited to certain topics
<ul>
<li>Do say that data may be used for future research and share general purposes (e.g., replication, new analyses)</li>
</ul>
</li>
<li>Do review the ways you plan to de-identify data but be thoughtful when considering risks of re-identification (ex: small sample size for sub-groups)</li>
</ul>
<p>There are essentially three different ways you can go about obtaining consent for data sharing <span class="citation">(<a href="references.html#ref-gilmore_practical_2018" role="doc-biblioref">Gilmore, Kennedy, and Adolph 2018</a>)</span>.</p>
<ol style="list-style-type: decimal">
<li>Include a line about public data sharing in your consent to participate to research.
<ul>
<li>With this method, a participant who consents is agreeing to both participate in the research study and have their data shared publicly.</li>
</ul>
</li>
<li>Have participants consent to data sharing at the same time you provide the research study consent, but provide a separate consent form for the purposes of public data sharing.</li>
<li>Have participants consent to data sharing on a separate consent form, at a later time, after research activities are completed.
<ul>
<li>Obtaining consent this way ensures the participants are fully aware of the data collected from them and can make an informed decision about the future of that data.</li>
</ul>
</li>
</ol>
<p>A limitation of using method 1, as discussed by Gilmore, et al. <span class="citation">(<a href="references.html#ref-gilmore_practical_2018" role="doc-biblioref">2018</a>)</span>, is that if a participant is uncomfortable with their data being publicly shared, you will then also lose them as a study participant. So method 2 or 3 may be your best option. If you choose to go with method 2 or 3, it is very important that you not only track your participant study consent status in your tracking database (as discussed in Chapter <a href="track.html#track">9</a>), but that you also add a field to track the consent status for data sharing so that you only publicly share data for those that have given you permission to do so.</p>
</div>
</div>
<div id="assents" class="section level4" number="10.2.3.2">
<h4>
<span class="header-section-number">10.2.3.2</span> Assents<a class="anchor" aria-label="anchor" href="#assents"><i class="fas fa-link"></i></a>
</h4>
<p>If your study involves participants under the age of 18, you may also be required to obtain a participant assent form, in addition to a parent/guardian consent form. The guidelines for when assent is needed varies across IRBs, but typically if a child is age 7 or older <span class="citation">(<a href="references.html#ref-duru_institutional_2023" role="doc-biblioref">Duru and Sautmann 2023</a>)</span>, both assent and parent consent is needed. While including similar information as provided in the consent, these are usually shorter forms that require much more simplistic language depending on the age of the child.</p>
</div>
<div id="collecting-consent-and-assent" class="section level4" number="10.2.3.3">
<h4>
<span class="header-section-number">10.2.3.3</span> Collecting consent and assent<a class="anchor" aria-label="anchor" href="#collecting-consent-and-assent"><i class="fas fa-link"></i></a>
</h4>
<p>Last, many institutions have started collecting electronic consent rather than paper consents, especially with a rise in remote data collection efforts. There are benefits to this method including reducing the manual labor of collecting paper forms and removing the need to store paper forms or scan them into an electronic form. However, there are still a few things to consider before collecting electronic consent <span class="citation">(<a href="references.html#ref-lee_considerations_2020" role="doc-biblioref">Lee, Hughes, and Marsh 2020</a>; <a href="references.html#ref-malow_redcap-based_2021" role="doc-biblioref">Malow et al. 2021</a>)</span>.</p>
<ul>
<li>Make sure your IRB approves this method</li>
<li>Use institution and IRB approved tools to collect consent (e.g., Qualtrics, DocuSign)</li>
<li>Find out what information is required by your IRB (e.g., signature, typed name, check box, date)</li>
<li>Consider how those consents will be stored (e.g., download PDFs, download spreadsheet, store in collection tool)</li>
</ul>
<p>If you are collecting paper consent or assent, there are still some additional things to consider.</p>
<ul>
<li>If consents are sent out as packets, say to schools, make sure to have a system in place to track who each form belongs to. When consents start coming back, it’s possible that names are illegible, or there are duplicate names across sites. Tracking the origin of each form could look something like this:
<ul>
<li>Collecting class rosters ahead of time and pre-printing names and other identifiers (e.g., teacher, school) on consents before sending packets out (if this is allowed by both your IRB and the school)</li>
<li>Asking teachers to print student and teacher name on each form before the consents/assents are handed out</li>
</ul>
</li>
<li>If consents are collected by in-person data collectors, you will want a similar process
<ul>
<li>Either pre-print names on forms or have data collectors print names and other identifiers (e.g., teacher, school) on forms as they are collected</li>
</ul>
</li>
</ul>
<p><strong>Templates and Resources</strong></p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="42%">
<col width="57%">
</colgroup>
<thead><tr class="header">
<th>Source</th>
<th>Resource</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Anja Sautmann</td>
<td>Annontated informed consent checklist <a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;a href="https://www.povertyactionlab.org/sites/default/files/research-resources/rr_irb_annotated-informed-consent-checklist_0.pdf" class="uri"&gt;https://www.povertyactionlab.org/sites/default/files/research-resources/rr_irb_annotated-informed-consent-checklist_0.pdf&lt;/a&gt;&lt;/p&gt;'><sup>52</sup></a>
</td>
</tr>
<tr class="even">
<td>Holly Lane, Wilhemina van Dijk</td>
<td>Example parent consent <a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;a href="https://www.ldbase.org/system/files/documents/2021-04/HS-ParentConsent.txt" class="uri"&gt;https://www.ldbase.org/system/files/documents/2021-04/HS-ParentConsent.txt&lt;/a&gt;&lt;/p&gt;'><sup>53</sup></a>
</td>
</tr>
<tr class="odd">
<td>Jeffrey Shero, et al.</td>
<td>Informed consent and waiver of consent cheat sheet <a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;a href="https://osf.io/3czbx" class="uri"&gt;https://osf.io/3czbx&lt;/a&gt;&lt;/p&gt;'><sup>54</sup></a>
</td>
</tr>
<tr class="even">
<td>Jeffrey Shero, Sara Hart</td>
<td>Informed consent template with a focus on data sharing <a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;a href="https://figshare.com/articles/preprint/Informed_Consent_Template/13218773" class="uri"&gt;https://figshare.com/articles/preprint/Informed_Consent_Template/13218773&lt;/a&gt;&lt;/p&gt;'><sup>55</sup></a>
</td>
</tr>
<tr class="odd">
<td>Melissa Kline Struhl</td>
<td>Lookit consent form template 5<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;a href="https://github.com/lookit/research-resources/blob/master/Legal/Lookit%20consent%20form%20template%205.md" class="uri"&gt;https://github.com/lookit/research-resources/blob/master/Legal/Lookit%20consent%20form%20template%205.md&lt;/a&gt;&lt;/p&gt;'><sup>56</sup></a>
</td>
</tr>
<tr class="even">
<td>University of Virginia</td>
<td>A collection of consent and assent templates <a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;a href="https://research.virginia.edu/irb-sbs/consent-templates" class="uri"&gt;https://research.virginia.edu/irb-sbs/consent-templates&lt;/a&gt;&lt;/p&gt;'><sup>57</sup></a>
</td>
</tr>
</tbody>
</table></div>
</div>
<div id="other-agreements" class="section level4" number="10.2.3.4">
<h4>
<span class="header-section-number">10.2.3.4</span> Other agreements<a class="anchor" aria-label="anchor" href="#other-agreements"><i class="fas fa-link"></i></a>
</h4>
<p>Data use agreements (DUA) and data sharing agreements (DSA) are two types of documents that lay out expectations for how data will be shared between two or more parties. While the terms data use agreement and data sharing agreement (DSA) are often used interchangeably, I want to differentiate between the two documents <span class="citation">(<a href="references.html#ref-ldbase_data_nodate" role="doc-biblioref">LDbase n.d.a</a>)</span>. Data use agreements are typically legally binding, contractual agreements that provide terms and conditions for working with data that are restricted-use or contain identifiable information, often protected under laws such as HIPAA or FERPA. In addition to describing what data will be shared and a time frame for sharing, DUAs may include information such as the purposes for which the data can be used, data security and safeguarding expectations, and data destruction rules <span class="citation">(<a href="references.html#ref-feeney_using_2021" role="doc-biblioref">Feeney et al. 2021</a>; <a href="references.html#ref-fsu_office_of_research_research_nodate" role="doc-biblioref">FSU Office of Research n.d.</a>; <a href="references.html#ref-geraghty_formalize_2021" role="doc-biblioref">Geraghty and Feeney 2021</a>)</span>. DUAs are commonly written for data sharing when partnering with school districts. In the case of education research, a DUA may include the terms for sharing, working with, and storing identifiable district-level data. In some cases, districts also may require an additional consent form to be completed by parents, specifying the specific records that will be shared, before disclosing education records <span class="citation">(<a href="references.html#ref-university_of_michigan_guidance_2019" role="doc-biblioref">University of Michigan 2019</a>)</span>.</p>
<p>When working with de-identified, non-sensitive data though, a data sharing agreement is a good option. A DSA is a less formal agreement but is still beneficial if you want to provide terms for how data is used, such as limiting the types of projects that use the data or guidelines for citations. We will talk more about these types of agreements in the Chapter <a href="share.html#share">14</a>.</p>
<p>Another type of agreement, commonly signed when working with partners such a school districts, is a memorandum of understanding (MOU), which establishes the framework for collaboration <span class="citation">(<a href="references.html#ref-national_center_for_education_statistics_memoranda_nodate" role="doc-biblioref">National Center for Education Statistics n.d.b</a>; <a href="references.html#ref-rel_west_data_nodate" role="doc-biblioref">REL West, n.d.</a>)</span>. This document is typically not legally binding, but establishes agreements around things such as responsibilities, communication, and expectations <span class="citation">(<a href="references.html#ref-duru_grant_2021" role="doc-biblioref">Duru and Kopper 2021</a>)</span>. An MOU can be a standalone document or can include a DSA or DUA as part of the document.</p>
<p>Last, confidentiality agreements and non-disclosure agreements (NDAs) are other types of agreement that may be needed. These documents restrict the use of proprietary or confidential information <span class="citation">(<a href="references.html#ref-university_of_washington_sharing_nodate" role="doc-biblioref">University of Washington n.d.</a>)</span> and are legally enforceable agreements.</p>
<p><strong>Templates and Resources</strong></p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="42%">
<col width="57%">
</colgroup>
<thead><tr class="header">
<th>Source</th>
<th>Resource</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Amy O’Hara</td>
<td>Sample text for data use agreements <a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;a href="https://admindatahandbook.mit.edu/book/v1.0-rc4/appendix/dua_appendix.pdf" class="uri"&gt;https://admindatahandbook.mit.edu/book/v1.0-rc4/appendix/dua_appendix.pdf&lt;/a&gt;&lt;/p&gt;'><sup>58</sup></a>
</td>
</tr>
<tr class="even">
<td>Florida State University</td>
<td>Example data use agreement <a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;a href="https://www.research.fsu.edu/media/1091/hipaadatause.doc" class="uri"&gt;https://www.research.fsu.edu/media/1091/hipaadatause.doc&lt;/a&gt;&lt;/p&gt;'><sup>59</sup></a>
</td>
</tr>
<tr class="odd">
<td>REL West</td>
<td>Data use agreement checklist <a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;a href="https://ies.ed.gov/ncee/rel/regions/west/relwestFiles/pdf/CRP_Data_Sharing_Agreements_and_MOUs.pdf" class="uri"&gt;https://ies.ed.gov/ncee/rel/regions/west/relwestFiles/pdf/CRP_Data_Sharing_Agreements_and_MOUs.pdf&lt;/a&gt;&lt;/p&gt;'><sup>60</sup></a>
</td>
</tr>
<tr class="even">
<td>University of North Carolina</td>
<td>Data use agreement decision making flow chart <a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;a href="https://research.unc.edu/wp-content/uploads/sites/61/2013/04/CCM3_039360.pdf" class="uri"&gt;https://research.unc.edu/wp-content/uploads/sites/61/2013/04/CCM3_039360.pdf&lt;/a&gt;&lt;/p&gt;'><sup>61</sup></a>
</td>
</tr>
<tr class="odd">
<td>Wilhelmina van Dijk, Sara Hart</td>
<td>Example data sharing agreement <a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;a href="https://figshare.com/articles/preprint/Example_Data_Sharing_Agreement/14576049" class="uri"&gt;https://figshare.com/articles/preprint/Example_Data_Sharing_Agreement/14576049&lt;/a&gt;&lt;/p&gt;'><sup>62</sup></a>
</td>
</tr>
</tbody>
</table></div>
</div>
</div>
</div>
<div id="quality-assurance" class="section level2" number="10.3">
<h2>
<span class="header-section-number">10.3</span> Quality Assurance<a class="anchor" aria-label="anchor" href="#quality-assurance"><i class="fas fa-link"></i></a>
</h2>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:fig10-4"></span>
<img src="img/data_collected7.PNG" alt="Common education research data collection methods" width="100%"><p class="caption">
Figure 10.4: Common education research data collection methods
</p>
</div>
<p>Now that we have a baseline understanding of ethical and legal considerations, we can dive in to protecting data quality during data collection. Education researchers collect original data in many ways (see Figure <a href="collect.html#fig:fig10-4">10.4</a>). The focus of this chapter will be on data collected via forms (i.e., a document with spaces to respond to questions). Forms are widely used to collect data in education research (think surveys, assessments, observation forms, or a progress monitoring form on a website), yet if developed poorly, they can produce some of the most problematic data issues. On the flip side, if the practices discussed in this chapter are implemented, forms can also be the easiest tool to remedy issues with.</p>
<p>The focus on forms is not to discount the importance of data collected through other means such as video or audio recording, where issues such as participant privacy and data security and integrity should absolutely also be considered. However, even with those types of data collection efforts, often teams are ultimately still coding that data using some sort of form (e.g., observation form), further supporting the need to build forms that collect quality data.</p>
<p>When collecting information using forms you can certainly do your best to fix data errors after data collection during a cleaning process. However, one of the most effective ways to ensure quality data is to correct it at the source. This means designing items and building data collection tools in a way that produces valid, reliable, and more secure data. When creating your original data collection instruments, there are four ways to collect higher quality data.</p>
<ol style="list-style-type: decimal">
<li>Using good questionnaire design principles</li>
<li>Implementing a series of pilot test</li>
<li>Choosing data collection tools that meet your needs</li>
<li>Building your instrument with the end in mind</li>
</ol>
<p>We will discuss each of these phases below.</p>
<blockquote>
<p><strong>Note</strong> <br><br>
If you are collecting data using a standardized assessment, along with a provided instrument (e.g., a computer-adaptive testing program), most of the information in this section will not be applicable. In those situations, it is best to adhere to all guidelines provided by the assessment company.</p>
</blockquote>
<div id="questionnaire-design" class="section level3" number="10.3.1">
<h3>
<span class="header-section-number">10.3.1</span> Questionnaire design<a class="anchor" aria-label="anchor" href="#questionnaire-design"><i class="fas fa-link"></i></a>
</h3>
<p>In Chapter <a href="document.html#document">7</a> we discussed the importance of documenting all instrument items in your data dictionary before creating your data collection instruments. As you develop items to add to your data dictionary, it is vital to consider questionnaire design.</p>
<p>While some instruments (e.g., cognitive assessments) typically have standardized items, other instruments, such as surveys, are often not predefined, allowing researchers freedom in the design of the instrument which can lead to negative effects such as errors, bias, and potential harm <span class="citation">(<a href="references.html#ref-dime_analytics_data_2021" role="doc-biblioref">DIME Analytics 2021a</a>; <a href="references.html#ref-northern_illinois_university_data_nodate" role="doc-biblioref">Northern Illinois University n.d.</a>)</span>. Question ordering, response option ordering, question wording, and more can all impact participant responses. While questionnaire design is actually outside of the scope of this book, I have a few tips to help you collect more valid, reliable, and ethical survey data. In addition to following these tips, make sure to consult a methodologist when designing your questionnaire.</p>
<ol style="list-style-type: decimal">
<li>Use existing standards if possible
<ul>
<li>Organizations such as the <span class="citation">National Institutes of Health (<a href="references.html#ref-national_institutes_of_health_common_nodate" role="doc-biblioref">n.d.b</a>)</span> and the <span class="citation">National Center for Education Statistics (<a href="references.html#ref-national_center_for_education_statistics_common_nodate" role="doc-biblioref">n.d.a</a>)</span> have developed repositories (Common Data Elements<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;a href="https://www.nlm.nih.gov/oet/ed/cde/tutorial/03-100.html" class="uri"&gt;https://www.nlm.nih.gov/oet/ed/cde/tutorial/03-100.html&lt;/a&gt;&lt;/p&gt;'><sup>63</sup></a> and Common Education Data Standards<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;a href="https://ceds.ed.gov/" class="uri"&gt;https://ceds.ed.gov/&lt;/a&gt;&lt;/p&gt;'><sup>64</sup></a>) of standardized question wording paired with a set of allowable response options for commonly used data elements. Using standards when collecting commonly used variables, such as demographics, provides the following benefits <span class="citation">(<a href="references.html#ref-icpsr_introduction_2022" role="doc-biblioref">ICPSR 2022</a>; <a href="references.html#ref-kush_fair_2020" role="doc-biblioref">Kush et al. 2020</a>)</span>:
<ul>
<li>Reduces bias</li>
<li>Allows for harmonization of data across your own research studies and also across the field
<ul>
<li>This allows researchers to draw conclusions using larger samples or by comparing data over time</li>
<li>It also reduces the costs of integrating datasets</li>
</ul>
</li>
<li>Improves interpretation of information</li>
</ul>
</li>
</ul>
</li>
<li>Make sure questions are clearly worded and answer choices are clear and comprehensive
<ul>
<li>Consider how the language might be interpreted. Is the question wording confusing? Can the response options be misinterpreted?
<ul>
<li>Rather than asking “What county are you from?” when looking for the participant’s current location, be more specific and ask “What county do you currently reside in?”</li>
<li>Rather than asking “Which parent are you?” and providing the response options “m” and “f”, where “m” and “f” could be interpreted as “male” or “female”, clearly write out the response options and make sure they are comprehensive (mother, father, legal guardian, and so forth)</li>
<li>Is the question leading/biased?
<ul>
<li>Are the response options ordered in a leading way?</li>
</ul>
</li>
<li>Is there no one way to answer this question?
<ul>
<li>Are response categories mutually exclusive and exhaustive <span class="citation">(<a href="references.html#ref-icpsr_guide_nodate" role="doc-biblioref">ICPSR n.d.a</a>)</span>?</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Consider data ethics in your questionnaire design <span class="citation">(<a href="references.html#ref-gaddy_principles_2020" role="doc-biblioref">Gaddy and Scott 2020</a>; <a href="references.html#ref-kaplowitz_5_2020" role="doc-biblioref">Kaplowitz and Johnson 2020</a>; <a href="references.html#ref-kopper_survey_2021" role="doc-biblioref">Kopper and Parry 2021</a>; <a href="references.html#ref-mathematica_tips_nodate" role="doc-biblioref">Mathematica n.d.</a>; <a href="references.html#ref-narvaiz_data_nodate" role="doc-biblioref">Narvaiz n.d.</a>)</span>
<ul>
<li>Consider the why of each item and tie your questions to outcomes
<ul>
<li>Don’t cause undue burden on participants by collecting more data just to have more data</li>
<li>If collecting demographic information, provide an explanation of why that information is necessary and how it will be used in your research</li>
</ul>
</li>
<li>Review question wording
<ul>
<li>Does it have potential to do harm to participants? Do the benefits outweigh the risks?</li>
<li>If sensitive questions are included, make sure to discuss how you will protect respondent’s information</li>
</ul>
</li>
<li>Make questions inclusive of the population while also capturing the categories relevant for research
<ul>
<li>If a question is multiple choice, still include an “other” option with an open-text field</li>
<li>For demographic information, allow participants to select more than one option</li>
</ul>
</li>
<li>Consider including one general free-text field in your survey to allow participants to provide additional information that they feel was not captured elsewhere</li>
</ul>
</li>
<li>Limit the collection of personally identifiable information (PII)
<ul>
<li>Collecting identifiable information is a balancing act between protecting participant confidentiality and collecting the information necessary to implement a study. We often need to collect some identifying information either for the purposes of record linking or for purposes related to study outcomes (e.g., scoring an assessment based on participant’s age).</li>
<li>As a general rule, you only want to collect PII that is absolutely necessary for your project, and no more <span class="citation">(<a href="references.html#ref-gaddy_principles_2020" role="doc-biblioref">Gaddy and Scott 2020</a>)</span>. As discussed in Chapter <a href="rdm.html#rdm">2</a>, PII can include both direct identifiers (e.g., name or email) as well as indirect identifiers (e.g., birthdate). Before sharing your data, all PII will need to be removed or altered to protect confidentiality.</li>
</ul>
</li>
</ol>
<p><strong>Survey Design Resources</strong></p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="42%">
<col width="57%">
</colgroup>
<thead><tr class="header">
<th>Source</th>
<th>Resource</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Sarah Kopper, Katie Parry</td>
<td>Survey design <a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;a href="https://www.povertyactionlab.org/resource/survey-design" class="uri"&gt;https://www.povertyactionlab.org/resource/survey-design&lt;/a&gt;&lt;/p&gt;'><sup>65</sup></a>
</td>
</tr>
<tr class="even">
<td>Pew Research Center</td>
<td>Writing survey questions <a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;a href="https://www.pewresearch.org/our-methods/u-s-surveys/writing-survey-questions/" class="uri"&gt;https://www.pewresearch.org/our-methods/u-s-surveys/writing-survey-questions/&lt;/a&gt;&lt;/p&gt;'><sup>66</sup></a>
</td>
</tr>
<tr class="odd">
<td>Stefanie Stantcheva</td>
<td>How to run surveys: A guide to creating your own identifying variation and revealing the invisible <a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;a href="https://www.nber.org/system/files/working_papers/w30527/w30527.pdf" class="uri"&gt;https://www.nber.org/system/files/working_papers/w30527/w30527.pdf&lt;/a&gt;&lt;/p&gt;'><sup>67</sup></a>
</td>
</tr>
<tr class="even">
<td>World Bank</td>
<td>Survey content-focused pilot checklist <a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;a href="https://dimewiki.worldbank.org/Checklist:_Content-focused_Pilot" class="uri"&gt;https://dimewiki.worldbank.org/Checklist:_Content-focused_Pilot&lt;/a&gt;&lt;/p&gt;'><sup>68</sup></a>
</td>
</tr>
</tbody>
</table></div>
</div>
<div id="pilot-the-instrument" class="section level3" number="10.3.2">
<h3>
<span class="header-section-number">10.3.2</span> Pilot the instrument<a class="anchor" aria-label="anchor" href="#pilot-the-instrument"><i class="fas fa-link"></i></a>
</h3>
<p>Gathering feedback on your instruments is an integral part to the quality assurance process. There are three phases to piloting an instrument <span class="citation">(<a href="references.html#ref-dime_analytics_survey_2021" role="doc-biblioref">DIME Analytics 2021b</a>)</span> (see Figure <a href="collect.html#fig:fig10-5">10.5</a>):</p>
<ol style="list-style-type: decimal">
<li>Gathering internal feedback on items
<ul>
<li>As discussed in Chapter <a href="document.html#document">7</a>, once all items for each instrument have been added to your data dictionary, have your team review the data dictionary and provide feedback</li>
</ul>
</li>
<li>Piloting an instrument for content
<ul>
<li>Once the team has approved the items to be collected, the second phase of piloting can begin. Create a printable draft of your instrument that can be shared with people in your study population and gather feedback</li>
<li>If you are piloting your instrument with a small population (N &lt; 10), and you are either gathering feedback from a checklist or collecting data using the instrument with no intent to disseminate outcomes as research data, then IRB approval will most likely not be required <span class="citation">(<a href="references.html#ref-cornell_university_irb_2019" role="doc-biblioref">Cornell University 2019</a>; <a href="references.html#ref-stanford_university_use_nodate" role="doc-biblioref">Stanford University n.d.</a>)</span>. With that said, you should always consult with your institution’s IRB because rules can vary.</li>
</ul>
</li>
<li>Piloting the instrument for data related issues
<ul>
<li>Once the instrument is created in your chosen data collection tool, share the instrument with your team for review</li>
<li>Here we are most interested in whether or not the data we are collecting are accurate, comprehensive, and usable</li>
<li>We will discuss this phase in greater detail in Section <a href="collect.html#collect-build">10.3.4</a>
</li>
</ul>
</li>
</ol>
<p>Last, as you move through the piloting phases, remember to update any changes not only in your tool but also in your data dictionary and any other relevant documentation.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:fig10-5"></span>
<img src="img/pilot2.PNG" alt="Data collection instrument pilot phases" width="100%"><p class="caption">
Figure 10.5: Data collection instrument pilot phases
</p>
</div>
</div>
<div id="choose-quality-data-collection-tools" class="section level3" number="10.3.3">
<h3>
<span class="header-section-number">10.3.3</span> Choose quality data collection tools<a class="anchor" aria-label="anchor" href="#choose-quality-data-collection-tools"><i class="fas fa-link"></i></a>
</h3>
<p>Once content piloting is completed, teams should be ready to begin building their instruments in their data collection tools (see Figure <a href="collect.html#fig:fig10-4">10.4</a>). Research teams may be restricted in the tools they use to collect their data for a variety of reasons including limited resources, research design, the population being studied, or the chosen instrument (e.g., an existing assessment can only be collected using a provided tool). However, if you have the flexibility to choose how you collect your data, pick a tool that meets the various needs of your project while also providing data quality and security controls. Things to consider when choosing a data collection tool are:</p>
<ol style="list-style-type: decimal">
<li>Pick the tool that meets the needs of your project
<ul>
<li>Is crowdsourcing required?</li>
<li>Is multi-site access required?</li>
<li>Who is entering the data (i.e., data collectors, participants)?
<ul>
<li>If participants are entering data, is the tool accessible for your population?</li>
</ul>
</li>
<li>What are the technical requirements for the tool (i.e., will internet be available if you plan to use a web-based tool)?</li>
<li>Does the tool have customizable features that are necessary for your instrument (e.g., branching logic, automated email reminders, options to embed data, options to calculate scores in the tool)?</li>
</ul>
</li>
<li>Compliance and security
<ul>
<li>If you collect identifiable data, is the tool HIPAA compliant? FERPA compliant? (see Chapter <a href="rdm.html#rdm">2</a> for more information about these regulations)</li>
<li>Is the tool approved by your institution?</li>
<li>If collecting anonymous data, do you have the option to anonymize responses in the tool (e.g., remove IP Address and other identifying metadata collected by the tool)?</li>
</ul>
</li>
<li>Training needed
<ul>
<li>Is any additional team training needed to allow your team to use and/or build instruments in the tool?</li>
</ul>
</li>
<li>Associated costs
<ul>
<li>Is there a cost associated with the tool? Do you have the budget for the tool?</li>
<li>Will there be additional costs down the line (e.g., collecting data on paper means someone will need to hand enter the data later)?</li>
</ul>
</li>
<li>Data quality features
<ul>
<li>Does the tool allow you to set up data validation?</li>
<li>Does the tool have version control?</li>
<li>Does the tool have features to deal with fraud/bots?</li>
</ul>
</li>
</ol>
<p>While there are a variety of tool options, in a nutshell when it comes to data collected via forms, we are collecting data in one of two ways—electronic or paper. In addition to choosing tools based on the above criteria, there are some general benefits associated with each method that should also be considered <span class="citation">(<a href="references.html#ref-cohen_research_2007" role="doc-biblioref">Cohen, Manion, and Morrison 2007</a>; <a href="references.html#ref-douglas_data_2023" role="doc-biblioref">Douglas, Ewell, and Brauer 2023</a>; <a href="references.html#ref-gibson_data_2021" role="doc-biblioref">Gibson 2021</a>; <a href="references.html#ref-icpsr_guide_nodate" role="doc-biblioref">ICPSR n.d.a</a>; <a href="references.html#ref-malow_redcap-based_2021" role="doc-biblioref">Malow et al. 2021</a>; <a href="references.html#ref-society_of_critical_care_medicine_building_2018" role="doc-biblioref">Society of Critical Care Medicine 2018</a>; <a href="references.html#ref-van_bochove_data_nodate" role="doc-biblioref">Bochove, Alper, and Gu n.d.</a>)</span>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:fig10-6"></span>
<img src="img/collect_benefits2.PNG" alt="Comparison of data collection tool benefits" width="100%"><p class="caption">
Figure 10.6: Comparison of data collection tool benefits
</p>
</div>
<blockquote>
<p><strong>Note</strong> <br><br>
If you choose to collect data in an electronic format, I highly recommend using a web-based tool that directly feeds into a shared database rather than through offline tools that store data on individual devices. Using a web-based tool, all data is stored remotely in the same database and can be easily downloaded or connected to at any time. No additional work is required. <br><br>
However, when collecting data on various tablets in the field, if the forms are offline and cannot be later connected to a web-based form, then all data will be stored individually on each tablet. This not only may be less secure (e.g., a tablet becomes corrupted), it may also require additional data wrangling work including downloading data from each tablet to a secure storage location each day and then combining all files into a single dataset. If you use an electronic tool but your site does not have internet, consider using one of the many tools (e.g., Qualtrics, SurveyCTO) that allow you to collect data using their offline app and then upload that data back to the platform once you have an internet connection again.</p>
</blockquote>
<p><strong>Tool Comparison Resources</strong></p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="42%">
<col width="57%">
</colgroup>
<thead><tr class="header">
<th>Source</th>
<th>Resource</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Michael Gibson, Wim Louw</td>
<td>Survey platform comparison<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;a href="https://www.povertyactionlab.org/resource/survey-programming" class="uri"&gt;https://www.povertyactionlab.org/resource/survey-programming&lt;/a&gt;&lt;/p&gt;'><sup>69</sup></a>
</td>
</tr>
<tr class="even">
<td>Washington State University Libraries</td>
<td>Software for sensitive data<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;a href="https://libguides.libraries.wsu.edu/rdmlibguide/ethics" class="uri"&gt;https://libguides.libraries.wsu.edu/rdmlibguide/ethics&lt;/a&gt;&lt;/p&gt;'><sup>70</sup></a>
</td>
</tr>
<tr class="odd">
<td>Benjamin Douglas, et al.</td>
<td>Data quality in online human-subjects research comparison of tools<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0279720" class="uri"&gt;https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0279720&lt;/a&gt;&lt;/p&gt;'><sup>71</sup></a>
</td>
</tr>
</tbody>
</table></div>
</div>
<div id="collect-build" class="section level3" number="10.3.4">
<h3>
<span class="header-section-number">10.3.4</span> Build with the end in mind<a class="anchor" aria-label="anchor" href="#collect-build"><i class="fas fa-link"></i></a>
</h3>
<p>Last, you want to build your tool with the end in mind. This means taking time to consider how the data you collect will be translated into a dataset <span class="citation">(<a href="references.html#ref-beals_data_2014" role="doc-biblioref">Beals and Schectman 2014</a>; <a href="references.html#ref-lewis_how_2022" role="doc-biblioref">Lewis 2022b</a>; <a href="references.html#ref-uk_data_service_quality_2023" role="doc-biblioref">UK Data Service 2023b</a>)</span>. Recall from Chapter <a href="structure.html#structure">3</a>, we ultimately need our data to be in a rectangular format, organized according to the basic data organization rules, in order to be analyzable.</p>
<p>The process for building your tools with the end in mind is fairly different for electronic tools compared to paper forms so we are going to talk about these two processes separately.</p>
<div id="electronic-data-collection" class="section level4" number="10.3.4.1">
<h4>
<span class="header-section-number">10.3.4.1</span> Electronic data collection<a class="anchor" aria-label="anchor" href="#electronic-data-collection"><i class="fas fa-link"></i></a>
</h4>
<p>The first thing you will want to do before building your tool is bring out your data dictionary. This data dictionary will be your guide as you build your instrument. Some tools, such as REDCap, provide the option to upload your data dictionary which can then be used to automate the creation of data collection forms as opposed to building them from scratch <span class="citation">(<a href="references.html#ref-patridge_research_2018" role="doc-biblioref">Patridge and Bardyn 2018</a>)</span>.</p>
<p>However, if you are building your instrument manually, adhering to the following guidelines will ensure you collect data that is easier to interpret and more usable, and it will also reduce the amount of time you will need to spend on future data cleaning <span class="citation">(<a href="references.html#ref-lewis_how_2022" role="doc-biblioref">Lewis 2022b</a>)</span>.</p>
<ol style="list-style-type: decimal">
<li>Name all of your items the correct variable name from your data dictionary <span class="citation">(<a href="references.html#ref-uk_data_service_quality_2023" role="doc-biblioref">UK Data Service 2023b</a>)</span>
<ul>
<li>For example, instead of using the platform default name of “Q2”, rename the item to “tch_years”</li>
<li>As we mentioned in Chapter <a href="style.html#style">8</a>, it’s also best to not concatenate a time component to your variable names if your project is longitudinal. Doing so makes it difficult to reuse your instrument for other time periods, creating additional work for you or your team.</li>
</ul>
</li>
<li>Code all values as they are in your data dictionary
<ul>
<li>For example, 1 = “strongly agree”, 2 = “agree”, 3 = “disagree”, 4 = “strongly disagree”</li>
<li>Many times tools assign a default value to your response options and these values may not align with what you’ve designated in your data dictionary</li>
<li>As you edit your survey, continue to check that your coded values did not change due to reordering, removal, or addition of new response options</li>
</ul>
</li>
<li>Use data validation to reduce errors and missing data <span class="citation">(<a href="references.html#ref-uk_data_service_quality_2023" role="doc-biblioref">UK Data Service 2023b</a>)</span>
<ul>
<li>Content validation for open-text boxes
<ul>
<li>Restrict entry to the type assigned in your data dictionary (e.g., numeric)</li>
<li>Restrict entry to the format assigned in your data dictionary (e.g., YYYY-MM-DD)</li>
<li>Restrict ranges based on allowable ranges in your data dictionary (e.g., 1-50)
<ul>
<li>This could even include validating against previous responses (e.g., if SchoolA was selected in a previous question, grade level should be between 6-8, if SchoolB was selected, grade level should be between 7-8)</li>
</ul>
</li>
</ul>
</li>
<li>Response validation
<ul>
<li>Consider the use of forced-response and request-response options to reduce missing data
<ul>
<li>Forced-response options do not allow participants to move forward without completing an item. Request-response options notify a respondent if they skip a question and ask if they still would like to move forward without responding</li>
<li>Be aware that adding a forced-response option to sensitive questions has the potential to be harmful and produce bad data. If adding a forced-response option to a sensitive question, consider allowing those participants to opt-out in another way (e.g., “Prefer not to answer”).</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Choose an appropriate type and format to display the item
<ul>
<li>Become familiar with the various questions types available in your tool (e.g., rank order, multiple choice, text box, slider scale)</li>
<li>Become familiar with the various formats (e.g., radio button, drop-down, checkbox)</li>
<li>For example, if your item is a rank order question (ranking 3 items), creating this question as a multi-line, free-text entry form may lead to duplicate entries (such as entering a rank of 1 more than once). However, using something like a rank order question type with a drag and drop format ensures that participants are not allowed to duplicate rankings.</li>
</ul>
</li>
<li>If there is a finite number of response options for an item, and the number isn’t too large (less than ~ 20) use controlled vocabularies (i.e., a pre-defined list of values) rather than an open-text field <span class="citation">(<a href="references.html#ref-openaire_eu_basics_2018" role="doc-biblioref">OpenAIRE_eu 2018</a>; <a href="references.html#ref-uk_data_service_quality_2023" role="doc-biblioref">UK Data Service 2023b</a>)</span>
<ul>
<li>For example, list school name as a drop-down item rather than having participants enter a school name
<ul>
<li>This prevents variation in text entry (e.g., “Sunvalley Middle”, “sunvalley”, “Snvally Middle”), which ultimately creates unnecessary data cleaning work and may even lead to unusable values</li>
</ul>
</li>
</ul>
</li>
<li>If there is an infinite number of response options for an item or the number of options is large, use an open-text box
<ul>
<li>If you can create a searchable field in your tool, allowing your participants to easily sift through all of the options, you absolutely should. Otherwise, use a text-box as opposed to having participants scroll through a large list of options</li>
<li>Consider adding examples of possible response options to clarify what you are looking for</li>
<li>Using open-ended text boxes does not mean you cannot regroup this information into categories later during a cleaning process. It is just more time-consuming and requires interpretation and decision-making on the part of the data cleaner</li>
</ul>
</li>
<li>Only ask for one piece of information per question
<ul>
<li>For example, rather than asking “Please list the number of students in your algebra class and geometry class”, split those into two separate questions so those questions download as two separate items in your dataset</li>
<li>This also includes more simple examples such as splitting first name and last name into two separate fields</li>
<li>This prevents confusion in case a participant or data collector swaps the order of information</li>
</ul>
</li>
<li>To protect participant privacy and ensure the integrity of data, consider adding a line to the introduction of your web-based instrument, instructing participants to close their browser upon completion so that others may not access their responses</li>
<li>Last, if possible, export the instrument to a human-readable document to perform final checks
<ul>
<li>Are all questions accounted for?</li>
<li>Are all response options accounted for and coded as they should be?</li>
<li>Is skip logic shown as expected?</li>
</ul>
</li>
</ol>
<p>Once your tool is created, the last step is to pilot for data issues (see Figure <a href="collect.html#fig:fig10-5">10.5</a>). Collect sample responses from team members. Create a feedback checklist for them to complete as they review the instrument <span class="citation">(<a href="references.html#ref-gibson_survey_2020" role="doc-biblioref">Gibson and Louw 2020</a>)</span>. Assign different reviewers to enter the survey using varying criteria (e.g., different schools, different grade levels). Let team members know that they should actively try to break things <span class="citation">(<a href="references.html#ref-kopper_questionnaire_2020" role="doc-biblioref">Kopper and Parry 2020</a>)</span>. Try to enter nonsensical values, try to skip items, try to enter duplicate entries. If there are problems with the tool, now is the time to find out.</p>
<p>After sample responses are collected from team members, export the sample data and review the data for the following:</p>
<ol style="list-style-type: decimal">
<li>Are there any unexpected or missing variables?</li>
<li>Are there any unexpected variable names?</li>
<li>Are there unexpected values for variables?</li>
<li>Are there missing values where you expect data?</li>
<li>Are there unexpected variable formats?</li>
<li>Is data exporting in an analyzable, rectangular format?</li>
</ol>
<p>If any issues are found either through team feedback or while reviewing the exported sample data, take time to update the tool as well as your documentation as needed before starting data collection.</p>
</div>
<div id="paper-data-collection" class="section level4" number="10.3.4.2">
<h4>
<span class="header-section-number">10.3.4.2</span> Paper data collection<a class="anchor" aria-label="anchor" href="#paper-data-collection"><i class="fas fa-link"></i></a>
</h4>
<p>There are many situations where collecting data electronically may not be feasible or the best option for your project. While it is definitely trickier to design a paper tool in a way that prevents bad data, there are still steps you can take to improve data quality.</p>
<ol style="list-style-type: decimal">
<li>Use your data dictionary as a guide as you create your paper form
<ul>
<li>Make sure all questions are included and all response options are accurately added to the form</li>
</ul>
</li>
<li>Have clear instructions for how to complete the paper form <span class="citation">(<a href="references.html#ref-kopper_survey_2021" role="doc-biblioref">Kopper and Parry 2021</a>)</span>
<ul>
<li>Make sure to not only have overall instructions at the top of the form but also have explicit instructions for how each question should be completed
<ul>
<li>Where to write answers (e.g., not in the margin)</li>
<li>How answers should be recorded (e.g., YYYY-MM-DD, or 3 digit number)</li>
<li>How many answers should be recorded (e.g., circle only one answer, check all applicable boxes)</li>
<li>How to navigate item skip logic (e.g., include visual arrows)</li>
</ul>
</li>
</ul>
</li>
<li>Only ask for one piece of information per question to reduce confusion in interpretation</li>
</ol>
<p>Once your tool is created, you will want to pilot the instrument with your team for data issues (see Figure <a href="collect.html#fig:fig10-5">10.5</a>). Using the feedback collected, edit your tool as needed before sending it out into the field.</p>
<p>Last, all data that is collected on paper will need to be entered into an electronic format. While we will talk about data entry specifically in Chapter <a href="capture.html#capture">11</a>, this point in instrument creation is a great time to create an annotated instrument that can be used for future data entry <span class="citation">(<a href="references.html#ref-neild_sharing_2022" role="doc-biblioref">Neild, Robinson, and Agufa 2022</a>)</span>. This includes taking a copy of your instrument and writing the associated codes alongside each item (i.e., variable name, value codes). This can be useful during the data entry process and serve as a linking key between your instrument and your data dictionary (see Figure <a href="collect.html#fig:fig10-7">10.7</a>) <span class="citation">(<a href="references.html#ref-hart_florida_2018" role="doc-biblioref">Hart, Schatschneider, and Taylor 2018</a>)</span>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:fig10-7"></span>
<img src="img/annotated_instrument.PNG" alt="Annotated instrument from The Florida State Twin Registry project" width="80%"><p class="caption">
Figure 10.7: Annotated instrument from The Florida State Twin Registry project
</p>
</div>
<p>Another option for capturing paper data in an electronic format is using TeleForm rather than paper. These forms are designed to be scanned by machines. Using TeleForm removes the extra step of future data entry and errors associated with human entry.</p>
</div>
<div id="identifiers" class="section level4" number="10.3.4.3">
<h4>
<span class="header-section-number">10.3.4.3</span> Identifiers<a class="anchor" aria-label="anchor" href="#identifiers"><i class="fas fa-link"></i></a>
</h4>
<p>When building data collection tools, no matter if they are paper or electronic, it is vitally important to make sure you are collecting unique identifiers <span class="citation">(<a href="references.html#ref-kopper_survey_2021" role="doc-biblioref">Kopper and Parry 2021</a>)</span>. Whether you have participants enter a unique identifier into a form or you link study ID to each form in some other way, it’s important to not accidentally collect anonymous data. Without unique identifiers in your data, you will be unable to link data across time and forms. If possible, you want to avoid collecting names as unique identifiers for the following reasons <span class="citation">(<a href="references.html#ref-mckenzie_falsehoods_2010" role="doc-biblioref">McKenzie 2010</a>)</span>:</p>
<ul>
<li>To protect confidentiality we want to use names as little as possible on forms
<ul>
<li>If they are used on forms, we want to remove them as soon as possible</li>
</ul>
</li>
<li>Names are not unique
<ul>
<li>If you do collect names, you’ll want to ask for additional identifying information that when combined, make a participant unique (e.g., student name and email)</li>
</ul>
</li>
<li>Names change (e.g., someone gets married/divorced)</li>
<li>There is too much room for error
<ul>
<li>If names are hand entered, there are endless issues with case sensitivity, spelling errors, special characters, spacing, and so forth</li>
</ul>
</li>
</ul>
<p>All of the above issues make it very difficult to link data. If you do decide to collect names, remember that you will need to remove names during data processing and replace them with your unique study identifiers.</p>
<p>Figure <a href="collect.html#fig:fig10-8">10.8</a> shows what a data de-identification process looks like <span class="citation">(<a href="references.html#ref-otoole_data_2018" role="doc-biblioref">O’Toole et al. 2018</a>)</span>. Dataset 1 would be the incoming survey data with identifiers, Dataset 2 would be a roster exported from your participant database (see Chapter <a href="track.html#track">9</a>), and Dataset 3 is your clean, de-identified dataset, created by merging Dataset 1 with Dataset 2 on your unique identifier and dropping your identifying variables. I want to emphasize the importance of using a “merge” which we will discuss more in Chapter <a href="clean.html#clean">13</a>, as opposed to replacing names with IDs by hand entering identifiers. If at all possible, we want to completely avoid hand entry of study IDs. Hand entry is error-prone and can lead to many mistakes.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:fig10-8"></span>
<img src="img/de-identify.PNG" alt="Process of creating a de-identified dataset" width="90%"><p class="caption">
Figure 10.8: Process of creating a de-identified dataset
</p>
</div>
<p>Rather than having to de-identify your data through this cleaning process, another option is to collect a different type of unique identifier, or pre-link unique study identifiers and names in your instrument, removing many of the issues above <span class="citation">(<a href="references.html#ref-dime_analytics_data_2021" role="doc-biblioref">DIME Analytics 2021a</a>; <a href="references.html#ref-gibson_survey_2020" role="doc-biblioref">Gibson and Louw 2020</a>)</span>. We will discuss these methods separately for electronic data and paper data.</p>
<blockquote>
<p><strong>Note</strong> <br><br>
If your study is designed to collect anonymous data, then you will not assign study identifiers and no participant identifying information should be collected in your instruments (e.g., name, email, date of birth). You will also want to make sure that if your tool collects identifying metadata such as IP Address or worker IDs in the case of crowdsourcing tools (e.g., MTurk), this information will not be included in your downloaded data. <br><br>
Remember that if you collect anonymous data, you will not be able to link data across measures or across time. However, if your study randomizes participants by an entity (e.g., school or district), you will need to collect identifying information from that entity in order to cluster on that information (e.g., school name).</p>
</blockquote>
<div id="electronic-data" class="section level5" number="10.3.4.3.1">
<h5>
<span class="header-section-number">10.3.4.3.1</span> Electronic Data<a class="anchor" aria-label="anchor" href="#electronic-data"><i class="fas fa-link"></i></a>
</h5>
<p>There are many ways you might consider collecting unique identifiers other than names. A few possible options are provided below. The method you choose will depend on your data collection design, your participant population, your tool capabilities, and your team expertise.</p>
<ol style="list-style-type: decimal">
<li>Create unique links for participants
<ul>
<li>Many tools will allow you to preload a contact list of participants (from your participant database) that includes both their names and study IDs. Using this list, the tool can create unique links for each participant. This is the most error-proof way to ensure study IDs are entered correctly.</li>
<li>When you export your data, the correct ID is already linked to each participant and you can choose to not export names in the data.</li>
<li>If using this method, make sure to build a data check into the system. When a participant opens their unique link, verify their identity by asking, “Are you {first name}?” or “Are your initials {initials}?”. In order to protect other participant identities, do not share full names.
<ul>
<li>If they say yes, they move forward. If they say no, the system redirects them to someone to contact. This ensures that participants are not completing someone else’s survey and IDs are connected to the correct participant.</li>
</ul>
</li>
</ul>
</li>
<li>Provide one link to all participants and separately, in an email, in person, or by mail, provide participants with their study ID to enter into the system.
<ul>
<li>This might be a preferred method if you are collecting data in a computer lab or on tablets at a school site, or if your tool does not have the option to create unique links</li>
<li>This can possibly introduce error if a participant enters their study ID incorrectly.
<ul>
<li>Similar to the first option, after a participant enters their ID, verify their identity</li>
</ul>
</li>
<li>Note that participants are only becoming aware of their own study identifier, not the identifiers associated with other participants. However, if your team, or your IRB, is uncomfortable with participants knowing their study IDs you can also consider using a “double ID” which is yet another set of unchanging unique identifiers that you use for the sole purpose of data collection. Those identifiers will need to be tracked in your participant tracking database and will need to be replaced with study IDs in the clean data</li>
</ul>
</li>
<li>If you have not previously assigned study identifiers (i.e., your consent and assent process is a part of your instrument), you can have participants enter their identifying information (e.g., name) and then have the tool assign a unique identifier to the participants
<ul>
<li>Using this method, you can potentially download two separate files
<ul>
<li>One with just the instrument data and assigned study ID, with name removed</li>
<li>One with just identifying information and assigned study ID (this information will be added to your participant tracking database)</li>
</ul>
</li>
</ul>
</li>
</ol>
</div>
<div id="paper-data" class="section level5" number="10.3.4.3.2">
<h5>
<span class="header-section-number">10.3.4.3.2</span> Paper Data<a class="anchor" aria-label="anchor" href="#paper-data"><i class="fas fa-link"></i></a>
</h5>
<p>If you take paper forms into the field consider doing the following to connect your data to a participant <span class="citation">(<a href="references.html#ref-otoole_data_2018" role="doc-biblioref">O’Toole et al. 2018</a>; <a href="references.html#ref-reynolds_basics_2022" role="doc-biblioref">Reynolds, Schatschneider, and Logan 2022</a>)</span>.</p>
<ul>
<li>Write the study ID, and any other relevant identifiers (e.g., school ID and teacher ID), on each page of your data collection form and then use either a removable label with participant name and other relevant information and place that over the ID or attach a cover sheet with this information. When you return to the office, you can remove the name label/cover sheet and be left with only the ID on the form.
<ul>
<li>It is this ID only that you will enter into your data entry form during the data capture process, no name.</li>
<li>Removing the label/cover sheet also ensures that your data entry team only sees the study ID when they enter data, increasing privacy by minimizing the number of people who see see participant names.</li>
<li>It is important to double and triple check study identifiers against your participant database to make sure the information is correct before removing the label or cover sheet</li>
<li>Make a plan for the labels/cover sheets (either shred them if they are no longer needed, or store them securely in a locked file cabinet and shred them at a later point)</li>
</ul>
</li>
</ul>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:fig10-9"></span>
<img src="img/cover_sheet2.PNG" alt="Example cover sheet for a paper data collection instrument" width="90%"><p class="caption">
Figure 10.9: Example cover sheet for a paper data collection instrument
</p>
</div>
</div>
</div>
</div>
</div>
<div id="quality-control" class="section level2" number="10.4">
<h2>
<span class="header-section-number">10.4</span> Quality Control<a class="anchor" aria-label="anchor" href="#quality-control"><i class="fas fa-link"></i></a>
</h2>
<p>In addition to implementing quality assurance measures during your planning phases, it is equally important to implement several quality control measures while data collection is underway. Those measures include:</p>
<ol style="list-style-type: decimal">
<li>Field data management</li>
<li>Ongoing data checks</li>
<li>Tracking data collection daily</li>
<li>Collecting data consistently</li>
</ol>
<p>We will discuss each of these measures now.</p>
<div id="field-data-management" class="section level3" number="10.4.1">
<h3>
<span class="header-section-number">10.4.1</span> Field data management<a class="anchor" aria-label="anchor" href="#field-data-management"><i class="fas fa-link"></i></a>
</h3>
<p>If your data collection efforts include field data collection (e.g., data collectors administering assessments in a school), there are several steps your team can implement that will keep your data more secure in the field, help a project coordinator keep better track of what happens in the field, and will lead to more accurate and usable data. Some best practices for field data collection include the following <span class="citation">(<a href="references.html#ref-dime_analytics_data_2021" role="doc-biblioref">DIME Analytics 2021a</a>)</span>:</p>
<ul>
<li>Keep your data secure in the field
<ul>
<li>Make sure all paper forms are kept in a folder (or even a lock box) with you at all times and that they are promptly returned to the office (e.g., not left in a car, not left at someone’s home)</li>
<li>Make sure all data collection devices (e.g., phones, tablets) are password protected and never left open and unattended. Keep all identifiable information encrypted on your field devices (i.e., data is encoded so that only those with a password can decipher it). You may also consider remote wiping capabilities on portable devices in the case of loss or theft <span class="citation">(<a href="references.html#ref-otoole_data_2018" role="doc-biblioref">O’Toole et al. 2018</a>)</span>
</li>
</ul>
</li>
<li>Create tracking sheets to use in the field
<ul>
<li>These sheets should include the names and/or identifiers of every participant who data collectors will be collecting data from</li>
<li>Next to each participant, include any other relevant information to track such as
<ul>
<li>Was the data collected (i.e., a check box)</li>
<li>Who collected the data (i.e., data collector initials or ID)</li>
<li>Date the data was collected</li>
<li>As well as a notes section to describe any potential issues with the data (e.g., “Student had to leave the classroom halfway through the assessment - only partially completed”)</li>
</ul>
</li>
<li>This tracking sheet allows the project coordinator to keep track of what is occurring in the field so that information can be accurately recorded in the participant tracking database and forms can be sent back out for completion as needed</li>
</ul>
</li>
<li>Check paper data in the field
<ul>
<li>Immediately upon completing a form, have data collectors do spot checks. If any problems are found, follow up with the participant for correction if possible.
<ul>
<li>Check for missing data</li>
<li>Check for duplicate answers given</li>
<li>Check for answers provided outside of the assigned area (e.g., answers written in the margins)</li>
<li>Check scoring (e.g., basals and ceilings)</li>
</ul>
</li>
</ul>
</li>
<li>Assign a field supervisor. This person is assigned to:
<ul>
<li>Do another round of data checks in the field once the data collector returns paper forms to the on-site central location (e.g., if data collectors have set up in the teacher’s lounge)</li>
<li>Ensure that all data and equipment is accounted for and returned to the office</li>
<li>Be available for trouble shooting as needed</li>
</ul>
</li>
<li>Do another round of paper data spot checking as soon as the data is returned to the office (see Figure <a href="collect.html#fig:fig10-10">10.10</a>)
<ul>
<li>The project coordinator may do this round of checking as they are tracking information in the participant database</li>
<li>If any issues are found, note that in the tracking database and send the form back out to the field for correction</li>
<li>If your paper forms are mailed back to you from participants, rather than returned from field data collectors, it is still important to do in-office spot checks. If at all possible, reach out to those participants for any corrections.</li>
</ul>
</li>
<li>When a wave of data collection wraps up, collect feedback from data collectors to improve future data collection efforts
<ul>
<li>What went well? What didn’t?</li>
</ul>
</li>
</ul>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:fig10-10"></span>
<img src="img/spot_check.PNG" alt="A series of spot checks that occur with paper data" width="100%"><p class="caption">
Figure 10.10: A series of spot checks that occur with paper data
</p>
</div>
<p><strong>Tracking sheet templates</strong></p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="42%">
<col width="57%">
</colgroup>
<thead><tr class="header">
<th>Source</th>
<th>Resource</th>
</tr></thead>
<tbody><tr class="odd">
<td>Crystal Lewis</td>
<td>Field tracking sheet template <a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;a href="https://docs.google.com/spreadsheets/d/1CeIXvTBtU9O3GNzfFaAMtb69Z2HyOLuPQWsxy7jOWdU/edit?usp=sharing" class="uri"&gt;https://docs.google.com/spreadsheets/d/1CeIXvTBtU9O3GNzfFaAMtb69Z2HyOLuPQWsxy7jOWdU/edit?usp=sharing&lt;/a&gt;&lt;/p&gt;'><sup>72</sup></a>
</td>
</tr></tbody>
</table></div>
</div>
<div id="ongoing-data-checks" class="section level3" number="10.4.2">
<h3>
<span class="header-section-number">10.4.2</span> Ongoing data checks<a class="anchor" aria-label="anchor" href="#ongoing-data-checks"><i class="fas fa-link"></i></a>
</h3>
<p>If you collect data via a web-based form, you will want to perform frequent data quality checks, similar to the checks you performed during the content and data piloting phase. You will want to check for both programming errors (i.e., skip logic programmed incorrectly) as well as response quality errors (e.g. bots, survey comprehension) <span class="citation">(<a href="references.html#ref-dime_analytics_data_2021" role="doc-biblioref">DIME Analytics 2021a</a>; <a href="references.html#ref-gibson_data_2021" role="doc-biblioref">Gibson 2021</a>)</span>.</p>
<ul>
<li>Checks for comprehension
<ul>
<li>Are any questions being misinterpreted?</li>
</ul>
</li>
<li>Checks for missing data
<ul>
<li>Are items being skipped that should not be skipped?</li>
<li>Are participants/data collectors not finishing forms?</li>
</ul>
</li>
<li>Checks for ranges and formats
<ul>
<li>Are values in unexpected formats or falling outside of unexpected ranges?</li>
</ul>
</li>
<li>Checks for duplicate forms
<ul>
<li>Are there duplicate entries for participants?</li>
</ul>
</li>
<li>Is skip logic working as expected?
<ul>
<li>Are people being directed to the correct location based on their responses to items?</li>
</ul>
</li>
<li>Checks for bots/fraud
<ul>
<li>Are forms being completed in a very short period of time?</li>
<li>Are forms being collected from suspicious geolocations?
<ul>
<li>This information may not be available for anonymous data - consult with your IRB</li>
</ul>
</li>
<li>Are there nonsensical responses for open-ended questions?</li>
<li>Are there nonsensical responses to attention or logic checking questions?</li>
</ul>
</li>
</ul>
<p>Some of these checks can be performed programmatically (i.e., you can write a validation script in a program such as R, and run that script on a recurring schedule during data collection to check for things such as values out of range). Other checks may be a manual check of data (e.g., such as downloading your data on a recurring schedule and reviewing open-ended questions for nonsensical responses). If errors are found, consider revising your instrument to prevent future errors if this is possible without jeopardizing the consistency of your data.</p>
</div>
<div id="tracking-data-collection" class="section level3" number="10.4.3">
<h3>
<span class="header-section-number">10.4.3</span> Tracking data collection<a class="anchor" aria-label="anchor" href="#tracking-data-collection"><i class="fas fa-link"></i></a>
</h3>
<p>Throughout data collection your team should be tracking the completion of forms (e.g., consents, paperwork, data collection forms). Your team may designate one person to track data (e.g., the project coordinator), or they may designate multiple. If you are working across multiple sites, with multiple teams, you will most likely have one or more people at each site tracking data as it comes in.</p>
<p>Some tracking best practices include:</p>
<ol style="list-style-type: decimal">
<li>Only track data that you physically have (paper or electronic)
<ul>
<li>Never track data as “complete” that someone just tells you they collected
<ul>
<li>You can always mark this information in a “notes” field and track when you have the physical data</li>
</ul>
</li>
</ul>
</li>
<li>Track daily during data collection
<ul>
<li>Do not wait until the end of data collection to track what data was collected</li>
<li>This helps ensure that you don’t miss the opportunity to collect data that you <em>thought</em> you had but never actually collected</li>
</ul>
</li>
<li>Only track complete data as “complete”
<ul>
<li>If a form is only partially completed and you plan to send it back out to the field for completion, mark this in the “notes” but do not mark it as “completed”. If you have a “partially completed” option, you can mark this option.</li>
</ul>
</li>
</ol>
</div>
<div id="collecting-data-consistently" class="section level3" number="10.4.4">
<h3>
<span class="header-section-number">10.4.4</span> Collecting data consistently<a class="anchor" aria-label="anchor" href="#collecting-data-consistently"><i class="fas fa-link"></i></a>
</h3>
<p>As mentioned in Chapter <a href="style.html#style">8</a>, it’s important to collect data consistently for the entire project to ensure interoperability. Keep the following consistent across both time and forms (e.g., Spanish and English version of a form, link for SchoolA and link for SchoolB):</p>
<ul>
<li>Variable names
<ul>
<li>Use the same names for the same items (and remember it’s best to not add a time component to your variable names at this time)</li>
</ul>
</li>
<li>Variable types
<ul>
<li>For example, if gender is collected as a numeric variable, keep it as a numeric variable</li>
</ul>
</li>
<li>Value codes
<ul>
<li>Make sure response options are consistently coded using the same values (e.g., 0 = “No”, 1 = “Yes”)</li>
</ul>
</li>
<li>Question type and format
<ul>
<li>If a slider question was used for “Percent of time on homework”, continue to ask that question using a slider question</li>
</ul>
</li>
</ul>
<p>Failing to collect your data consistently has many consequences:</p>
<ol style="list-style-type: decimal">
<li>It can make it difficult or impossible to compare outcomes</li>
<li>It makes your work less reproducible</li>
<li>It reduces your ability to physically combine data (i.e., you cannot append dissimilar variables)</li>
<li>It can lead to errors in interpretation</li>
</ol>
<p>Last, collecting data consistently also means measuring things in the same way over time or across forms so that you don’t bias your results. The slightest change in item wording or response options can result in dramatic changes to outcomes <span class="citation">(<a href="references.html#ref-icpsr_introduction_2022" role="doc-biblioref">ICPSR 2022</a>; <a href="references.html#ref-pew_research_center_writing_2023" role="doc-biblioref">Pew Research Center 2023</a>)</span>.</p>
</div>
</div>
<div id="review" class="section level2" number="10.5">
<h2>
<span class="header-section-number">10.5</span> Review<a class="anchor" aria-label="anchor" href="#review"><i class="fas fa-link"></i></a>
</h2>
<p>Recall from Chapter <a href="plan.html#plan">5</a>, we discussed designing and visualizing a data collection workflow during your planning phase. As we’ve learned from this chapter, errors can happen at any point in the workflow so it is important to consider the entire data collection process holistically and integrate both quality assurance and quality control procedures throughout. Figure <a href="collect.html#fig:fig10-11">10.11</a> helps us to see when these practices fit into the different phases our workflow.</p>
<p>Once your workflow is developed and quality assurance and control practices are integrated, consider how you will ensure that your team implements these practices with fidelity. Document the specifics of your plan in an SOP (see Chapter <a href="document.html#document">7</a>), including assigning roles and responsibilities for each task in the process. Last, train your team on how to implement the data collection SOP, and implement refresher trainings as needed.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:fig10-11"></span>
<img src="img/data_collect_workflow2.PNG" alt="Integrating quality assurance and control into a data collection workflow" width="100%"><p class="caption">
Figure 10.11: Integrating quality assurance and control into a data collection workflow
</p>
</div>
<p><strong>Instrument Workflow Resources</strong></p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="42%">
<col width="57%">
</colgroup>
<thead><tr class="header">
<th>Source</th>
<th>Resource</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>DIME Wiki</td>
<td>Questionnaire design timeline<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;a href="https://dimewiki.worldbank.org/Questionnaire_Design" class="uri"&gt;https://dimewiki.worldbank.org/Questionnaire_Design&lt;/a&gt;&lt;/p&gt;'><sup>73</sup></a>
</td>
</tr>
<tr class="even">
<td>Sarah Kopper, Katie Parry</td>
<td>Five key steps in the process of survey design<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;a href="https://www.povertyactionlab.org/resource/survey-design" class="uri"&gt;https://www.povertyactionlab.org/resource/survey-design&lt;/a&gt;&lt;/p&gt;'><sup>74</sup></a>
</td>
</tr>
</tbody>
</table></div>
<blockquote>
<p><strong>Note</strong> <br><br>
All of the web-based data collection efforts in this chapter assume you are making a private link that you are sharing with a targeted list (e.g., students in a classroom, teachers in a school). However, there may be times when you need to publicly recruit and collect data for your study and this opens your instrument up for a plethora of data quality issues. Bots, fraudulent data, and incoherent or synthetic responses are all issues that can plague your online data collection efforts, particularly with crowdsourcing platforms <span class="citation">(<a href="references.html#ref-douglas_data_2023" role="doc-biblioref">Douglas, Ewell, and Brauer 2023</a>; <a href="references.html#ref-veselovsky_artificial_2023" role="doc-biblioref">Veselovsky, Ribeiro, and West 2023</a>; <a href="references.html#ref-webb_too_2022" role="doc-biblioref">Webb and Tangney 2022</a>)</span>. If possible though, avoid using public survey links. One possible workaround would be to first create a public link with a screener. Then after participants are verified through the screener, send a private, unique link. <br><br>
If a workaround is not possible and you need to use a public link, some suggestions that can help you both secure your instrument and detect fraud include the following <span class="citation">(<a href="references.html#ref-simone_how_2019" role="doc-biblioref">Simone 2019</a>; <a href="references.html#ref-teitcher_detecting_2015" role="doc-biblioref">Teitcher et al. 2015</a>)</span>:
- Not posting the link on social media<br>
- Using CAPTCHA verification<br>
- Using tools that allow you to block suspicious geolocations<br>
- Not automating payment upon survey completion<br>
- Including open-ended questions<br>
- Building attention/logic checks into the survey<br>
- Asking some of the same questions twice (once early on and again at the end) <br><br>
Even with these additions to the survey, you will want to check your data thoroughly before analyzing it and before providing payments to participants. <br><br></p>
</blockquote>

</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="track.html"><span class="header-section-number">9</span> Data Tracking</a></div>
<div class="next"><a href="capture.html"><span class="header-section-number">11</span> Data Capture</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#collect"><span class="header-section-number">10</span> Data Collection</a></li>
<li><a class="nav-link" href="#quality-assurance-and-control"><span class="header-section-number">10.1</span> Quality assurance and control</a></li>
<li>
<a class="nav-link" href="#institutional-review-board"><span class="header-section-number">10.2</span> Institutional Review Board</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#background"><span class="header-section-number">10.2.1</span> Background</a></li>
<li><a class="nav-link" href="#requirements"><span class="header-section-number">10.2.2</span> Requirements</a></li>
<li><a class="nav-link" href="#agreements"><span class="header-section-number">10.2.3</span> Agreements</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#quality-assurance"><span class="header-section-number">10.3</span> Quality Assurance</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#questionnaire-design"><span class="header-section-number">10.3.1</span> Questionnaire design</a></li>
<li><a class="nav-link" href="#pilot-the-instrument"><span class="header-section-number">10.3.2</span> Pilot the instrument</a></li>
<li><a class="nav-link" href="#choose-quality-data-collection-tools"><span class="header-section-number">10.3.3</span> Choose quality data collection tools</a></li>
<li><a class="nav-link" href="#collect-build"><span class="header-section-number">10.3.4</span> Build with the end in mind</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#quality-control"><span class="header-section-number">10.4</span> Quality Control</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#field-data-management"><span class="header-section-number">10.4.1</span> Field data management</a></li>
<li><a class="nav-link" href="#ongoing-data-checks"><span class="header-section-number">10.4.2</span> Ongoing data checks</a></li>
<li><a class="nav-link" href="#tracking-data-collection"><span class="header-section-number">10.4.3</span> Tracking data collection</a></li>
<li><a class="nav-link" href="#collecting-data-consistently"><span class="header-section-number">10.4.4</span> Collecting data consistently</a></li>
</ul>
</li>
<li><a class="nav-link" href="#review"><span class="header-section-number">10.5</span> Review</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/Cghlewis/data-mgmt-ed-research-book/blob/master/09-data-collection.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/Cghlewis/data-mgmt-ed-research-book/edit/master/09-data-collection.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Data Management in Large-Scale Education Research</strong>" was written by Crystal Lewis. It was last built on 2023-07-05.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer>
</body>
</html>
